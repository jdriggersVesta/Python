{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72278115",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Importing Necessary dependencies\n",
    "import pandas as pd\n",
    "import snowflake.connector as sf\n",
    "import numpy as np\n",
    "import time\n",
    "import boto3\n",
    "import os\n",
    "import zipfile\n",
    "import smtplib, ssl\n",
    "import shutil\n",
    "import csv\n",
    "from snowflake.connector.pandas_tools import write_pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ba74034",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Create Log for review\n",
    "start_time = time.time()\n",
    "claimslog = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1a58ff69",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    #Create Local Directory to store files in temporarily\n",
    "    os.makedirs('C:\\\\Users\\\\Jad Driggers\\\\Documents\\\\Vesta\\\\CCAFILES')\n",
    "    os.chdir('C:\\\\Users\\\\Jad Driggers\\\\Documents\\\\Vesta\\\\CCAFILES')\n",
    "    root_directory = os.getcwd()\n",
    "    claimslog.append('Successfully created CCA File Temporary Folder at ' + time.strftime('%Y-%m-%d %H:%M:%S',\n",
    "                                                                                          time.localtime(time.time())))\n",
    "except Exception as e:\n",
    "    claimslog.append('There was an error with creating the temporary CCA File - ' + str(e))\n",
    "    print('Successfully created CCA File Temporary Folder at ' + time.strftime('%Y-%m-%d %H:%M:%S',\n",
    "                                                                               time.localtime(time.time())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e1967f2d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AWS connection object created at 2022-10-10 16:11:04\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    #Create Connection Object for Connecting to AWS\n",
    "    s3 = boto3.resource(\n",
    "        service_name='s3',\n",
    "        region_name='us-east-1',\n",
    "        aws_access_key_id=os.getenv('aws_access_key_id'),\n",
    "        aws_secret_access_key=os.getenv('aws_secret_access_key'))\n",
    "    print('AWS connection object created at ' + time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(time.time())))\n",
    "    claimslog.append(\n",
    "        'AWS connection object created at ' + time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(time.time())))\n",
    "except Exception as e:\n",
    "    print('There was an error with creating the AWS connection object - ' + str(e))\n",
    "    claimslog.append('There was an error with creating the AWS connection object - ' + str(e))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "['Successfully created CCA File Temporary Folder at 2022-10-10 12:58:14',\n 'AWS connection object created at 2022-10-10 12:58:21',\n 'Looking for CCA Files that start like Element claims 202209.zip and Element MDS 202209.zip at 2022-10-10 12:58:42',\n 'There was an error while looking for most CCA Files - An error occurred (SignatureDoesNotMatch) when calling the ListObjects operation: The request signature we calculated does not match the signature you provided. Check your key and signing method.',\n 'AWS connection object created at 2022-10-10 13:01:23',\n 'Looking for CCA Files that start like Element claims 202209.zip and Element MDS 202209.zip at 2022-10-10 13:01:31',\n 'Files were successfully downloaded at 2022-10-10 13:02:17',\n 'Successfully Deleted all contents in temporary CCA Folder at 2022-10-10 13:04:42',\n 'Successfully created CCA File Temporary Folder at 2022-10-10 16:10:53',\n 'AWS connection object created at 2022-10-10 16:11:04']"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "claimslog"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a96227da",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for CCA Files that start like Element claims 202210.zip and Element MDS 202210.zip at 2022-10-10 16:11:16\n"
     ]
    }
   ],
   "source": [
    "#Create the file name format for locating the proper CCA files to parse\n",
    "\n",
    "filename_format_list = ['Element claims 202210.zip', 'Element MDS 202210.zip']\n",
    "claimslog.append('Looking for CCA Files that start like ' + \" and \".join(filename_format_list) + ' at ' + time.strftime(\n",
    "    '%Y-%m-%d %H:%M:%S', time.localtime(time.time())))\n",
    "print('Looking for CCA Files that start like ' + \" and \".join(filename_format_list) + ' at ' + time.strftime(\n",
    "    '%Y-%m-%d %H:%M:%S', time.localtime(time.time())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Element claims 202210.zip', 'Element MDS 202210.zip']\n"
     ]
    }
   ],
   "source": [
    "print(filename_format_list)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "79a82ef6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Creating a list to store all the keys (file names) to download\n",
    "\n",
    "key_list = []\n",
    "\n",
    "try:\n",
    "    #Searching the S3 bucket for the most current Ping Files\n",
    "    for obj in s3.Bucket('hometeam-clinical-data').objects.all():\n",
    "        for filename_format in filename_format_list:\n",
    "            if filename_format in str(obj):\n",
    "                #print(obj.key)\n",
    "                key_list.append(obj.key)\n",
    "\n",
    "except Exception as e:\n",
    "    claimslog.append('There was an error while looking for most CCA Files - ' + str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    },
    {
     "data": {
      "text/plain": "['Successfully created CCA File Temporary Folder at 2022-10-10 12:58:14',\n 'AWS connection object created at 2022-10-10 12:58:21',\n 'Looking for CCA Files that start like Element claims 202209.zip and Element MDS 202209.zip at 2022-10-10 12:58:42',\n 'There was an error while looking for most CCA Files - An error occurred (SignatureDoesNotMatch) when calling the ListObjects operation: The request signature we calculated does not match the signature you provided. Check your key and signing method.',\n 'AWS connection object created at 2022-10-10 13:01:23',\n 'Looking for CCA Files that start like Element claims 202209.zip and Element MDS 202209.zip at 2022-10-10 13:01:31',\n 'Files were successfully downloaded at 2022-10-10 13:02:17',\n 'Successfully Deleted all contents in temporary CCA Folder at 2022-10-10 13:04:42',\n 'Successfully created CCA File Temporary Folder at 2022-10-10 16:10:53',\n 'AWS connection object created at 2022-10-10 16:11:04',\n 'Looking for CCA Files that start like Element claims 202210.zip and Element MDS 202210.zip at 2022-10-10 16:11:16']"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(key_list)\n",
    "claimslog\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e6ccf1d8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    #Downloading each of the files found in the key list\n",
    "    for file in key_list:\n",
    "        s3.Bucket('hometeam-clinical-data').download_file(file, file.split('/')[2])\n",
    "        print(\n",
    "            'Files were successfully downloaded at ' + time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(time.time())))\n",
    "    claimslog.append(\n",
    "        'Files were successfully downloaded at ' + time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(time.time())))\n",
    "except Exception as e:\n",
    "    claimslog.append('There was an error while trying to download the CCA Files - ' + str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca78188d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#On local computer, change directory and set directory for unzipping of files.\n",
    "os.chdir('C:\\\\Users\\\\Jad Driggers\\\\Documents\\\\Vesta\\\\CCAFILES')\n",
    "root_directory = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29382098",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Locate only Zipped Files\n",
    "files_to_unzip = []\n",
    "for filename in os.listdir(root_directory):\n",
    "    if 'zip' in filename:\n",
    "        files_to_unzip.append(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dec649e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    #Unzip each file in the Zipped files list\n",
    "    for zipped_file in files_to_unzip:\n",
    "        with zipfile.ZipFile(root_directory + \"\\\\\" + zipped_file, 'r') as zip_ref:\n",
    "            #print(zipped_file)\n",
    "            zip_ref.extractall(root_directory)\n",
    "    shutil.unpack_archive(root_directory + \"\\\\\" + zipped_file, root_directory + \"\\\\\" + zipped_file.split('.')[0])\n",
    "    claimslog.append(\n",
    "        'Successfully Unzipped each file at ' + time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(time.time())))\n",
    "except Exception as e:\n",
    "    claimslog.append('There was an error while trying to unzip each file - ' + str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525b6dee",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "% % time\n",
    "#Create dictionary to store dataframes as they are created \n",
    "df_dict = {}\n",
    "error_dict = {}\n",
    "\n",
    "#Set current directory\n",
    "cwd = os.chdir('C:\\\\Users\\\\Jad Driggers\\\\Documents\\\\Vesta\\\\CCAFILES')\n",
    "\n",
    "#Loop through all txt files in the directory\n",
    "for i, file in enumerate(os.listdir(cwd)):\n",
    "    if '.txt' in file:\n",
    "\n",
    "        #empty lists to story the data while cleaning\n",
    "        df_list = []\n",
    "        df_error_list = []\n",
    "\n",
    "        #open the txt file\n",
    "        with open(file, 'r') as csvfile:\n",
    "            reader = csv.reader(csvfile, delimiter='\\t')\n",
    "\n",
    "            #read through each line and find any rows with errors\n",
    "            for i, row in enumerate(reader):\n",
    "                if i == 0:\n",
    "                    #capture the correct number of columns for the dataframe\n",
    "                    correct_columns = len(row)\n",
    "\n",
    "                df_list.append(row)\n",
    "\n",
    "                #create list of rows with errors\n",
    "                if len(row) < correct_columns:\n",
    "                    df_error_list.append(i)\n",
    "\n",
    "            #Check to see if the list row in the data frame is an empty row, if so, drop it\n",
    "            if len(df_list[df_error_list[-1]]) == 0:\n",
    "                df_error_list.pop()\n",
    "\n",
    "            #The error exists between two rows, so looking at the second occurance of an error \n",
    "            #and deleting the first item should fix the error\n",
    "            for i, error in enumerate(df_error_list):\n",
    "                if i % 2 != 0:\n",
    "                    df_list[error].pop(0)\n",
    "\n",
    "            #Loop back through the error list and join first errors to second errors to make a complete row\n",
    "            for i, error in enumerate(df_error_list):\n",
    "                if i % 2 == 0:\n",
    "                    df_list[error] = df_list[error] + df_list[error + 1]\n",
    "\n",
    "            #Loop back through the entire data frame list to delete those rows that are smaller than the correct\n",
    "            #number of columns\n",
    "            for i, item in enumerate(df_list):\n",
    "                if len(item) < correct_columns:\n",
    "                    del df_list[i]\n",
    "\n",
    "            df = pd.DataFrame(df_list[1:])\n",
    "            df.columns = df_list[0]\n",
    "            df = df.rename(columns={df.columns[0]: df.columns[0][3:]})\n",
    "            df = df.astype(str)\n",
    "            df.columns = map(lambda x: str(x).upper(), df.columns)\n",
    "            df_dict[csvfile.name.replace(' ', '_').split(\".\")[0]] = df\n",
    "            error_dict[csvfile.name.replace(' ', '_').split(\".\")[0]] = df_error_list\n",
    "\n",
    "        csvfile.close()\n",
    "\n",
    "for key, value in df_dict.items():\n",
    "    print(key)\n",
    "\n",
    "print(error_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e675666d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'C:\\\\Users\\\\Jad Driggers\\\\Documents\\\\Vesta\\\\CCAFILES'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[1;32mIn [17]\u001B[0m, in \u001B[0;36m<cell line: 3>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m#Delete all contents in the temporary CCA Folder\u001B[39;00m\n\u001B[0;32m      2\u001B[0m os\u001B[38;5;241m.\u001B[39mchdir(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mC:\u001B[39m\u001B[38;5;130;01m\\\\\u001B[39;00m\u001B[38;5;124mUsers\u001B[39m\u001B[38;5;130;01m\\\\\u001B[39;00m\u001B[38;5;124mJad Driggers\u001B[39m\u001B[38;5;130;01m\\\\\u001B[39;00m\u001B[38;5;124mDocuments\u001B[39m\u001B[38;5;130;01m\\\\\u001B[39;00m\u001B[38;5;124mVesta\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m----> 3\u001B[0m \u001B[43mshutil\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrmtree\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mC:\u001B[39;49m\u001B[38;5;130;43;01m\\\\\u001B[39;49;00m\u001B[38;5;124;43mUsers\u001B[39;49m\u001B[38;5;130;43;01m\\\\\u001B[39;49;00m\u001B[38;5;124;43mJad Driggers\u001B[39;49m\u001B[38;5;130;43;01m\\\\\u001B[39;49;00m\u001B[38;5;124;43mDocuments\u001B[39;49m\u001B[38;5;130;43;01m\\\\\u001B[39;49;00m\u001B[38;5;124;43mVesta\u001B[39;49m\u001B[38;5;130;43;01m\\\\\u001B[39;49;00m\u001B[38;5;124;43mCCAFILES\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m      4\u001B[0m claimslog\u001B[38;5;241m.\u001B[39mappend(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mSuccessfully Deleted all contents in temporary CCA Folder at \u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;241m+\u001B[39m time\u001B[38;5;241m.\u001B[39mstrftime(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m%\u001B[39m\u001B[38;5;124mY-\u001B[39m\u001B[38;5;124m%\u001B[39m\u001B[38;5;124mm-\u001B[39m\u001B[38;5;132;01m%d\u001B[39;00m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m%\u001B[39m\u001B[38;5;124mH:\u001B[39m\u001B[38;5;124m%\u001B[39m\u001B[38;5;124mM:\u001B[39m\u001B[38;5;124m%\u001B[39m\u001B[38;5;124mS\u001B[39m\u001B[38;5;124m'\u001B[39m, time\u001B[38;5;241m.\u001B[39mlocaltime(time\u001B[38;5;241m.\u001B[39mtime())))\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\NewBase\\lib\\shutil.py:759\u001B[0m, in \u001B[0;36mrmtree\u001B[1;34m(path, ignore_errors, onerror)\u001B[0m\n\u001B[0;32m    757\u001B[0m     \u001B[38;5;66;03m# can't continue even if onerror hook returns\u001B[39;00m\n\u001B[0;32m    758\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m\n\u001B[1;32m--> 759\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_rmtree_unsafe\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpath\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43monerror\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\NewBase\\lib\\shutil.py:610\u001B[0m, in \u001B[0;36m_rmtree_unsafe\u001B[1;34m(path, onerror)\u001B[0m\n\u001B[0;32m    608\u001B[0m         entries \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(scandir_it)\n\u001B[0;32m    609\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mOSError\u001B[39;00m:\n\u001B[1;32m--> 610\u001B[0m     \u001B[43monerror\u001B[49m\u001B[43m(\u001B[49m\u001B[43mos\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mscandir\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpath\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msys\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexc_info\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    611\u001B[0m     entries \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m    612\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m entry \u001B[38;5;129;01min\u001B[39;00m entries:\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\NewBase\\lib\\shutil.py:607\u001B[0m, in \u001B[0;36m_rmtree_unsafe\u001B[1;34m(path, onerror)\u001B[0m\n\u001B[0;32m    605\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_rmtree_unsafe\u001B[39m(path, onerror):\n\u001B[0;32m    606\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 607\u001B[0m         \u001B[38;5;28;01mwith\u001B[39;00m \u001B[43mos\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mscandir\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpath\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mas\u001B[39;00m scandir_it:\n\u001B[0;32m    608\u001B[0m             entries \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(scandir_it)\n\u001B[0;32m    609\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mOSError\u001B[39;00m:\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: [WinError 3] The system cannot find the path specified: 'C:\\\\Users\\\\Jad Driggers\\\\Documents\\\\Vesta\\\\CCAFILES'"
     ]
    }
   ],
   "source": [
    "#Delete all contents in the temporary CCA Folder\n",
    "os.chdir('C:\\\\Users\\\\Jad Driggers\\\\Documents\\\\Vesta')\n",
    "shutil.rmtree('C:\\\\Users\\\\Jad Driggers\\\\Documents\\\\Vesta\\\\CCAFILES')\n",
    "claimslog.append('Successfully Deleted all contents in temporary CCA Folder at ' + time.strftime('%Y-%m-%d %H:%M:%S',\n",
    "                                                                                                 time.localtime(\n",
    "                                                                                                     time.time())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ec5abe",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_dict['Element_claims_member_demographics'].rename(columns={\"CCAID\": \"MEMBER_ID\",\n",
    "                                                              \"NAME\": \"MNAME\",\n",
    "                                                              \"PCL_SITENAME\": \"PCL\",\n",
    "                                                              \"PCL_SUMMARYNAME\": \"PCL_SUMMARY\",\n",
    "                                                              \"PCL_CAPSITE\": \"PCL_CAP\",\n",
    "                                                              \"DUAL\": \"DUAL_\",\n",
    "                                                              \"GC_ENGAGEMENTSTATUS\": \"GC_ENGAGEMENT_STATUS\",\n",
    "                                                              \"MDS_UNREACHABLEFLAG\": \"MDS_UNREACHABLE\"},\n",
    "                                                     errors=\"raise\",\n",
    "                                                     inplace=True)\n",
    "df_dict['Element_claims_member_contact'].rename(columns={\"CCAID\": \"MEMBER_ID\",\n",
    "                                                         \"ENR_SPAN_START\": \"ENROLL_ST\",\n",
    "                                                         \"ENR_SPAN_END\": \"ENROLL_ED\",\n",
    "                                                         \"ENROLL_STATUS\": \"ENROLL_STATUS2\",\n",
    "                                                         \"NAME\": \"FULL_NAME\",\n",
    "                                                         \"AGE_NOW\": \"AGE\",\n",
    "                                                         \"GENDER\": \"SEX\",\n",
    "                                                         \"LANGUAGE\": \"LANGUAGE_SPOKEN\",\n",
    "                                                         \"ADDRESS1\": \"ADDRESS_1\",\n",
    "                                                         \"ADDRESS2\": \"ADDRESS_2\",\n",
    "                                                         \"LATEST_PHONE\": \"PHONE_1\"},\n",
    "                                                errors=\"raise\",\n",
    "                                                inplace=True)\n",
    "df_dict['Element_claims_member_enrollment'].rename(columns={\"CCAID\": \"MEMBER_ID\",\n",
    "                                                            \"PCP_PROVK\": \"PCP_ID\",\n",
    "                                                            \"PCL_SITENAME\": \"PCL\",\n",
    "                                                            \"DUAL\": \"DUAL_\"},\n",
    "                                                   errors=\"raise\",\n",
    "                                                   inplace=True)\n",
    "df_dict['Element_claims'].rename(columns={\"CCAID\": \"MEMBER_ID\",\n",
    "                                          \"HICN\": \"MEDICARE_ID\",\n",
    "                                          \"CLAIM_NUM\": \"CLAIM_ID\",\n",
    "                                          \"TABLEROWID\": \"CLAIM_LINE\",\n",
    "                                          \"HOSPITAL_CLAIM_TYPE\": \"HOS_CLAIM_TYPE\",\n",
    "                                          \"SERVICE_CODE\": \"CODE\",\n",
    "                                          \"SERVICE_DESC\": \"CODE_DESC\",\n",
    "                                          \"DATE_TO\": \"DATE_THRU\",\n",
    "                                          \"BILLTYPE\": \"BILL_TYPE\",\n",
    "                                          \"BILLTYPE_DESCR\": \"BILL_TYPE_DESCR\",\n",
    "                                          \"DATE_PAID\": \"PAID_DTE\",\n",
    "                                          \"CLAIMCATEGORY_GL1\": \"CLAIM_GROUP\"},\n",
    "                                 errors=\"raise\",\n",
    "                                 inplace=True)\n",
    "df_dict['Element_claims_member_dx'].rename(columns={\"CCAID\": \"MEMBER_ID\",\n",
    "                                                    \"HICN\": \"MEDICARE_ID\",\n",
    "                                                    \"CLAIM_NUM\": \"CLAIM_ID\",\n",
    "                                                    \"DIAGREFNO\": \"DIAG_NUM\"},\n",
    "                                           errors=\"raise\",\n",
    "                                           inplace=True)\n",
    "df_dict['Element_MDS'].rename(columns={\"CCAID\": \"MEMBER_ID\",\n",
    "                                       \"ASSESSMENT_DATE\": \"ENC_DATE\"},\n",
    "                              errors=\"raise\",\n",
    "                              inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02503b8a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Create two dictionaries to store the columns and the max len of values in those columns\n",
    "max_col_len = {}\n",
    "col_dict = {}\n",
    "\n",
    "#Vectorizing the lenth function\n",
    "measurer = np.vectorize(len)\n",
    "\n",
    "#Looping through df_dictionary to capture column names and max len of values in those columns\n",
    "max_col_len = {}\n",
    "for key, value in df_dict.items():\n",
    "    col_len = measurer(df_dict[key].astype(str)).max(axis=0)\n",
    "    max_col_len[key] = col_len\n",
    "    col_dict[key] = df_dict[key].columns.tolist()\n",
    "\n",
    "\n",
    "#Function for joining the two dictionaries with similar keys (claim files)\n",
    "def common_entries(*dcts):\n",
    "    if not dcts:\n",
    "        return\n",
    "    for i in set(dcts[0]).intersection(*dcts[1:]):\n",
    "        yield (i,) + tuple(d[i] for d in dcts)\n",
    "\n",
    "\n",
    "mylist = list(common_entries(col_dict, max_col_len))\n",
    "\n",
    "#Creating new dictionary and zipping the column names with respective max len of values in those columns\n",
    "sql_dict = {}\n",
    "for x in mylist:\n",
    "    sql_dict[x[0]] = list(zip(x[1], x[2]))\n",
    "\n",
    "#Iterating through the list values to prep for SQL to Snowflake\n",
    "sql_script_dict_table = {}\n",
    "for key, value in sql_dict.items():\n",
    "    script_string_table = ''\n",
    "    for (col, max_len) in sql_dict[key]:\n",
    "        script_string_table += str(col) + ' VARCHAR(' + str(max_len + 10) + '),'\n",
    "    sql_script_dict_table[key] = \"(\" + script_string_table[:-1] + \")\"\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa556c56",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8987b95d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "##### BEFORE PRODUCTION - YOU MUST CREATE SQL LOGIC TO DROP ALL THE TABLES PRIOR TO CREATING NEW ONES\n",
    "\n",
    "\n",
    "############ EXCEPTION ############### DO NOT DROP MDS TABLE - APPEND TO IT !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a14776",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8dc8c4",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_dict['Element_claims_member_contact']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "#Creating of parameters for securing connection to Snowflake-credentials stored in local environment variables\n",
    "username = os.getenv('Snowflake_User')\n",
    "password = os.getenv('Snowflake_password')\n",
    "account = os.getenv('Snowflake_account')\n",
    "\n",
    "#Define parameters if neccessary\n",
    "warehouse = 'DEVELOPER_STANDARD'\n",
    "database = 'VESTA_DEVELOPMENT'\n",
    "schema = 'ANALYST_SANDBOX'\n",
    "\n",
    "#Create connection object for Snowflake connection\n",
    "conn = sf.connect(user=username, password=password, account=account, warehouse=warehouse)\n",
    "\n",
    "\n",
    "#Execution function\n",
    "def execute_query(connection, query):\n",
    "    cursor = connection.cursor()\n",
    "    cursor.execute(query)\n",
    "    cursor.close\n",
    "\n",
    "\n",
    "#Define Database to use in Snowflake\n",
    "sql = 'USE DATABASE {}'.format(database)\n",
    "execute_query(conn, sql)\n",
    "\n",
    "#Define Schema to use in Snowflake\n",
    "sql = 'USE SCHEMA {}.{}'.format(database, schema)\n",
    "execute_query(conn, sql)\n",
    "\n",
    "#Define Warehouse to use in Snowflake\n",
    "sql = 'USE WAREHOUSE {}'.format(warehouse)\n",
    "execute_query(conn, sql)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### SQL to drop tables prior to creating and uploading data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "################################## Contact Table\n",
    "try:\n",
    "    sql = 'DROP TABLE IF EXISTS CCA_CONTACT_RAW_TEST'\n",
    "    execute_query(conn, sql)\n",
    "\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "################################## Claims Table\n",
    "try:\n",
    "    sql = 'DROP TABLE IF EXISTS CCA_CLAIMS_RAW_TEST'\n",
    "    execute_query(conn, sql)\n",
    "\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "################################## Demographic Table\n",
    "try:\n",
    "    sql = 'DROP TABLE IF EXISTS CCA_DEMO_RAW_TEST'\n",
    "    execute_query(conn, sql)\n",
    "\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "################################## DX Table\n",
    "try:\n",
    "    sql = 'DROP TABLE IF EXISTS CCA_DX_RAW_TEST'\n",
    "    execute_query(conn, sql)\n",
    "\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "################################## Enroll Table\n",
    "try:\n",
    "    sql = 'DROP TABLE IF EXISTS CCA_ENROLL_RAW_TEST'\n",
    "    execute_query(conn, sql)\n",
    "\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "################################## PCP Table\n",
    "try:\n",
    "    sql = 'DROP TABLE IF EXISTS CCA_PCP_RAW_TEST'\n",
    "    execute_query(conn, sql)\n",
    "\n",
    "except Exception as e:\n",
    "    print(e)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d315275",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name 'sql_script_dict_table' is not defined\n",
      "name 'sql_script_dict_table' is not defined\n",
      "--- 1.956712245941162 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# start_time = time.time()\n",
    "# #Creating of parameters for securing connection to Snowflake-credentials stored in local environment variables\n",
    "# username = os.getenv('Snowflake_User')\n",
    "# password = os.getenv('Snowflake_password')\n",
    "# account = os.getenv('Snowflake_account')\n",
    "#\n",
    "# #Define parameters if neccessary\n",
    "# warehouse = 'DEVELOPER_STANDARD'\n",
    "# database = 'VESTA_DEVELOPMENT'\n",
    "# schema = 'ANALYST_SANDBOX'\n",
    "#\n",
    "# #Create connection object for Snowflake connection\n",
    "# conn = sf.connect(user = username, password = password, account = account, warehouse = warehouse)\n",
    "#\n",
    "# #Execution function\n",
    "# def execute_query(connection,query):\n",
    "#     cursor = connection.cursor()\n",
    "#     cursor.execute(query)\n",
    "#     cursor.close\n",
    "#\n",
    "# #Define Database to use in Snowflake\n",
    "# sql = 'USE DATABASE {}'.format(database)\n",
    "# execute_query(conn,sql)\n",
    "#\n",
    "# #Define Schema to use in Snowflake\n",
    "# sql = 'USE SCHEMA {}.{}'.format(database,schema)\n",
    "# execute_query(conn,sql)\n",
    "#\n",
    "# #Define Warehouse to use in Snowflake\n",
    "# sql = 'USE WAREHOUSE {}'.format(warehouse)\n",
    "# execute_query(conn,sql)\n",
    "\n",
    "\n",
    "################################## MEMBER CONTACT SQL\n",
    "\n",
    "try:\n",
    "    sql = 'CREATE TABLE IF NOT EXISTS CCA_CONTACT_RAW_TEST ' + sql_script_dict_table['Element_claims_member_contact']\n",
    "    execute_query(conn, sql)\n",
    "\n",
    "    success, nchucks, nrows, _ = write_pandas(conn, df_dict['Element_claims_member_contact'], 'CCA_CONTACT_RAW_TEST')\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "###################################\n",
    "\n",
    "################################## CLAIMS SQL\n",
    "\n",
    "try:\n",
    "    sql = 'CREATE TABLE IF NOT EXISTS CCA_CLAIMS_RAW_TEST ' + sql_script_dict_table['Element_claims']\n",
    "    execute_query(conn, sql)\n",
    "\n",
    "    success, nchucks, nrows, _ = write_pandas(conn, df_dict['Element_claims'], 'CCA_CLAIMS_RAW_TEST')\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "# ###################################\n",
    "#\n",
    "# ################################## DEMO SQL\n",
    "#\n",
    "try:\n",
    "    sql = 'CREATE TABLE IF NOT EXISTS CCA_DEMO_RAW_TEST ' + sql_script_dict_table['Element_claims_member_demographics']\n",
    "    execute_query(conn, sql)\n",
    "\n",
    "    success, nchucks, nrows, _ = write_pandas(conn, df_dict['Element_claims_member_demographics'], 'CCA_DEMO_RAW_TEST')\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "# ###################################\n",
    "#\n",
    "# ################################## DX SQL\n",
    "\n",
    "try:\n",
    "    sql = 'CREATE TABLE IF NOT EXISTS CCA_DX_RAW_TEST ' + sql_script_dict_table['Element_claims_member_dx']\n",
    "    execute_query(conn, sql)\n",
    "\n",
    "    success, nchucks, nrows, _ = write_pandas(conn, df_dict['Element_claims_member_dx'], 'CCA_DX_RAW_TEST')\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "# ###################################\n",
    "#\n",
    "# ################################## ENROLLMENT SQL\n",
    "\n",
    "try:\n",
    "    sql = 'CREATE TABLE IF NOT EXISTS CCA_ENROLL_RAW_TEST ' + sql_script_dict_table['Element_claims_member_enrollment']\n",
    "    execute_query(conn, sql)\n",
    "\n",
    "    success, nchucks, nrows, _ = write_pandas(conn, df_dict['Element_claims_member_enrollment'], 'CCA_ENROLL_RAW_TEST')\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "# ###################################\n",
    "#\n",
    "# ################################## PCP SQL\n",
    "\n",
    "try:\n",
    "    sql = 'CREATE TABLE IF NOT EXISTS CCA_PCP_RAW_TEST ' + sql_script_dict_table['Element_claims_PCP_contact']\n",
    "    execute_query(conn, sql)\n",
    "\n",
    "    success, nchucks, nrows, _ = write_pandas(conn, df_dict['Element_claims_PCP_contact'], 'CCA_PCP_RAW_TEST')\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "# # ###################################\n",
    "#\n",
    "# ################################## MDS SQL\n",
    "\n",
    "try:\n",
    "    sql = 'CREATE TABLE IF NOT EXISTS CCA_MDS_RAW_TEST ' + sql_script_dict_table['Element_MDS']\n",
    "    execute_query(conn, sql)\n",
    "\n",
    "    success, nchucks, nrows, _ = write_pandas(conn, df_dict['Element_MDS'], 'CCA_MDS_RAW_TEST')\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "###################################\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c535ea98",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "claimslog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c566bff",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "my_string = '\\n'.join(pinglog)\n",
    "\n",
    "port = 465  # For SSL\n",
    "smtp_server = \"smtp.gmail.com\"\n",
    "sender_email = \"VestaPingLog@gmail.com\"  # Enter your address\n",
    "receiver_email_list = [\"jdriggers@vestahealthcare.com\", \"john@vestahealthcare.com\",\n",
    "                       'joe@vestahealthcare.com']  # Enter receiver address\n",
    "password = os.getenv('Vesta_Ping_Log_Email')\n",
    "message = \"Subject: Ping Logs \\n\" + '''\n",
    "             \n",
    "''' + my_string\n",
    "\n",
    "context = ssl.create_default_context()\n",
    "with smtplib.SMTP_SSL(smtp_server, port, context=context) as server:\n",
    "    server.login(sender_email, password)\n",
    "    for receiver_email in receiver_email_list:\n",
    "        server.sendmail(sender_email, receiver_email, message)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}