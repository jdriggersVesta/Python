{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54c41d9f",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# ED-IP Prediction with Random Forests\n",
    "\n",
    "The goal of the model is to predict whether or not a member is going to have an ED or IP visit in the next 180 following the latest claim stratification. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5140dc89",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Importing Necessary dependencies\n",
    "import pandas as pd\n",
    "import snowflake.connector as sf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea02a87f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successful Connection\n",
      "Successful DataFrame Created\n",
      "Ready for Cleaning\n"
     ]
    }
   ],
   "source": [
    "# Snowflake credentials stored in environment variables\n",
    "\n",
    "username = os.getenv('Snowflake_User')\n",
    "password = os.getenv('Snowflake_password')\n",
    "account = os.getenv('Snowflake_account')\n",
    "\n",
    "# Define warehouse, if necessary\n",
    "warehouse = 'DEVELOPER_BASIC'\n",
    "\n",
    "# Define Database, if not defined in SQL request\n",
    "#database = 'VESTA_STAGING'\n",
    "\n",
    "# Create connection object for Snowflake connection\n",
    "conn = sf.connect(user = username, password = password, account = account, warehouse = warehouse)\n",
    "\n",
    "# Execution function\n",
    "def execute_query(connection,query):\n",
    "    cursor = connection.cursor()\n",
    "    cursor.execute(query)\n",
    "    cursor.close\n",
    "\n",
    "try:\n",
    "    # If defining a database, uncomment code set and add database in connection parameter\n",
    "    #sql = 'use {}'.format(database)\n",
    "    #execute_query(conn,sql)\n",
    "    \n",
    "    # Define warehouse to use in Snowflake\n",
    "    sql = 'use warehouse {}'.format(warehouse)\n",
    "    execute_query(conn,sql)\n",
    "    \n",
    "    print('Successful Connection')\n",
    "    \n",
    "    # Query to Snowflake\n",
    "    sql = '''WITH EDIP AS ( //This is sub table for a self join\n",
    "\n",
    "    SELECT \n",
    "        *\n",
    "    FROM \"VESTA_DEVELOPMENT\".\"CLAIMS_REPORTING\".\"CTL_MEM_PROFILE_IP_ER_SNF\" //THIS NEEDS TO CHANGE BASED ON CLIENT\n",
    "    WHERE MEASURE = 'ED' or MEASURE = 'IP' \n",
    "\n",
    "    ),\n",
    "\n",
    "    EDIPTABLE AS ( //This table shows the Member ID, date start, and the number of ED/IP in the next 6 months\n",
    "\n",
    "    SELECT\n",
    "        SCORE.MEMBER_ID,\n",
    "        TO_DATE(CONCAT(LEFT(SCORE.DATA_DATE_START,4),'-',RIGHT(SCORE.DATA_DATE_START,2),'-01')) AS DATE_START,\n",
    "        COUNT(DISTINCT EDIP.DOS_FROM) AS ED_IP_VISITS_IN_NEXT_6_MONTHS\n",
    "    FROM \"VESTA_DEVELOPMENT\".\"ANALYST_SANDBOX\".\"CLNT_STRAT_VIP\" SCORE\n",
    "        LEFT JOIN EDIP \n",
    "            ON SCORE.MEMBER_ID = EDIP.MEMBER_ID\n",
    "                AND EDIP.DOS_FROM > TO_DATE(CONCAT(LEFT(SCORE.DATA_DATE_START,4),'-',RIGHT(SCORE.DATA_DATE_START,2),'-01'))\n",
    "                AND DATEDIFF(days,TO_DATE(CONCAT(LEFT(SCORE.DATA_DATE_START,4),'-',RIGHT(SCORE.DATA_DATE_START,2),'-01')),EDIP.DOS_FROM) >= 45\n",
    "                AND DATEDIFF(days, TO_DATE(CONCAT(LEFT(SCORE.DATA_DATE_START,4),'-',RIGHT(SCORE.DATA_DATE_START,2),'-01')),EDIP.DOS_FROM) <= 180\n",
    "    GROUP BY SCORE.MEMBER_ID,\n",
    "        DATE_START \n",
    "\n",
    "    )\n",
    "\n",
    "SELECT\n",
    "    //TO_DATE(CONCAT(LEFT(SCORE.DATA_DATE_START,4),'-',RIGHT(SCORE.DATA_DATE_START,2),'-01')) AS DATE_START,\n",
    "    //DATA_DATE_START,\n",
    "    //SCORE.MEMBER_ID,\n",
    "    CASE WHEN EDIPTABLE.ED_IP_VISITS_IN_NEXT_6_MONTHS > 0 THEN 1 ELSE 0 END as ED_IP_VISIT,\n",
    "    ACSC__COUNT,\n",
    "    ACSC__SCORE,\n",
    "    ACSC_A_FIB_AND_FLUTTER,\n",
    "    ACSC_ALCOHOL_RELATED,\n",
    "    ACSC_ANEMIA,\n",
    "    ACSC_ANGINA,\n",
    "    ACSC_ASTHMA,\n",
    "    ACSC_CELLULITIS,\n",
    "    ACSC_CONGESTIVE_HEART_FAILURE,\n",
    "    ACSC_CONSTIPATION,\n",
    "    ACSC_CONVULSION_EPILEPSY,\n",
    "    ACSC_COPD,\n",
    "    ACSC_DECUBITI_STAGE_3_,\n",
    "    ACSC_DEHYDRATION_GASTROENTERITIS,\n",
    "    ACSC_DIABETES_COMPLICATIONS,\n",
    "    ACSC_DYSPEPSIA,\n",
    "    ACSC_ENT_INFECTION,\n",
    "    ACSC_HYPERTENSION,\n",
    "    ACSC_HYPOGLYCEMIA,\n",
    "    ACSC_HYPOKALEMIA,\n",
    "    ACSC_INFLUENZA_PNEUMONIA,\n",
    "    ACSC_MIGRAINE_HEADACHE,\n",
    "    ACSC_NUTRITION_DEFICIENT,\n",
    "    ACSC_PERFORATED_BLEEDING_ULCER,\n",
    "    ACSC_PROXIMAL_FEMUR_FRACTURE,\n",
    "    ACSC_PYELONEPHRITIS,\n",
    "    ACSC_UTI,\n",
    "    ACSC_VACCINE_PREVENTABLE_DX,\n",
    "    DATEDIFF(year,DOB, TO_DATE(CONCAT(LEFT(SCORE.DATA_DATE_START,4),'-',RIGHT(SCORE.DATA_DATE_START,2),'-01'))) as AGE,\n",
    "    AMB_ACSC_COST,\n",
    "    AMB_ACSC_COUNT,\n",
    "    BH__COUNT,\n",
    "    BH__SCORE,\n",
    "    BH_ALTERED_MENTAL_STATE,\n",
    "    BH_ALZHEIMERS_DEMENTIA,\n",
    "    BH_ANXIETY,\n",
    "    BH_BI_POLAR,\n",
    "    BH_DEPRESSION,\n",
    "    BH_SCHIZOPHRENIA,\n",
    "    BH_SUBABUSE,\n",
    "    CRN__COUNT,\n",
    "    CRN_AFIB,\n",
    "    CRN_ASTHMA,\n",
    "    CRN_CARDIOVASCULAR_DX,\n",
    "    CRN_CHRONIC_KIDNEY_DISEASE,\n",
    "    CRN_CONGESTIVE_HEART_FAILURE,\n",
    "    CRN_COPD,\n",
    "    CRN_DIABETES_W__ACUTE_COMP,\n",
    "    CRN_DIABETES_W__CHRONIC_COMP,\n",
    "    CRN_DIABETES_W_OUT_COMP,\n",
    "    CRN_FALLS,\n",
    "    CRN_GASTRO_ESOPH_REFLUX,\n",
    "    CRN_HIP_FRACTURE,\n",
    "    CRN_HTN,\n",
    "    CRN_OBESITY,\n",
    "    CRN_OSTEOPOROSIS,\n",
    "    CRN_PARKINSONS_DISEASE,\n",
    "    CRN_PRESSURE_ULCER,\n",
    "    CRN_PRIOR_MI,\n",
    "    CRN_PRIOR_STROKE,\n",
    "    CRN_SCORE,\n",
    "    CRN_SLEEP_APNEA,\n",
    "    CRN_SMOKING,\n",
    "    CRN_UTI,\n",
    "    DYAD_CKD_DD,\n",
    "    DYAD_CKD_OP,\n",
    "    DYAD_COPD_DD,\n",
    "    DYAD_COPD_HF,\n",
    "    DYAD_COPD_OP,\n",
    "    DYAD_COUNT,\n",
    "    DYAD_DM_CKD,\n",
    "    DYAD_DM_OP,\n",
    "    DYAD_HBP_HF,\n",
    "    DYAD_HF_CKD,\n",
    "    ED_ACSC_COST,\n",
    "    ED_ACSC_COUNT,\n",
    "    GENDER,\n",
    "    CASE WHEN \"GROUP\" = 'E' THEN 'A' ELSE \"GROUP\" END as \"GROUP\",\n",
    "    HMKR_ACSC_COST,\n",
    "    HMKR_ACSC_COUNT,\n",
    "    HTI_RISK_SCORE_V2_1,\n",
    "    IP_ACSC_COST,\n",
    "    IP_ACSC_COUNT,\n",
    "    IP_READMIT_ACSC_COST,\n",
    "    IP_READMIT_ACSC_COUNT,\n",
    "    IP_RHB_ACSC_COST,\n",
    "    IP_RHB_ACSC_COUNT,\n",
    "    CASE WHEN LANGUAGE_SPOKEN is NULL THEN 'Unknown'\n",
    "         WHEN LANGUAGE_SPOKEN = 'English' THEN 'English'\n",
    "         WHEN LANGUAGE_SPOKEN = 'Chinese' THEN 'Chinese'\n",
    "         WHEN LANGUAGE_SPOKEN = 'Spanish' THEN 'Spanish'\n",
    "         WHEN LANGUAGE_SPOKEN = 'Russian' THEN 'Russian'\n",
    "    ELSE 'Other' END AS LANGUAGE_SPOKEN_CLEAN,\n",
    "    NI_COST_DENT,\n",
    "    NI_COST_ED,\n",
    "    NI_COST_HM,\n",
    "    NI_COST_HMKR,\n",
    "    NI_COST_HS,\n",
    "    NI_COST_IP,\n",
    "    NI_COST_IP_RHB,\n",
    "    NI_COST_OP,\n",
    "    NI_COST_OTH,\n",
    "    NI_COST_PCA_T1020,\n",
    "    NI_COST_PCA_T1019,\n",
    "    NI_COST_PR,\n",
    "    NI_COST_PSYC,\n",
    "    NI_COST_RX,\n",
    "    NI_COUNT_DENT,\n",
    "    NI_COUNT_ED,\n",
    "    NI_COUNT_HM,\n",
    "    NI_COUNT_HMKR,\n",
    "    NI_COUNT_HS,\n",
    "    NI_COUNT_IP,\n",
    "    NI_COUNT_IP_RHB,\n",
    "    NI_COUNT_OP,\n",
    "    NI_COUNT_OTH,\n",
    "    NI_COUNT_PCA_T1020,\n",
    "    NI_COUNT_PCA_T1019,\n",
    "    NI_COUNT_PR,\n",
    "    NI_COUNT_PSYC,\n",
    "    NI_COUNT_RX,\n",
    "    NON_IMPACTABLE_CLAIM_COUNT,\n",
    "    OP_ACSC_COST,\n",
    "    OP_ACSC_COUNT,\n",
    "    CAST(PART_C_RISK_SCORE as FLOAT) as PART_C_RISK_SCORE,\n",
    "    PCA_T1020_ACSC_COUNT,\n",
    "    PCA_T1020_ACSC_COST,\n",
    "    PCA_T1019_ACSC_COUNT,\n",
    "    PCA_T1019_ACSC_COST,\n",
    "    PR_ACSC_COST,\n",
    "    PR_ACSC_COUNT,\n",
    "    //CASE WHEN RC is NULL THEN 'UNDEFINED' ELSE RC END AS RC_CLEAN,\n",
    "    SNF_COST,\n",
    "    SNF_COUNT,\n",
    "    TOTAL_IMPACTABLE_COST,\n",
    "    TOTAL_IMPACTABLE_COST_PRO,\n",
    "    TOTAL_NON_IMPACTABLE_COST\n",
    "FROM \"VESTA_DEVELOPMENT\".\"ANALYST_SANDBOX\".\"CLNT_STRAT_VIP\" SCORE\n",
    "    LEFT JOIN EDIPTABLE\n",
    "        ON SCORE.MEMBER_ID = EDIPTABLE.MEMBER_ID\n",
    "            AND TO_DATE(CONCAT(LEFT(SCORE.DATA_DATE_START,4),'-',RIGHT(SCORE.DATA_DATE_START,2),'-01')) = EDIPTABLE.DATE_START\n",
    "WHERE SCORE.CLNT = 'CTL' //THIS NEEDS TO CHANGE BASED ON CLIENT\n",
    "    AND TO_DATE(CONCAT(LEFT(SCORE.DATA_DATE_START,4),'-',RIGHT(SCORE.DATA_DATE_START,2),'-01')) \n",
    "     between '2020-04-01' and TO_DATE(CONCAT(LEFT(CURRENT_DATE-210,7),'-01')) //This is looking at files that have had a reasonable amount of time to process'''\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(sql)\n",
    "    \n",
    "    # Dataframe creation\n",
    "    df = pd.DataFrame.from_records(iter(cursor), columns = [x[0] for x in cursor.description])\n",
    "    \n",
    "    print('Successful DataFrame Created')\n",
    "    \n",
    "    cursor.close\n",
    "    \n",
    "except Exception as e:\n",
    "        print(e)\n",
    "        \n",
    "finally:\n",
    "    conn.close\n",
    "    \n",
    "print('Ready for Cleaning')   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b3e1dd",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Cleaning Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "768b10d3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These are the features that initially had missing values within the data frame: \n",
      " ['ACSC_ALCOHOL_RELATED', 'ACSC_CELLULITIS', 'ACSC_ENT_INFECTION', 'ACSC_HYPOGLYCEMIA', 'ACSC_MIGRAINE_HEADACHE', 'ACSC_VACCINE_PREVENTABLE_DX', 'CRN_SMOKING', 'NI_COST_DENT', 'NI_COST_HMKR', 'NI_COST_HS', 'NI_COST_IP_RHB', 'NI_COST_PSYC', 'NI_COUNT_DENT', 'NI_COUNT_HMKR', 'NI_COUNT_HS', 'NI_COUNT_IP_RHB', 'NI_COUNT_PSYC'] \n",
      "\n",
      "\n",
      "These columns were dropped after because missing values were not corrected :\n",
      " [] \n",
      "\n",
      "\n",
      "These are the features that were converted to dummy variables: \n",
      " ['GENDER', 'GROUP', 'LANGUAGE_SPOKEN_CLEAN'] \n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "   ED_IP_VISIT  ACSC__COUNT  ACSC__SCORE  ACSC_A_FIB_AND_FLUTTER  \\\n0            0          0.0          0.0                     0.0   \n1            0          0.0          0.0                     0.0   \n2            0          0.0          0.0                     0.0   \n3            0          0.0          0.0                     0.0   \n4            0          0.0          0.0                     0.0   \n\n   ACSC_ALCOHOL_RELATED  ACSC_ANEMIA  ACSC_ANGINA  ACSC_ASTHMA  \\\n0                   0.0          0.0          0.0          0.0   \n1                   0.0          0.0          0.0          0.0   \n2                   0.0          0.0          0.0          0.0   \n3                   0.0          0.0          0.0          0.0   \n4                   0.0          0.0          0.0          0.0   \n\n   ACSC_CELLULITIS  ACSC_CONGESTIVE_HEART_FAILURE  ...  TOTAL_IMPACTABLE_COST  \\\n0              0.0                            0.0  ...                 1380.0   \n1              0.0                            0.0  ...                    0.0   \n2              0.0                            0.0  ...                    0.0   \n3              0.0                            0.0  ...                    0.0   \n4              0.0                            0.0  ...                    0.0   \n\n   TOTAL_IMPACTABLE_COST_PRO  TOTAL_NON_IMPACTABLE_COST  GENDER_M  GROUP_C  \\\n0                     8280.0                9279.009995         0        0   \n1                        0.0               13390.920036         1        0   \n2                        0.0               26807.569999         1        0   \n3                        0.0               47250.239999         0        0   \n4                        0.0               37442.380000         0        0   \n\n   GROUP_D  LANGUAGE_SPOKEN_CLEAN_English  LANGUAGE_SPOKEN_CLEAN_Other  \\\n0        1                              0                            0   \n1        1                              0                            1   \n2        1                              1                            0   \n3        1                              1                            0   \n4        1                              1                            0   \n\n   LANGUAGE_SPOKEN_CLEAN_Russian  LANGUAGE_SPOKEN_CLEAN_Spanish  \n0                              0                              0  \n1                              0                              0  \n2                              0                              0  \n3                              0                              0  \n4                              0                              0  \n\n[5 rows x 136 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ED_IP_VISIT</th>\n      <th>ACSC__COUNT</th>\n      <th>ACSC__SCORE</th>\n      <th>ACSC_A_FIB_AND_FLUTTER</th>\n      <th>ACSC_ALCOHOL_RELATED</th>\n      <th>ACSC_ANEMIA</th>\n      <th>ACSC_ANGINA</th>\n      <th>ACSC_ASTHMA</th>\n      <th>ACSC_CELLULITIS</th>\n      <th>ACSC_CONGESTIVE_HEART_FAILURE</th>\n      <th>...</th>\n      <th>TOTAL_IMPACTABLE_COST</th>\n      <th>TOTAL_IMPACTABLE_COST_PRO</th>\n      <th>TOTAL_NON_IMPACTABLE_COST</th>\n      <th>GENDER_M</th>\n      <th>GROUP_C</th>\n      <th>GROUP_D</th>\n      <th>LANGUAGE_SPOKEN_CLEAN_English</th>\n      <th>LANGUAGE_SPOKEN_CLEAN_Other</th>\n      <th>LANGUAGE_SPOKEN_CLEAN_Russian</th>\n      <th>LANGUAGE_SPOKEN_CLEAN_Spanish</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>1380.0</td>\n      <td>8280.0</td>\n      <td>9279.009995</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>13390.920036</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>26807.569999</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>47250.239999</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>37442.380000</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 136 columns</p>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find features with missing values\n",
    "sumdf = pd.DataFrame(df.isna().sum())\n",
    "\n",
    "features_to_drop = []\n",
    "for row in sumdf.iterrows():\n",
    "    if row[1][0] != 0:\n",
    "        features_to_drop.append(row[0])\n",
    "\n",
    "# Review features with missing values\n",
    "print('These are the features that initially had missing values within the data frame: \\n',features_to_drop,'\\n\\n')\n",
    "\n",
    "Nulls_to_correct = ['ACSC_ALCOHOL_RELATED',\n",
    "                    'ACSC_CELLULITIS',\n",
    "                    'ACSC_ENT_INFECTION',\n",
    "                    'ACSC_HYPOGLYCEMIA',\n",
    "                    'ACSC_MIGRAINE_HEADACHE',\n",
    "                    'ACSC_VACCINE_PREVENTABLE_DX',\n",
    "                    'BH_SUBABUSE',\n",
    "                    'CRN_SMOKING', \n",
    "                    'NI_COST_DENT',\n",
    "                    'NI_COST_HMKR',\n",
    "                    'NI_COST_HS',\n",
    "                    'NI_COST_IP_RHB',\n",
    "                    'NI_COST_PSYC',\n",
    "                    'NI_COUNT_DENT',\n",
    "                    'NI_COUNT_HMKR',\n",
    "                    'NI_COUNT_HS',\n",
    "                    'NI_COUNT_IP_RHB',\n",
    "                    'NI_COUNT_PSYC'] \n",
    "\n",
    "# Fill selected features with 0 value\n",
    "for col in Nulls_to_correct:\n",
    "    df[col] = df[col].fillna(0)\n",
    "    \n",
    "# Check for missing values and drop columns with missing values\n",
    "sumdf = pd.DataFrame(df.isna().sum())\n",
    "\n",
    "features_to_drop = []\n",
    "for row in sumdf.iterrows():\n",
    "    if row[1][0] != 0:\n",
    "        features_to_drop.append(row[0])\n",
    "\n",
    "print('These columns were dropped after because missing values were not corrected :\\n', features_to_drop,'\\n\\n')        \n",
    "df = df.drop(columns = features_to_drop)\n",
    "\n",
    "# Convert object datatypes to dummy variables\n",
    "object_list = []\n",
    "\n",
    "for col in df.columns:\n",
    "    if df[col].dtypes == 'object':\n",
    "        object_list.append(col)\n",
    "        \n",
    "print('These are the features that were converted to dummy variables: \\n',object_list,'\\n\\n')\n",
    "df = pd.get_dummies(df, columns = object_list, drop_first = True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c410a3ac",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Option to remove low variability features\n",
    "\n",
    "This block is here to run as optional pre-processing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "613b57d6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These are the features that were dropped because of low variability: \n",
      " ['HMKR_ACSC_COST', 'HMKR_ACSC_COUNT', 'IP_RHB_ACSC_COST', 'IP_RHB_ACSC_COUNT', 'NI_COST_DENT', 'NI_COST_HS', 'NI_COST_IP_RHB', 'NI_COST_PSYC', 'NI_COUNT_DENT', 'NI_COUNT_HS', 'NI_COUNT_IP_RHB', 'NI_COUNT_PSYC', 'PART_C_RISK_SCORE'] \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Drop low variability columns\n",
    "df_var = df.var()\n",
    "df.columns.to_list()\n",
    "\n",
    "features_to_drop = []\n",
    "\n",
    "for i in range(len(df.columns.to_list())):\n",
    "    #print(df.columns.to_list()[i],df_var[i])\n",
    "    if df_var[i] == 0 and df.columns.to_list()[i] != 'ED_IP_VISIT':\n",
    "        features_to_drop.append(df.columns.to_list()[i])\n",
    "\n",
    "        \n",
    "print('These are the features that were dropped because of low variability: \\n',features_to_drop,'\\n\\n')\n",
    "        \n",
    "df = df.drop(columns = features_to_drop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ad2786",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Spliting, Scaling, and SMOTE (Synthetic Minority Oversampling Technique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f0da78",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Split the data set\n",
    "X = df[[col for col in df.columns if col != 'ED_IP_VISIT']] #independent variables\n",
    "y = df[[col for col in df.columns if col == 'ED_IP_VISIT']] #dependent variable\n",
    "y = y.values.flatten()\n",
    "\n",
    "# Define MinMax Scaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Transform data\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Split X and y into training and testing sets\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.30, random_state = 2)\n",
    "\n",
    "# Smote for balancing the training data set\n",
    "smote = SMOTE(random_state = 2)\n",
    "X_train,y_train = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f0c9ab0",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Creating and Training Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1567d0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Create a Random Forest Classifier\n",
    "clf=RandomForestClassifier(n_estimators = 2000,min_samples_split = 2, min_samples_leaf = 1,\n",
    "                           max_depth = 50, bootstrap = False, n_jobs = -1,random_state = 2)\n",
    "\n",
    "# Train the model using the training sets\n",
    "clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "784162ce",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Reporting on Performace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5bfe15d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Create probabilities from the model on test data\n",
    "y_prob = clf.predict_proba(X_test)[:,1]\n",
    "\n",
    "# Store probabilites in Datafram for threshold analysis\n",
    "threshold_list = [0.05,0.1,0.15,0.2,0.25,0.3,0.35,0.4,0.45,0.5,0.55,0.6,0.65,.7,.75,.8,.85,.9,.95,.99]\n",
    "accuracy_list = []\n",
    "precision_list = []\n",
    "recall_list = []\n",
    "for threshold in threshold_list:\n",
    "    y_pred = [1 if result >= threshold else 0 for result in y_prob]\n",
    "   \n",
    "    #Calulating Metrics\n",
    "    accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "    precision = metrics.precision_score(y_test, y_pred)\n",
    "    recall = metrics.recall_score(y_test, y_pred)\n",
    "    \n",
    "    accuracy_list.append(accuracy)\n",
    "    precision_list.append(precision)\n",
    "    recall_list.append(recall)\n",
    "    \n",
    "    #print('Thereshold: ',threshold)\n",
    "    #print(\"Accuracy: \",accuracy)\n",
    "    #print(\"Precision: \",precision)\n",
    "    #print(\"Recall: \",recall)\n",
    "    \n",
    "metric_df = pd.DataFrame()\n",
    "metric_df['Threshold'] = threshold_list\n",
    "metric_df['Accuracy'] = accuracy_list\n",
    "metric_df['Precision'] = precision_list\n",
    "metric_df['Recall'] = recall_list\n",
    "metric_df['F1'] = (2 * metric_df['Precision'] * metric_df['Recall']) / (metric_df['Precision'] + metric_df['Recall'])\n",
    "metric_df['Acc + Recall'] = metric_df['Accuracy'] + metric_df['Recall']\n",
    "\n",
    "metric_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d06cf77",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Confusion Matrix for Threshold with Max Accuracy + Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23c6b62",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Find the max accuracy and recall from the Metric Table and corresponding Threshold\n",
    "threshold = metric_df[metric_df['Acc + Recall'] == metric_df['Acc + Recall'].max()]['Threshold'].item()\n",
    "\n",
    "y_pred = [1 if result >= threshold else 0 for result in y_prob]\n",
    "\n",
    "\n",
    "# Creating confusion maxtrix\n",
    "cnf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "\n",
    "%matplotlib inline\n",
    "class_names=[0,1]\n",
    "fig, ax = plt.subplots()\n",
    "tick_marks = np.arange(len(class_names))\n",
    "plt.xticks(tick_marks, class_names)\n",
    "plt.yticks(tick_marks, class_names)\n",
    "\n",
    "# Create heatmap\n",
    "sns.heatmap(pd.DataFrame(cnf_matrix), annot=True, cmap=\"YlGnBu\" ,fmt='g')\n",
    "ax.xaxis.set_label_position(\"top\")\n",
    "\n",
    "# Axis labels\n",
    "plt.tight_layout()\n",
    "plt.title('Confusion matrix', y=1.1)\n",
    "plt.ylabel('Actual label')\n",
    "plt.xlabel('Predicted label')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#Calulating Metrics\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "precision = metrics.precision_score(y_test, y_pred)\n",
    "recall = metrics.recall_score(y_test, y_pred)\n",
    "    \n",
    "print('Thereshold: ',threshold)\n",
    "print(\"Accuracy: \",accuracy)\n",
    "print(\"Precision: \",precision)\n",
    "print(\"Recall: \",recall)\n",
    "print('F1: ', (2*precision*recall)/(precision+recall))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "268cee6a",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### ROC and AUC and Precision-Recall Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9104e4ea",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = metrics.roc_curve(y_test,  y_prob)\n",
    "\n",
    "# Print(thresholds)\n",
    "auc = metrics.roc_auc_score(y_test, y_prob)\n",
    "plt.plot(fpr,tpr,label=\"data 1, auc=\"+str(auc))\n",
    "plt.plot([0, 1], [0, 1], color=\"red\", linestyle=\"--\")\n",
    "\n",
    "# Axis labels\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend()\n",
    "\n",
    "# Show the legend\n",
    "plt.legend(loc=4)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n",
    "# Calculate precision and recall for each threshold\n",
    "precision, recall, _ = metrics.precision_recall_curve(y_test, y_prob)\n",
    "\n",
    "# Calculate scores\n",
    "f1, auc = metrics.f1_score(y_test, y_pred), metrics.auc(recall, precision)\n",
    "\n",
    "# Plot the precision-recall curves\n",
    "no_skill = len(y_test[y_test==1]) / len(y_test)\n",
    "plt.plot([0, 1], [no_skill, no_skill], linestyle='--', label='No Skill')\n",
    "plt.plot(recall, precision, marker='.', label='Random Forest')\n",
    "\n",
    "# Axis labels\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "\n",
    "# Show the legend\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a0b258b",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Ensemble of Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2333ca29",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 65.96624636650085 seconds ---\n",
      "--- 77.43321371078491 seconds ---\n",
      "--- 88.6663110256195 seconds ---\n",
      "--- 89.03759837150574 seconds ---\n",
      "--- 114.11678290367126 seconds ---\n",
      "--- 125.84485483169556 seconds ---\n",
      "--- 81.84997344017029 seconds ---\n",
      "--- 132.92904615402222 seconds ---\n",
      "--- 169.39867186546326 seconds ---\n",
      "--- 176.89685106277466 seconds ---\n"
     ]
    }
   ],
   "source": [
    "forest_dict = {}\n",
    "\n",
    "for i in range(0,10):\n",
    "    start_time = time.time()\n",
    "    # Split the data set\n",
    "    X = df[[col for col in df.columns if col != 'ED_IP_VISIT']] #independent variables\n",
    "    y = df[[col for col in df.columns if col == 'ED_IP_VISIT']] #dependent variable\n",
    "    y = y.values.flatten()\n",
    "\n",
    "    # Define MinMax Scaler\n",
    "    scaler = MinMaxScaler()\n",
    "\n",
    "    # Transform data\n",
    "    X = scaler.fit_transform(X)\n",
    "\n",
    "    # Split X and y into training and testing sets\n",
    "    X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.30, random_state = i)\n",
    "\n",
    "    # Smote for balancing the training data set\n",
    "    smote = SMOTE(random_state = i)\n",
    "    X_train,y_train = smote.fit_resample(X_train, y_train)\n",
    "    \n",
    "    # Create a Random Forest Classifier\n",
    "    clf=RandomForestClassifier(n_estimators = 2000,min_samples_split = 2, min_samples_leaf = 1,\n",
    "                           max_depth = 50, bootstrap = False, n_jobs = -1,random_state = i)\n",
    "\n",
    "    # Train the model using the training sets\n",
    "    clf.fit(X_train,y_train)\n",
    "    \n",
    "    #Store Random Forest\n",
    "    forest_dict[i] = clf\n",
    "    \n",
    "    print( \"--- %s seconds ---\" % (time.time() - start_time))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af532778",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### New Query for Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "217ba951",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successful Connection\n",
      "Successful DataFrame Created\n",
      "Ready for Cleaning\n",
      "(4691, 134)\n"
     ]
    },
    {
     "data": {
      "text/plain": "  DATA_DATE_START MEMBER_ID  ED_IP_VISIT  ACSC__COUNT  ACSC__SCORE  \\\n0          202208     64831            0          1.0          2.0   \n1          202208     42200            0          0.0          0.0   \n2          202208     63267            0          1.0          2.0   \n3          202208     61800            0          0.0          0.0   \n4          202208     62297            0          0.0          0.0   \n\n   ACSC_A_FIB_AND_FLUTTER  ACSC_ALCOHOL_RELATED  ACSC_ANEMIA  ACSC_ANGINA  \\\n0                     0.0                   0.0          0.0          0.0   \n1                     0.0                   0.0          0.0          0.0   \n2                     0.0                   0.0          0.0          0.0   \n3                     0.0                   0.0          0.0          0.0   \n4                     0.0                   0.0          0.0          0.0   \n\n   ACSC_ASTHMA  ... PCA_T1020_ACSC_COST  PCA_T1019_ACSC_COUNT  \\\n0          0.0  ...                 0.0                   5.0   \n1          0.0  ...                 0.0                   0.0   \n2          0.0  ...                 0.0                   0.0   \n3          0.0  ...                 0.0                   0.0   \n4          0.0  ...                 0.0                   0.0   \n\n   PCA_T1019_ACSC_COST  PR_ACSC_COST  PR_ACSC_COUNT  SNF_COST  SNF_COUNT  \\\n0               2765.0        149.74            1.0      0.00        0.0   \n1                  0.0          0.00            0.0      0.00        0.0   \n2                  0.0          0.00            0.0      0.00        0.0   \n3                  0.0          0.00            0.0      0.00        0.0   \n4                  0.0          0.00            0.0     83.28        1.0   \n\n   TOTAL_IMPACTABLE_COST  TOTAL_IMPACTABLE_COST_PRO  TOTAL_NON_IMPACTABLE_COST  \n0                2914.74                    2914.74                6145.670000  \n1                1743.83                    1743.83                4181.949970  \n2               49602.73                   49602.73                6829.070001  \n3                   0.00                       0.00               24875.760030  \n4                  83.28                      83.28               17954.939998  \n\n[5 rows x 134 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>DATA_DATE_START</th>\n      <th>MEMBER_ID</th>\n      <th>ED_IP_VISIT</th>\n      <th>ACSC__COUNT</th>\n      <th>ACSC__SCORE</th>\n      <th>ACSC_A_FIB_AND_FLUTTER</th>\n      <th>ACSC_ALCOHOL_RELATED</th>\n      <th>ACSC_ANEMIA</th>\n      <th>ACSC_ANGINA</th>\n      <th>ACSC_ASTHMA</th>\n      <th>...</th>\n      <th>PCA_T1020_ACSC_COST</th>\n      <th>PCA_T1019_ACSC_COUNT</th>\n      <th>PCA_T1019_ACSC_COST</th>\n      <th>PR_ACSC_COST</th>\n      <th>PR_ACSC_COUNT</th>\n      <th>SNF_COST</th>\n      <th>SNF_COUNT</th>\n      <th>TOTAL_IMPACTABLE_COST</th>\n      <th>TOTAL_IMPACTABLE_COST_PRO</th>\n      <th>TOTAL_NON_IMPACTABLE_COST</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>202208</td>\n      <td>64831</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>5.0</td>\n      <td>2765.0</td>\n      <td>149.74</td>\n      <td>1.0</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>2914.74</td>\n      <td>2914.74</td>\n      <td>6145.670000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>202208</td>\n      <td>42200</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>1743.83</td>\n      <td>1743.83</td>\n      <td>4181.949970</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>202208</td>\n      <td>63267</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>49602.73</td>\n      <td>49602.73</td>\n      <td>6829.070001</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>202208</td>\n      <td>61800</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>24875.760030</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>202208</td>\n      <td>62297</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>83.28</td>\n      <td>1.0</td>\n      <td>83.28</td>\n      <td>83.28</td>\n      <td>17954.939998</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 134 columns</p>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating of parameters for securing connection to Snowflake\n",
    "# %store -r username\n",
    "# %store -r password\n",
    "# %store -r account\n",
    "\n",
    "username = 'jdriggers'\n",
    "password = 'Franklin2!77'\n",
    "account = 'vh83029.us-east-1'\n",
    "\n",
    "# Define warehouse, if necessary\n",
    "warehouse = 'DEVELOPER_BASIC'\n",
    "\n",
    "# Define Database, if not defined in SQL request\n",
    "#database = 'VESTA_STAGING'\n",
    "\n",
    "# Create connection object for Snowflake connection\n",
    "conn = sf.connect(user = username, password = password, account = account, warehouse = warehouse)\n",
    "\n",
    "# Execution function\n",
    "def execute_query(connection,query):\n",
    "    cursor = connection.cursor()\n",
    "    cursor.execute(query)\n",
    "    cursor.close\n",
    "\n",
    "try:\n",
    "    # If defining a database, uncomment code set and add database in connection parameter\n",
    "    #sql = 'use {}'.format(database)\n",
    "    #execute_query(conn,sql)\n",
    "    \n",
    "    # Define warehouse to use in Snowflake\n",
    "    sql = 'use warehouse {}'.format(warehouse)\n",
    "    execute_query(conn,sql)\n",
    "    \n",
    "    print('Successful Connection')\n",
    "    \n",
    "    # Query to Snowflake\n",
    "    sql = '''\n",
    "WITH EDIP AS ( //This is sub table for a self join\n",
    "\n",
    "    SELECT \n",
    "        *\n",
    "    FROM \"VESTA_DEVELOPMENT\".\"CLAIMS_REPORTING\".\"CTL_MEM_PROFILE_IP_ER_SNF\" //THIS NEEDS TO CHANGE BASED ON CLIENT\n",
    "    WHERE MEASURE = 'ED' or MEASURE = 'IP' \n",
    "\n",
    "    ),\n",
    "\n",
    "EDIPTABLE AS ( //This table shows the Member ID, date start, and the number of ED/IP in the next 6 months\n",
    "\n",
    "    SELECT\n",
    "        SCORE.MEMBER_ID,\n",
    "        TO_DATE(CONCAT(LEFT(SCORE.DATA_DATE_START,4),'-',RIGHT(SCORE.DATA_DATE_START,2),'-01')) AS DATE_START,\n",
    "        COUNT(DISTINCT EDIP.DOS_FROM) AS ED_IP_VISITS_IN_NEXT_6_MONTHS\n",
    "    FROM \"VESTA_DEVELOPMENT\".\"ANALYST_SANDBOX\".\"CLNT_STRAT_VIP\" SCORE\n",
    "        LEFT JOIN EDIP \n",
    "            ON SCORE.MEMBER_ID = EDIP.MEMBER_ID\n",
    "                AND EDIP.DOS_FROM > TO_DATE(CONCAT(LEFT(SCORE.DATA_DATE_START,4),'-',RIGHT(SCORE.DATA_DATE_START,2),'-01'))\n",
    "                AND DATEDIFF(days,TO_DATE(CONCAT(LEFT(SCORE.DATA_DATE_START,4),'-',RIGHT(SCORE.DATA_DATE_START,2),'-01')),EDIP.DOS_FROM) >= 45\n",
    "                AND DATEDIFF(days, TO_DATE(CONCAT(LEFT(SCORE.DATA_DATE_START,4),'-',RIGHT(SCORE.DATA_DATE_START,2),'-01')),EDIP.DOS_FROM) <= 180\n",
    "    GROUP BY SCORE.MEMBER_ID,\n",
    "        DATE_START \n",
    "\n",
    "    )\n",
    "\n",
    "SELECT\n",
    "    //TO_DATE(CONCAT(LEFT(SCORE.DATA_DATE_START,4),'-',RIGHT(SCORE.DATA_DATE_START,2),'-01')) AS DATE_START,\n",
    "    DATA_DATE_START,\n",
    "    SCORE.MEMBER_ID,\n",
    "    CASE WHEN EDIPTABLE.ED_IP_VISITS_IN_NEXT_6_MONTHS > 0 THEN 1 ELSE 0 END as ED_IP_VISIT,\n",
    "    ACSC__COUNT,\n",
    "    ACSC__SCORE,\n",
    "    ACSC_A_FIB_AND_FLUTTER,\n",
    "    ACSC_ALCOHOL_RELATED,\n",
    "    ACSC_ANEMIA,\n",
    "    ACSC_ANGINA,\n",
    "    ACSC_ASTHMA,\n",
    "    ACSC_CELLULITIS,\n",
    "    ACSC_CONGESTIVE_HEART_FAILURE,\n",
    "    ACSC_CONSTIPATION,\n",
    "    ACSC_CONVULSION_EPILEPSY,\n",
    "    ACSC_COPD,\n",
    "    ACSC_DECUBITI_STAGE_3_,\n",
    "    ACSC_DEHYDRATION_GASTROENTERITIS,\n",
    "    ACSC_DIABETES_COMPLICATIONS,\n",
    "    ACSC_DYSPEPSIA,\n",
    "    ACSC_ENT_INFECTION,\n",
    "    ACSC_HYPERTENSION,\n",
    "    ACSC_HYPOGLYCEMIA,\n",
    "    ACSC_HYPOKALEMIA,\n",
    "    ACSC_INFLUENZA_PNEUMONIA,\n",
    "    ACSC_MIGRAINE_HEADACHE,\n",
    "    ACSC_NUTRITION_DEFICIENT,\n",
    "    ACSC_PERFORATED_BLEEDING_ULCER,\n",
    "    ACSC_PROXIMAL_FEMUR_FRACTURE,\n",
    "    ACSC_PYELONEPHRITIS,\n",
    "    ACSC_UTI,\n",
    "    ACSC_VACCINE_PREVENTABLE_DX,\n",
    "    DATEDIFF(year,DOB, TO_DATE(CONCAT(LEFT(SCORE.DATA_DATE_START,4),'-',RIGHT(SCORE.DATA_DATE_START,2),'-01'))) as AGE,\n",
    "    AMB_ACSC_COST,\n",
    "    AMB_ACSC_COUNT,\n",
    "    BH__COUNT,\n",
    "    BH__SCORE,\n",
    "    BH_ALTERED_MENTAL_STATE,\n",
    "    BH_ALZHEIMERS_DEMENTIA,\n",
    "    BH_ANXIETY,\n",
    "    BH_BI_POLAR,\n",
    "    BH_DEPRESSION,\n",
    "    BH_SCHIZOPHRENIA,\n",
    "    BH_SUBABUSE,\n",
    "    CRN__COUNT,\n",
    "    CRN_AFIB,\n",
    "    CRN_ASTHMA,\n",
    "    CRN_CARDIOVASCULAR_DX,\n",
    "    CRN_CHRONIC_KIDNEY_DISEASE,\n",
    "    CRN_CONGESTIVE_HEART_FAILURE,\n",
    "    CRN_COPD,\n",
    "    CRN_DIABETES_W__ACUTE_COMP,\n",
    "    CRN_DIABETES_W__CHRONIC_COMP,\n",
    "    CRN_DIABETES_W_OUT_COMP,\n",
    "    CRN_FALLS,\n",
    "    CRN_GASTRO_ESOPH_REFLUX,\n",
    "    CRN_HIP_FRACTURE,\n",
    "    CRN_HTN,\n",
    "    CRN_OBESITY,\n",
    "    CRN_OSTEOPOROSIS,\n",
    "    CRN_PARKINSONS_DISEASE,\n",
    "    CRN_PRESSURE_ULCER,\n",
    "    CRN_PRIOR_MI,\n",
    "    CRN_PRIOR_STROKE,\n",
    "    CRN_SCORE,\n",
    "    CRN_SLEEP_APNEA,\n",
    "    CRN_SMOKING,\n",
    "    CRN_UTI,\n",
    "    DYAD_CKD_DD,\n",
    "    DYAD_CKD_OP,\n",
    "    DYAD_COPD_DD,\n",
    "    DYAD_COPD_HF,\n",
    "    DYAD_COPD_OP,\n",
    "    DYAD_COUNT,\n",
    "    DYAD_DM_CKD,\n",
    "    DYAD_DM_OP,\n",
    "    DYAD_HBP_HF,\n",
    "    DYAD_HF_CKD,\n",
    "    ED_ACSC_COST,\n",
    "    ED_ACSC_COUNT,\n",
    "    GENDER,\n",
    "    CASE WHEN \"GROUP\" = 'E' THEN 'A' ELSE \"GROUP\" END as \"GROUP\",\n",
    "    HMKR_ACSC_COST,\n",
    "    HMKR_ACSC_COUNT,\n",
    "    HTI_RISK_SCORE_V2_1,\n",
    "    IP_ACSC_COST,\n",
    "    IP_ACSC_COUNT,\n",
    "    IP_READMIT_ACSC_COST,\n",
    "    IP_READMIT_ACSC_COUNT,\n",
    "    IP_RHB_ACSC_COST,\n",
    "    IP_RHB_ACSC_COUNT,\n",
    "    CASE WHEN LANGUAGE_SPOKEN is NULL THEN 'Unknown'\n",
    "         WHEN LANGUAGE_SPOKEN = 'English' THEN 'English'\n",
    "         WHEN LANGUAGE_SPOKEN = 'Chinese' THEN 'Chinese'\n",
    "         WHEN LANGUAGE_SPOKEN = 'Spanish' THEN 'Spanish'\n",
    "         WHEN LANGUAGE_SPOKEN = 'Russian' THEN 'Russian'\n",
    "    ELSE 'Other' END AS LANGUAGE_SPOKEN_CLEAN,\n",
    "    NI_COST_DENT,\n",
    "    NI_COST_ED,\n",
    "    NI_COST_HM,\n",
    "    NI_COST_HMKR,\n",
    "    NI_COST_HS,\n",
    "    NI_COST_IP,\n",
    "    NI_COST_IP_RHB,\n",
    "    NI_COST_OP,\n",
    "    NI_COST_OTH,\n",
    "    NI_COST_PCA_T1020,\n",
    "    NI_COST_PCA_T1019,\n",
    "    NI_COST_PR,\n",
    "    NI_COST_PSYC,\n",
    "    NI_COST_RX,\n",
    "    NI_COUNT_DENT,\n",
    "    NI_COUNT_ED,\n",
    "    NI_COUNT_HM,\n",
    "    NI_COUNT_HMKR,\n",
    "    NI_COUNT_HS,\n",
    "    NI_COUNT_IP,\n",
    "    NI_COUNT_IP_RHB,\n",
    "    NI_COUNT_OP,\n",
    "    NI_COUNT_OTH,\n",
    "    NI_COUNT_PCA_T1020,\n",
    "    NI_COUNT_PCA_T1019,\n",
    "    NI_COUNT_PR,\n",
    "    NI_COUNT_PSYC,\n",
    "    NI_COUNT_RX,\n",
    "    NON_IMPACTABLE_CLAIM_COUNT,\n",
    "    OP_ACSC_COST,\n",
    "    OP_ACSC_COUNT,\n",
    "    CAST(PART_C_RISK_SCORE as FLOAT) as PART_C_RISK_SCORE,\n",
    "    PCA_T1020_ACSC_COUNT,\n",
    "    PCA_T1020_ACSC_COST,\n",
    "    PCA_T1019_ACSC_COUNT,\n",
    "    PCA_T1019_ACSC_COST,\n",
    "    PR_ACSC_COST,\n",
    "    PR_ACSC_COUNT,\n",
    "    //CASE WHEN RC is NULL THEN 'UNDEFINED' ELSE RC END AS RC_CLEAN,\n",
    "    SNF_COST,\n",
    "    SNF_COUNT,\n",
    "    TOTAL_IMPACTABLE_COST,\n",
    "    TOTAL_IMPACTABLE_COST_PRO,\n",
    "    TOTAL_NON_IMPACTABLE_COST\n",
    "FROM \"VESTA_DEVELOPMENT\".\"ANALYST_SANDBOX\".\"CLNT_STRAT_VIP\" SCORE\n",
    "    LEFT JOIN EDIPTABLE\n",
    "        ON SCORE.MEMBER_ID = EDIPTABLE.MEMBER_ID\n",
    "            AND TO_DATE(CONCAT(LEFT(SCORE.DATA_DATE_START,4),'-',RIGHT(SCORE.DATA_DATE_START,2),'-01')) = EDIPTABLE.DATE_START\n",
    "WHERE SCORE.CLNT = 'CTL' //THIS NEEDS TO CHANGE BASED ON CLIENT\n",
    "    AND TO_DATE(CONCAT(LEFT(SCORE.DATA_DATE_START,4),'-',RIGHT(SCORE.DATA_DATE_START,2),'-01')) \n",
    "        = (SELECT max(TO_DATE(CONCAT(LEFT(DATA_DATE_START,4),'-',RIGHT(DATA_DATE_START,2),'-01'))) FROM \"VESTA_DEVELOPMENT\".\"ANALYST_SANDBOX\".\"CLNT_STRAT_VIP\" WHERE CLNT = 'CTL') \n",
    "        // Most Recent Stratification for Client// THIS NEEDS TO CHANGE BASED ON CLIENT'''\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(sql)\n",
    "    \n",
    "    # Dataframe creation\n",
    "    test_df = pd.DataFrame.from_records(iter(cursor), columns = [x[0] for x in cursor.description])\n",
    "    \n",
    "    print('Successful DataFrame Created')\n",
    "    \n",
    "    cursor.close\n",
    "    \n",
    "except Exception as e:\n",
    "        print(e)\n",
    "        \n",
    "finally:\n",
    "    conn.close\n",
    "    \n",
    "print('Ready for Cleaning')  \n",
    "\n",
    "print(test_df.shape)\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4aa4a7c",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Cleaning Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d225202e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These are the features that initially had missing values within the data frame: \n",
      " ['ACSC_CELLULITIS', 'ACSC_HYPOGLYCEMIA', 'ACSC_MIGRAINE_HEADACHE', 'ACSC_VACCINE_PREVENTABLE_DX', 'NI_COST_DENT', 'NI_COST_HMKR', 'NI_COST_IP_RHB', 'NI_COST_PSYC', 'NI_COUNT_DENT', 'NI_COUNT_HMKR', 'NI_COUNT_IP_RHB', 'NI_COUNT_PSYC'] \n",
      "\n",
      "\n",
      "These columns were dropped after because missing values were not corrected :\n",
      " [] \n",
      "\n",
      "\n",
      "These are the features that were converted to dummy variables: \n",
      " ['GENDER', 'GROUP', 'LANGUAGE_SPOKEN_CLEAN'] \n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "   ACSC__COUNT  ACSC__SCORE  ACSC_A_FIB_AND_FLUTTER  ACSC_ALCOHOL_RELATED  \\\n0          1.0          2.0                     0.0                   0.0   \n1          0.0          0.0                     0.0                   0.0   \n2          1.0          2.0                     0.0                   0.0   \n3          0.0          0.0                     0.0                   0.0   \n4          0.0          0.0                     0.0                   0.0   \n\n   ACSC_ANEMIA  ACSC_ANGINA  ACSC_ASTHMA  ACSC_CELLULITIS  \\\n0          0.0          0.0          0.0                0   \n1          0.0          0.0          0.0                0   \n2          0.0          0.0          0.0                0   \n3          0.0          0.0          0.0                0   \n4          0.0          0.0          0.0                0   \n\n   ACSC_CONGESTIVE_HEART_FAILURE  ACSC_CONSTIPATION  ...  \\\n0                            0.0                0.0  ...   \n1                            0.0                0.0  ...   \n2                            0.0                0.0  ...   \n3                            0.0                0.0  ...   \n4                            0.0                0.0  ...   \n\n   TOTAL_IMPACTABLE_COST  TOTAL_IMPACTABLE_COST_PRO  \\\n0                2914.74                    2914.74   \n1                1743.83                    1743.83   \n2               49602.73                   49602.73   \n3                   0.00                       0.00   \n4                  83.28                      83.28   \n\n   TOTAL_NON_IMPACTABLE_COST  GENDER_M  GROUP_C  GROUP_D  \\\n0                6145.670000         1        0        1   \n1                4181.949970         0        0        1   \n2                6829.070001         1        0        0   \n3               24875.760030         1        0        1   \n4               17954.939998         0        0        1   \n\n   LANGUAGE_SPOKEN_CLEAN_English  LANGUAGE_SPOKEN_CLEAN_Other  \\\n0                              1                            0   \n1                              1                            0   \n2                              1                            0   \n3                              1                            0   \n4                              1                            0   \n\n   LANGUAGE_SPOKEN_CLEAN_Russian  LANGUAGE_SPOKEN_CLEAN_Spanish  \n0                              0                              0  \n1                              0                              0  \n2                              0                              0  \n3                              0                              0  \n4                              0                              0  \n\n[5 rows x 135 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ACSC__COUNT</th>\n      <th>ACSC__SCORE</th>\n      <th>ACSC_A_FIB_AND_FLUTTER</th>\n      <th>ACSC_ALCOHOL_RELATED</th>\n      <th>ACSC_ANEMIA</th>\n      <th>ACSC_ANGINA</th>\n      <th>ACSC_ASTHMA</th>\n      <th>ACSC_CELLULITIS</th>\n      <th>ACSC_CONGESTIVE_HEART_FAILURE</th>\n      <th>ACSC_CONSTIPATION</th>\n      <th>...</th>\n      <th>TOTAL_IMPACTABLE_COST</th>\n      <th>TOTAL_IMPACTABLE_COST_PRO</th>\n      <th>TOTAL_NON_IMPACTABLE_COST</th>\n      <th>GENDER_M</th>\n      <th>GROUP_C</th>\n      <th>GROUP_D</th>\n      <th>LANGUAGE_SPOKEN_CLEAN_English</th>\n      <th>LANGUAGE_SPOKEN_CLEAN_Other</th>\n      <th>LANGUAGE_SPOKEN_CLEAN_Russian</th>\n      <th>LANGUAGE_SPOKEN_CLEAN_Spanish</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>2914.74</td>\n      <td>2914.74</td>\n      <td>6145.670000</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>1743.83</td>\n      <td>1743.83</td>\n      <td>4181.949970</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>49602.73</td>\n      <td>49602.73</td>\n      <td>6829.070001</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>24875.760030</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>83.28</td>\n      <td>83.28</td>\n      <td>17954.939998</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 135 columns</p>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove Member ID and Data Start Date from Data Frame for prediction\n",
    "data_date_start_list = test_df['DATA_DATE_START']\n",
    "test_df = test_df.drop(['DATA_DATE_START'], axis = 1)\n",
    "member_id_list = test_df['MEMBER_ID']\n",
    "test_df = test_df.drop(['MEMBER_ID'], axis = 1)\n",
    "\n",
    "#Remove ED_Visit from Data Frame\n",
    "y_test_df = test_df['ED_IP_VISIT']\n",
    "test_df = test_df.drop(['ED_IP_VISIT'], axis = 1)\n",
    "\n",
    "# Find features with missing values\n",
    "sumdf = pd.DataFrame(test_df.isna().sum())\n",
    "\n",
    "features_to_drop = []\n",
    "for row in sumdf.iterrows():\n",
    "    if row[1][0] != 0:\n",
    "        features_to_drop.append(row[0])\n",
    "\n",
    "# Review features with missing values\n",
    "print('These are the features that initially had missing values within the data frame: \\n',features_to_drop,'\\n\\n')\n",
    "\n",
    "Nulls_to_correct = ['ACSC_ALCOHOL_RELATED',\n",
    "                    'ACSC_CELLULITIS',\n",
    "                    'ACSC_ENT_INFECTION',\n",
    "                    'ACSC_HYPOGLYCEMIA',\n",
    "                    'ACSC_MIGRAINE_HEADACHE',\n",
    "                    'ACSC_VACCINE_PREVENTABLE_DX',\n",
    "                    'BH_SUBABUSE',\n",
    "                    'CRN_SMOKING',\n",
    "                    'CRN_PRIOR_MI',\n",
    "                    'NI_COST_DENT',\n",
    "                    'NI_COST_HMKR',\n",
    "                    'NI_COST_HS',\n",
    "                    'NI_COST_IP_RHB',\n",
    "                    'NI_COST_PSYC',\n",
    "                    'NI_COUNT_DENT',\n",
    "                    'NI_COUNT_HMKR',\n",
    "                    'NI_COUNT_HS',\n",
    "                    'NI_COUNT_IP_RHB',\n",
    "                    'NI_COUNT_PSYC'] \n",
    "\n",
    "# Fill selected features with 0 value\n",
    "for col in Nulls_to_correct:\n",
    "    test_df[col] = test_df[col].fillna(0)\n",
    "    \n",
    "# Check for missing values and drop columns with missing values\n",
    "sumdf = pd.DataFrame(test_df.isna().sum())\n",
    "\n",
    "features_to_drop = []\n",
    "for row in sumdf.iterrows():\n",
    "    if row[1][0] != 0:\n",
    "        features_to_drop.append(row[0])\n",
    "\n",
    "print('These columns were dropped after because missing values were not corrected :\\n', features_to_drop,'\\n\\n')        \n",
    "test_df = test_df.drop(columns = features_to_drop)\n",
    "\n",
    "# Convert object datatypes to dummy variables\n",
    "object_list = []\n",
    "\n",
    "for col in test_df.columns:\n",
    "    if test_df[col].dtypes == 'object':\n",
    "        object_list.append(col)\n",
    "        \n",
    "print('These are the features that were converted to dummy variables: \\n',object_list,'\\n\\n')\n",
    "test_df = pd.get_dummies(test_df, columns = object_list, drop_first = True)\n",
    "\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5bdb77d0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "   ACSC__COUNT  ACSC__SCORE  ACSC_A_FIB_AND_FLUTTER  ACSC_ALCOHOL_RELATED  \\\n0          1.0          2.0                     0.0                   0.0   \n1          0.0          0.0                     0.0                   0.0   \n2          1.0          2.0                     0.0                   0.0   \n3          0.0          0.0                     0.0                   0.0   \n4          0.0          0.0                     0.0                   0.0   \n\n   ACSC_ANEMIA  ACSC_ANGINA  ACSC_ASTHMA  ACSC_CELLULITIS  \\\n0          0.0          0.0          0.0                0   \n1          0.0          0.0          0.0                0   \n2          0.0          0.0          0.0                0   \n3          0.0          0.0          0.0                0   \n4          0.0          0.0          0.0                0   \n\n   ACSC_CONGESTIVE_HEART_FAILURE  ACSC_CONSTIPATION  ...  \\\n0                            0.0                0.0  ...   \n1                            0.0                0.0  ...   \n2                            0.0                0.0  ...   \n3                            0.0                0.0  ...   \n4                            0.0                0.0  ...   \n\n   TOTAL_IMPACTABLE_COST  TOTAL_IMPACTABLE_COST_PRO  \\\n0                2914.74                    2914.74   \n1                1743.83                    1743.83   \n2               49602.73                   49602.73   \n3                   0.00                       0.00   \n4                  83.28                      83.28   \n\n   TOTAL_NON_IMPACTABLE_COST  GENDER_M  GROUP_C  GROUP_D  \\\n0                6145.670000         1        0        1   \n1                4181.949970         0        0        1   \n2                6829.070001         1        0        0   \n3               24875.760030         1        0        1   \n4               17954.939998         0        0        1   \n\n   LANGUAGE_SPOKEN_CLEAN_English  LANGUAGE_SPOKEN_CLEAN_Other  \\\n0                              1                            0   \n1                              1                            0   \n2                              1                            0   \n3                              1                            0   \n4                              1                            0   \n\n   LANGUAGE_SPOKEN_CLEAN_Russian  LANGUAGE_SPOKEN_CLEAN_Spanish  \n0                              0                              0  \n1                              0                              0  \n2                              0                              0  \n3                              0                              0  \n4                              0                              0  \n\n[5 rows x 122 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ACSC__COUNT</th>\n      <th>ACSC__SCORE</th>\n      <th>ACSC_A_FIB_AND_FLUTTER</th>\n      <th>ACSC_ALCOHOL_RELATED</th>\n      <th>ACSC_ANEMIA</th>\n      <th>ACSC_ANGINA</th>\n      <th>ACSC_ASTHMA</th>\n      <th>ACSC_CELLULITIS</th>\n      <th>ACSC_CONGESTIVE_HEART_FAILURE</th>\n      <th>ACSC_CONSTIPATION</th>\n      <th>...</th>\n      <th>TOTAL_IMPACTABLE_COST</th>\n      <th>TOTAL_IMPACTABLE_COST_PRO</th>\n      <th>TOTAL_NON_IMPACTABLE_COST</th>\n      <th>GENDER_M</th>\n      <th>GROUP_C</th>\n      <th>GROUP_D</th>\n      <th>LANGUAGE_SPOKEN_CLEAN_English</th>\n      <th>LANGUAGE_SPOKEN_CLEAN_Other</th>\n      <th>LANGUAGE_SPOKEN_CLEAN_Russian</th>\n      <th>LANGUAGE_SPOKEN_CLEAN_Spanish</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>2914.74</td>\n      <td>2914.74</td>\n      <td>6145.670000</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>1743.83</td>\n      <td>1743.83</td>\n      <td>4181.949970</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>49602.73</td>\n      <td>49602.73</td>\n      <td>6829.070001</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>24875.760030</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>83.28</td>\n      <td>83.28</td>\n      <td>17954.939998</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 122 columns</p>\n</div>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_to_drop = ['HMKR_ACSC_COST', 'HMKR_ACSC_COUNT', 'IP_RHB_ACSC_COST', \n",
    "                    'IP_RHB_ACSC_COUNT', 'NI_COST_DENT', 'NI_COST_HS', 'NI_COST_IP_RHB', \n",
    "                    'NI_COST_PSYC', 'NI_COUNT_DENT', 'NI_COUNT_HS', 'NI_COUNT_IP_RHB', 'NI_COUNT_PSYC','PART_C_RISK_SCORE']\n",
    "\n",
    " \n",
    "test_df = test_df.drop(columns = features_to_drop)\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5d667e37",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Scale data for prediction with original model\n",
    "X = test_df\n",
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "13063e2d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 0.9848787784576416 seconds ---\n",
      "--- 1.766463041305542 seconds ---\n",
      "--- 6.207555770874023 seconds ---\n",
      "--- 8.324062585830688 seconds ---\n",
      "--- 5.883327007293701 seconds ---\n",
      "--- 1.9664580821990967 seconds ---\n",
      "--- 2.332198143005371 seconds ---\n",
      "--- 1.1793632507324219 seconds ---\n",
      "--- 1.0218150615692139 seconds ---\n",
      "--- 3.4029698371887207 seconds ---\n"
     ]
    },
    {
     "data": {
      "text/plain": "            1         2         3         4         5         6         7   \\\n0     0.408000  0.405500  0.410000  0.405000  0.396000  0.406500  0.411500   \n1     0.379500  0.385000  0.416500  0.440000  0.398500  0.467500  0.373500   \n2     0.375000  0.403500  0.393500  0.423500  0.432000  0.406000  0.431000   \n3     0.155000  0.206000  0.152500  0.198500  0.171500  0.228000  0.157000   \n4     0.574500  0.524500  0.522500  0.559500  0.492500  0.636000  0.488500   \n...        ...       ...       ...       ...       ...       ...       ...   \n4686  0.248000  0.265000  0.233000  0.291000  0.166500  0.202500  0.319000   \n4687  0.365000  0.368898  0.368375  0.419500  0.383000  0.362000  0.372500   \n4688  0.375683  0.388681  0.389468  0.339825  0.363918  0.373310  0.392877   \n4689  0.447500  0.339487  0.299000  0.397500  0.366500  0.416000  0.257000   \n4690  0.207500  0.259500  0.251000  0.219350  0.298500  0.237786  0.235500   \n\n            8         9         10  \n0     0.389500  0.393500  0.407500  \n1     0.392000  0.387000  0.409500  \n2     0.417500  0.400000  0.354000  \n3     0.188500  0.152500  0.160000  \n4     0.495500  0.491000  0.557000  \n...        ...       ...       ...  \n4686  0.217167  0.200077  0.262500  \n4687  0.374500  0.390500  0.382500  \n4688  0.369819  0.371783  0.355431  \n4689  0.353000  0.413000  0.409500  \n4690  0.228000  0.258000  0.240460  \n\n[4691 rows x 10 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>10</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.408000</td>\n      <td>0.405500</td>\n      <td>0.410000</td>\n      <td>0.405000</td>\n      <td>0.396000</td>\n      <td>0.406500</td>\n      <td>0.411500</td>\n      <td>0.389500</td>\n      <td>0.393500</td>\n      <td>0.407500</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.379500</td>\n      <td>0.385000</td>\n      <td>0.416500</td>\n      <td>0.440000</td>\n      <td>0.398500</td>\n      <td>0.467500</td>\n      <td>0.373500</td>\n      <td>0.392000</td>\n      <td>0.387000</td>\n      <td>0.409500</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.375000</td>\n      <td>0.403500</td>\n      <td>0.393500</td>\n      <td>0.423500</td>\n      <td>0.432000</td>\n      <td>0.406000</td>\n      <td>0.431000</td>\n      <td>0.417500</td>\n      <td>0.400000</td>\n      <td>0.354000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.155000</td>\n      <td>0.206000</td>\n      <td>0.152500</td>\n      <td>0.198500</td>\n      <td>0.171500</td>\n      <td>0.228000</td>\n      <td>0.157000</td>\n      <td>0.188500</td>\n      <td>0.152500</td>\n      <td>0.160000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.574500</td>\n      <td>0.524500</td>\n      <td>0.522500</td>\n      <td>0.559500</td>\n      <td>0.492500</td>\n      <td>0.636000</td>\n      <td>0.488500</td>\n      <td>0.495500</td>\n      <td>0.491000</td>\n      <td>0.557000</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>4686</th>\n      <td>0.248000</td>\n      <td>0.265000</td>\n      <td>0.233000</td>\n      <td>0.291000</td>\n      <td>0.166500</td>\n      <td>0.202500</td>\n      <td>0.319000</td>\n      <td>0.217167</td>\n      <td>0.200077</td>\n      <td>0.262500</td>\n    </tr>\n    <tr>\n      <th>4687</th>\n      <td>0.365000</td>\n      <td>0.368898</td>\n      <td>0.368375</td>\n      <td>0.419500</td>\n      <td>0.383000</td>\n      <td>0.362000</td>\n      <td>0.372500</td>\n      <td>0.374500</td>\n      <td>0.390500</td>\n      <td>0.382500</td>\n    </tr>\n    <tr>\n      <th>4688</th>\n      <td>0.375683</td>\n      <td>0.388681</td>\n      <td>0.389468</td>\n      <td>0.339825</td>\n      <td>0.363918</td>\n      <td>0.373310</td>\n      <td>0.392877</td>\n      <td>0.369819</td>\n      <td>0.371783</td>\n      <td>0.355431</td>\n    </tr>\n    <tr>\n      <th>4689</th>\n      <td>0.447500</td>\n      <td>0.339487</td>\n      <td>0.299000</td>\n      <td>0.397500</td>\n      <td>0.366500</td>\n      <td>0.416000</td>\n      <td>0.257000</td>\n      <td>0.353000</td>\n      <td>0.413000</td>\n      <td>0.409500</td>\n    </tr>\n    <tr>\n      <th>4690</th>\n      <td>0.207500</td>\n      <td>0.259500</td>\n      <td>0.251000</td>\n      <td>0.219350</td>\n      <td>0.298500</td>\n      <td>0.237786</td>\n      <td>0.235500</td>\n      <td>0.228000</td>\n      <td>0.258000</td>\n      <td>0.240460</td>\n    </tr>\n  </tbody>\n</table>\n<p>4691 rows × 10 columns</p>\n</div>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create Data Frame to store results\n",
    "model_df = pd.DataFrame()\n",
    "\n",
    "for i,clf in forest_dict.items():\n",
    "    start_time = time.time()\n",
    "    np.random.seed(i)\n",
    "    model_df[i+1] = clf.predict_proba(X)[:,1]\n",
    "    print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "model_df  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f9b11203",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "             1         2         3         4         5         6         7  \\\n0     0.408000  0.405500  0.410000  0.405000  0.396000  0.406500  0.411500   \n1     0.379500  0.385000  0.416500  0.440000  0.398500  0.467500  0.373500   \n2     0.375000  0.403500  0.393500  0.423500  0.432000  0.406000  0.431000   \n3     0.155000  0.206000  0.152500  0.198500  0.171500  0.228000  0.157000   \n4     0.574500  0.524500  0.522500  0.559500  0.492500  0.636000  0.488500   \n...        ...       ...       ...       ...       ...       ...       ...   \n4686  0.248000  0.265000  0.233000  0.291000  0.166500  0.202500  0.319000   \n4687  0.365000  0.368898  0.368375  0.419500  0.383000  0.362000  0.372500   \n4688  0.375683  0.388681  0.389468  0.339825  0.363918  0.373310  0.392877   \n4689  0.447500  0.339487  0.299000  0.397500  0.366500  0.416000  0.257000   \n4690  0.207500  0.259500  0.251000  0.219350  0.298500  0.237786  0.235500   \n\n             8         9        10  VIP_SCORE  \n0     0.389500  0.393500  0.407500   0.403300  \n1     0.392000  0.387000  0.409500   0.404900  \n2     0.417500  0.400000  0.354000   0.403600  \n3     0.188500  0.152500  0.160000   0.176950  \n4     0.495500  0.491000  0.557000   0.534150  \n...        ...       ...       ...        ...  \n4686  0.217167  0.200077  0.262500   0.240474  \n4687  0.374500  0.390500  0.382500   0.378677  \n4688  0.369819  0.371783  0.355431   0.372080  \n4689  0.353000  0.413000  0.409500   0.369849  \n4690  0.228000  0.258000  0.240460   0.243560  \n\n[4691 rows x 11 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>10</th>\n      <th>VIP_SCORE</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.408000</td>\n      <td>0.405500</td>\n      <td>0.410000</td>\n      <td>0.405000</td>\n      <td>0.396000</td>\n      <td>0.406500</td>\n      <td>0.411500</td>\n      <td>0.389500</td>\n      <td>0.393500</td>\n      <td>0.407500</td>\n      <td>0.403300</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.379500</td>\n      <td>0.385000</td>\n      <td>0.416500</td>\n      <td>0.440000</td>\n      <td>0.398500</td>\n      <td>0.467500</td>\n      <td>0.373500</td>\n      <td>0.392000</td>\n      <td>0.387000</td>\n      <td>0.409500</td>\n      <td>0.404900</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.375000</td>\n      <td>0.403500</td>\n      <td>0.393500</td>\n      <td>0.423500</td>\n      <td>0.432000</td>\n      <td>0.406000</td>\n      <td>0.431000</td>\n      <td>0.417500</td>\n      <td>0.400000</td>\n      <td>0.354000</td>\n      <td>0.403600</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.155000</td>\n      <td>0.206000</td>\n      <td>0.152500</td>\n      <td>0.198500</td>\n      <td>0.171500</td>\n      <td>0.228000</td>\n      <td>0.157000</td>\n      <td>0.188500</td>\n      <td>0.152500</td>\n      <td>0.160000</td>\n      <td>0.176950</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.574500</td>\n      <td>0.524500</td>\n      <td>0.522500</td>\n      <td>0.559500</td>\n      <td>0.492500</td>\n      <td>0.636000</td>\n      <td>0.488500</td>\n      <td>0.495500</td>\n      <td>0.491000</td>\n      <td>0.557000</td>\n      <td>0.534150</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>4686</th>\n      <td>0.248000</td>\n      <td>0.265000</td>\n      <td>0.233000</td>\n      <td>0.291000</td>\n      <td>0.166500</td>\n      <td>0.202500</td>\n      <td>0.319000</td>\n      <td>0.217167</td>\n      <td>0.200077</td>\n      <td>0.262500</td>\n      <td>0.240474</td>\n    </tr>\n    <tr>\n      <th>4687</th>\n      <td>0.365000</td>\n      <td>0.368898</td>\n      <td>0.368375</td>\n      <td>0.419500</td>\n      <td>0.383000</td>\n      <td>0.362000</td>\n      <td>0.372500</td>\n      <td>0.374500</td>\n      <td>0.390500</td>\n      <td>0.382500</td>\n      <td>0.378677</td>\n    </tr>\n    <tr>\n      <th>4688</th>\n      <td>0.375683</td>\n      <td>0.388681</td>\n      <td>0.389468</td>\n      <td>0.339825</td>\n      <td>0.363918</td>\n      <td>0.373310</td>\n      <td>0.392877</td>\n      <td>0.369819</td>\n      <td>0.371783</td>\n      <td>0.355431</td>\n      <td>0.372080</td>\n    </tr>\n    <tr>\n      <th>4689</th>\n      <td>0.447500</td>\n      <td>0.339487</td>\n      <td>0.299000</td>\n      <td>0.397500</td>\n      <td>0.366500</td>\n      <td>0.416000</td>\n      <td>0.257000</td>\n      <td>0.353000</td>\n      <td>0.413000</td>\n      <td>0.409500</td>\n      <td>0.369849</td>\n    </tr>\n    <tr>\n      <th>4690</th>\n      <td>0.207500</td>\n      <td>0.259500</td>\n      <td>0.251000</td>\n      <td>0.219350</td>\n      <td>0.298500</td>\n      <td>0.237786</td>\n      <td>0.235500</td>\n      <td>0.228000</td>\n      <td>0.258000</td>\n      <td>0.240460</td>\n      <td>0.243560</td>\n    </tr>\n  </tbody>\n</table>\n<p>4691 rows × 11 columns</p>\n</div>"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_df['VIP_SCORE'] = (model_df[1] + model_df[2] + model_df[3] + model_df[4] + \n",
    "    model_df[5] +model_df[6] + model_df[7] + model_df[8] + model_df[9] + model_df[10])/10\n",
    "\n",
    "model_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0a688c58",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Merge Results back to Test Data Frame\n",
    "test_df['VIP_SCORE'] = model_df['VIP_SCORE']\n",
    "test_df['ED_IP_VISIT'] = y_test_df\n",
    "test_df['MEMBER_ID'] = member_id_list\n",
    "test_df['DATA_DATE_START'] = data_date_start_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "766ae136",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "     MEMBER_ID  VIP_SCORE  ED_IP_VISIT DATA_DATE_START\n568      64632   0.750250            0          202208\n284      63254   0.721820            0          202208\n133      64568   0.692650            0          202208\n179      29973   0.692350            0          202208\n3279   1020876   0.690900            0          202208\n201      74216   0.686900            0          202208\n68       83765   0.683900            0          202208\n503      80138   0.681650            0          202208\n280    1019365   0.666550            0          202208\n257      63580   0.662050            0          202208\n337      48287   0.656638            0          202208\n149    1020955   0.650750            0          202208\n138    1018514   0.646750            0          202208\n384      75463   0.644413            0          202208\n70       63013   0.641700            0          202208",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>MEMBER_ID</th>\n      <th>VIP_SCORE</th>\n      <th>ED_IP_VISIT</th>\n      <th>DATA_DATE_START</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>568</th>\n      <td>64632</td>\n      <td>0.750250</td>\n      <td>0</td>\n      <td>202208</td>\n    </tr>\n    <tr>\n      <th>284</th>\n      <td>63254</td>\n      <td>0.721820</td>\n      <td>0</td>\n      <td>202208</td>\n    </tr>\n    <tr>\n      <th>133</th>\n      <td>64568</td>\n      <td>0.692650</td>\n      <td>0</td>\n      <td>202208</td>\n    </tr>\n    <tr>\n      <th>179</th>\n      <td>29973</td>\n      <td>0.692350</td>\n      <td>0</td>\n      <td>202208</td>\n    </tr>\n    <tr>\n      <th>3279</th>\n      <td>1020876</td>\n      <td>0.690900</td>\n      <td>0</td>\n      <td>202208</td>\n    </tr>\n    <tr>\n      <th>201</th>\n      <td>74216</td>\n      <td>0.686900</td>\n      <td>0</td>\n      <td>202208</td>\n    </tr>\n    <tr>\n      <th>68</th>\n      <td>83765</td>\n      <td>0.683900</td>\n      <td>0</td>\n      <td>202208</td>\n    </tr>\n    <tr>\n      <th>503</th>\n      <td>80138</td>\n      <td>0.681650</td>\n      <td>0</td>\n      <td>202208</td>\n    </tr>\n    <tr>\n      <th>280</th>\n      <td>1019365</td>\n      <td>0.666550</td>\n      <td>0</td>\n      <td>202208</td>\n    </tr>\n    <tr>\n      <th>257</th>\n      <td>63580</td>\n      <td>0.662050</td>\n      <td>0</td>\n      <td>202208</td>\n    </tr>\n    <tr>\n      <th>337</th>\n      <td>48287</td>\n      <td>0.656638</td>\n      <td>0</td>\n      <td>202208</td>\n    </tr>\n    <tr>\n      <th>149</th>\n      <td>1020955</td>\n      <td>0.650750</td>\n      <td>0</td>\n      <td>202208</td>\n    </tr>\n    <tr>\n      <th>138</th>\n      <td>1018514</td>\n      <td>0.646750</td>\n      <td>0</td>\n      <td>202208</td>\n    </tr>\n    <tr>\n      <th>384</th>\n      <td>75463</td>\n      <td>0.644413</td>\n      <td>0</td>\n      <td>202208</td>\n    </tr>\n    <tr>\n      <th>70</th>\n      <td>63013</td>\n      <td>0.641700</td>\n      <td>0</td>\n      <td>202208</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#View Predicted Members DF\n",
    "predicted_df = test_df[['MEMBER_ID','VIP_SCORE','ED_IP_VISIT','DATA_DATE_START']]\n",
    "predicted_df = predicted_df.sort_values(by=['VIP_SCORE'],ascending = False)\n",
    "predicted_df.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c246c5ba",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "predicted_df.to_csv('CTL Model - 202208.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d17587d",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Output and Update Tables in Snowflake for Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e144d0e4",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successful Connection\n"
     ]
    }
   ],
   "source": [
    "# Snowflake credentials stored in environment variables\n",
    "\n",
    "username = os.getenv('Snowflake_User')\n",
    "password = os.getenv('Snowflake_password')\n",
    "account = os.getenv('Snowflake_account')\n",
    "\n",
    "\n",
    "#Define parameters if neccessary\n",
    "warehouse = os.getenv('Snowflake_warehouse')\n",
    "database = os.getenv('Snowflake_database')\n",
    "schema = os.getenv('Snowflake_schema')\n",
    "\n",
    "#Create connection object for Snowflake connection\n",
    "conn = sf.connect(user = username, password = password, account = account, warehouse = warehouse)\n",
    "\n",
    "#Execution function\n",
    "def execute_query(connection,query):\n",
    "    cursor = connection.cursor()\n",
    "    cursor.execute(query)\n",
    "    cursor.close\n",
    "\n",
    "try:\n",
    "    sql = 'USE DATABASE {}'.format(database)\n",
    "    execute_query(conn,sql)\n",
    "    \n",
    "    sql = 'USE SCHEMA {}.{}'.format(database,schema)\n",
    "    execute_query(conn,sql)\n",
    "    \n",
    "    #Define warehouse to use in Snowflake\n",
    "    sql = 'use warehouse {}'.format(warehouse)\n",
    "    execute_query(conn,sql)\n",
    "    \n",
    "    print('Successful Connection')\n",
    "    \n",
    "    #Query to Snowflake\n",
    "    sql = \"CREATE TABLE IF NOT EXISTS VIP_SCORING (CLNT string,MEMBER_ID string, VIP_SCORE float ,DATA_DATE_START string)\"\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(sql)\n",
    "    \n",
    "    entry_list = []\n",
    "    for row in predicted_df.iterrows():\n",
    "        client = 'CTL'\n",
    "        member_id = str(row[1][0])\n",
    "        vip_score = row[1][1]\n",
    "        data_date = str(row[1][3])\n",
    "        entry = (client,member_id,vip_score,data_date)\n",
    "        entry_list.append(entry)       \n",
    "    entry = str(entry_list)[1:len(str(entry_list))-1]\n",
    "    sql = 'INSERT INTO VIP_SCORING (CLNT,MEMBER_ID, VIP_SCORE, DATA_DATE_START) VALUES {}'.format(entry)\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(sql)  \n",
    "    cursor.close\n",
    "    \n",
    "except Exception as e:\n",
    "        print(e)\n",
    "        \n",
    "finally:\n",
    "    conn.close"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb7003b",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# ITEMS BELOW THIS ARE FOR ANALYSIS ONLY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1182c6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Prediction List\n",
    "for row in predicted_df.iterrows():\n",
    "    print('Member: ',row[1][0],' VIP_SCORE: ',round(row[1][1],4), ' ED_IP_VISIT: ',row[1][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc46052",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "final_threshold = 0.3\n",
    "\n",
    "final_y_pred = [1 if result >= final_threshold else 0 for result in test_df['VIP_SCORE'].tolist()]\n",
    "\n",
    "# Creating confusion maxtrix\n",
    "new_cnf_matrix = metrics.confusion_matrix(y_test_df,final_y_pred)\n",
    "\n",
    "%matplotlib inline\n",
    "class_names=[0,1]\n",
    "fig, ax = plt.subplots()\n",
    "tick_marks = np.arange(len(class_names))\n",
    "plt.xticks(tick_marks, class_names)\n",
    "plt.yticks(tick_marks, class_names)\n",
    "\n",
    "# Create heatmap\n",
    "sns.heatmap(pd.DataFrame(new_cnf_matrix), annot=True, cmap=\"YlGnBu\" ,fmt='g')\n",
    "ax.xaxis.set_label_position(\"top\")\n",
    "\n",
    "# Axis labels\n",
    "plt.tight_layout()\n",
    "plt.title('Confusion matrix', y=1.1)\n",
    "plt.ylabel('Actual label')\n",
    "plt.xlabel('Predicted label')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n",
    "#Calulating Metrics\n",
    "accuracy = metrics.accuracy_score(y_test_df, final_y_pred)\n",
    "precision = metrics.precision_score(y_test_df, final_y_pred)\n",
    "recall = metrics.recall_score(y_test_df, final_y_pred)\n",
    "    \n",
    "print('Thereshold: ',final_threshold)\n",
    "print(\"Accuracy: \",accuracy)\n",
    "print(\"Precision: \",precision)\n",
    "print(\"Recall: \",recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c1fe52b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Realtime Accuracy\n",
    "X = []\n",
    "Y = []\n",
    "count = 1\n",
    "sums = 0\n",
    "for row in predicted_df.iterrows():\n",
    "    sums += row[1][2]\n",
    "    accuracy = round(sums/count *100,2)\n",
    "    X.append(count)\n",
    "    Y.append(accuracy)\n",
    "    print('After',count, 'prediction, the realtime accuarcy is ',accuracy)\n",
    "    count +=1\n",
    "    \n",
    "plt.plot(X, Y, marker='.', label='Random Forest')\n",
    "\n",
    "acc = np.where(np.array(Y) <= 60)\n",
    "\n",
    "acc = np.where(np.array(Y) <= 60)\n",
    "#for i,x in enumerate(acc[0]):\n",
    "    #print(i,x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f17f997c",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Important Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bfe6e06",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "feature_list = [x for x in df.columns if x != 'ED_IP_VISIT']\n",
    "\n",
    "importance_df = pd.DataFrame()\n",
    "\n",
    "for i,clf in forest_dict.items():\n",
    "    start_time = time.time()\n",
    "    importances = list(clf.feature_importances_)\n",
    "    feature_importances = [(feature, round(importance, 15)) for feature, importance in zip(feature_list, importances)]\n",
    "    importance_df[i+1] = feature_importances\n",
    "    print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "importance_avg_list = []\n",
    "\n",
    "for row in importance_df.iterrows():\n",
    "    feature_name = row[1][1][0]\n",
    "    avg = round((row[1][1][1] + row[1][2][1] + row[1][3][1] + row[1][4][1] + row[1][5][1] + row[1][6][1] + row[1][7][1] \n",
    "            + row[1][8][1] + row[1][9][1] + row[1][10][1])/10,4)\n",
    "    \n",
    "    importance_avg_list.append((feature_name,avg))\n",
    "    \n",
    "# Sort the feature importances by most important first\n",
    "feature_importances = sorted(importance_avg_list, key = lambda x: x[1], reverse = True)\n",
    "\n",
    "feature_importances[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a47259",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "list1 = df.columns.tolist()\n",
    "list2 = test_df.columns.tolist()\n",
    "list3 = set(list2)\n",
    "[item for item in list1 if item not in list3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46952730",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}