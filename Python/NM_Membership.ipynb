{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Importing Necessary dependencies\n",
    "import pandas as pd,datetime\n",
    "import snowflake.connector as sf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn import utils\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import time\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successful Connection\n",
      "Successful DataFrame Created\n"
     ]
    }
   ],
   "source": [
    "# Snowflake credentials stored in environment variables\n",
    "\n",
    "username = os.getenv('Snowflake_User')\n",
    "password = os.getenv('Snowflake_password')\n",
    "account = os.getenv('Snowflake_account')\n",
    "\n",
    "# Define warehouse, if neccessary\n",
    "warehouse = 'DEVELOPER_BASIC'\n",
    "\n",
    "# Define Database, if not defined in SQL request\n",
    "#database = 'VESTA_STAGING'\n",
    "\n",
    "# Create connection object for Snowflake connection\n",
    "conn = sf.connect(user=username, password=password, account=account, warehouse=warehouse)\n",
    "\n",
    "\n",
    "# Execution function\n",
    "def execute_query(connection, query):\n",
    "    cursor = connection.cursor()\n",
    "    cursor.execute(query)\n",
    "    cursor.close\n",
    "\n",
    "\n",
    "try:\n",
    "    # If defining a database, uncomment code set and add database in connection parameter\n",
    "    #sql = 'use {}'.format(database)\n",
    "    #execute_query(conn,sql)1011\n",
    "\n",
    "    # Define warehouse to use in Snowflake\n",
    "    sql = 'use warehouse {}'.format(warehouse)\n",
    "    execute_query(conn, sql)\n",
    "\n",
    "    print('Successful Connection')\n",
    "\n",
    "    # Query to Snowflake\n",
    "    sql = '''WITH EDIP AS ( //This is sub table for a self join\n",
    "\n",
    "    SELECT\n",
    "        *\n",
    "    FROM \"VESTA_DEVELOPMENT\".\"CLAIMS_REPORTING\".\"CCA_MEM_PROFILE_IP_ER_SNF\" //THIS NEEDS TO CHANGE BASED ON CLIENT\n",
    "    WHERE MEASURE = 'ED' or MEASURE = 'IP'\n",
    "\n",
    "    SELECT\n",
    "    *\n",
    "FROM\n",
    "VESTA_DEVELOPMENT.CLAIMS_REPORTING.NM_MEMBERSHIP_MTH\n",
    "WHERE CLNT = 'CCA'\n",
    "and month >= '202201'\n",
    "'''\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(sql)\n",
    "\n",
    "    # Dataframe creation\n",
    "    df = pd.DataFrame.from_records(iter(cursor), columns = [x[0] for x in cursor.description])\n",
    "\n",
    "    print('Successful DataFrame Created')\n",
    "\n",
    "\n",
    "\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "finally:\n",
    "    conn.close\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "data": {
      "text/plain": "  CLNT   MEMBER_ID DASH_ID HR_MIN_DATE DISENROLL_DATE PLATFORM_STATUS  \\\n0  CCA  5365612939    3682  2021-03-19     2022-03-15     DISENROLLED   \n1  CCA  5365612939    3682  2021-03-19     2022-03-15     DISENROLLED   \n2  CCA  5365612938    2193        None           None        DECLINED   \n3  CCA  5365612938    2193        None           None        DECLINED   \n4  CCA  5365612938    2193        None           None        DECLINED   \n\n   TARGETTED_HISTORICALLY  ENROLLED  ENGAGED  DISENROLLED  ...  NI_COST_OP  \\\n0                     1.0       1.0      0.0          1.0  ...        0.00   \n1                     1.0       1.0      0.0          1.0  ...        0.00   \n2                     1.0       0.0      0.0          0.0  ...        0.00   \n3                     1.0       0.0      0.0          0.0  ...        0.00   \n4                     1.0       0.0      0.0          0.0  ...       38.82   \n\n  NI_COST_OTH NI_COST_PCA_T1019 NI_COST_PCA_T1020 NI_COST_PR NI_COST_PSYC  \\\n0         0.0           1390.00             46.20    1078.55          0.0   \n1         0.0           1820.00             51.15       0.00          0.0   \n2         0.0              0.00              0.00       0.00          0.0   \n3         0.0            494.00              0.00     280.95          0.0   \n4         0.0           1817.92             49.50     391.98          0.0   \n\n  NI_COST_RX  NI_COST_RXD NI_COST_UNC TOTAL_NON_IMPACTABLE_COST  \n0      43.43       197.81         0.0                   2814.98  \n1       0.00         0.85         0.0                   2549.07  \n2       0.00         0.00         0.0                      0.00  \n3       0.00       127.09         0.0                    902.04  \n4      23.82       188.88         0.0                   2510.92  \n\n[5 rows x 168 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>CLNT</th>\n      <th>MEMBER_ID</th>\n      <th>DASH_ID</th>\n      <th>HR_MIN_DATE</th>\n      <th>DISENROLL_DATE</th>\n      <th>PLATFORM_STATUS</th>\n      <th>TARGETTED_HISTORICALLY</th>\n      <th>ENROLLED</th>\n      <th>ENGAGED</th>\n      <th>DISENROLLED</th>\n      <th>...</th>\n      <th>NI_COST_OP</th>\n      <th>NI_COST_OTH</th>\n      <th>NI_COST_PCA_T1019</th>\n      <th>NI_COST_PCA_T1020</th>\n      <th>NI_COST_PR</th>\n      <th>NI_COST_PSYC</th>\n      <th>NI_COST_RX</th>\n      <th>NI_COST_RXD</th>\n      <th>NI_COST_UNC</th>\n      <th>TOTAL_NON_IMPACTABLE_COST</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>CCA</td>\n      <td>5365612939</td>\n      <td>3682</td>\n      <td>2021-03-19</td>\n      <td>2022-03-15</td>\n      <td>DISENROLLED</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>1390.00</td>\n      <td>46.20</td>\n      <td>1078.55</td>\n      <td>0.0</td>\n      <td>43.43</td>\n      <td>197.81</td>\n      <td>0.0</td>\n      <td>2814.98</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>CCA</td>\n      <td>5365612939</td>\n      <td>3682</td>\n      <td>2021-03-19</td>\n      <td>2022-03-15</td>\n      <td>DISENROLLED</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>1820.00</td>\n      <td>51.15</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.85</td>\n      <td>0.0</td>\n      <td>2549.07</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>CCA</td>\n      <td>5365612938</td>\n      <td>2193</td>\n      <td>None</td>\n      <td>None</td>\n      <td>DECLINED</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>CCA</td>\n      <td>5365612938</td>\n      <td>2193</td>\n      <td>None</td>\n      <td>None</td>\n      <td>DECLINED</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>494.00</td>\n      <td>0.00</td>\n      <td>280.95</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>127.09</td>\n      <td>0.0</td>\n      <td>902.04</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>CCA</td>\n      <td>5365612938</td>\n      <td>2193</td>\n      <td>None</td>\n      <td>None</td>\n      <td>DECLINED</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>38.82</td>\n      <td>0.0</td>\n      <td>1817.92</td>\n      <td>49.50</td>\n      <td>391.98</td>\n      <td>0.0</td>\n      <td>23.82</td>\n      <td>188.88</td>\n      <td>0.0</td>\n      <td>2510.92</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 168 columns</p>\n</div>"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "# features with missing values\n",
    "sumdf = pd.DataFrame(df.isna().sum())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               0\n",
      "CLNT                           0\n",
      "MEMBER_ID                      0\n",
      "DASH_ID                      823\n",
      "HR_MIN_DATE                14209\n",
      "DISENROLL_DATE             21007\n",
      "...                          ...\n",
      "NI_COST_PSYC                   0\n",
      "NI_COST_RX                     0\n",
      "NI_COST_RXD                    0\n",
      "NI_COST_UNC                    0\n",
      "TOTAL_NON_IMPACTABLE_COST      0\n",
      "\n",
      "[168 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "print(sumdf)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These are the features that initially had missing values within the data frame: \n",
      " ['DASH_ID', 'HR_MIN_DATE', 'DISENROLL_DATE', 'PLATFORM_STATUS', 'HR_LAST_4_WK', 'AVG_WKLY_HR', 'TARGETED_DATE', 'TARGETING_SOURCE', 'AGENCY', 'LANGUAGE_SPOKEN', 'CENTER_NAME', 'HR_COUNT', 'ALERT_COUNT', 'PREMIUM_MD', 'PREMIUM_MR_PART_C', 'PREMIUM_MR_PART_C_ACCRUAL', 'PREMIUM_MR_PART_C_PROJECTED', 'PREMIUM_MR_PART_D_LICS', 'PREMIUM_MR_PART_D_REINS', 'PREMIUM_MR_PART_D_PREMIUM', 'PREMIUM_MR_PART_D_TOTAL', 'PREMIUM_MR_TOTAL_PROJECTED', 'PREMIUM_MR_REVENUE_TOTAL', 'PREMIUM_TOTAL_PROJECTED', 'PREMIUM_TOTAL', 'INITIAL_TARGET_GROUP_M', 'CARECOORD_CNT', 'WELLNESS_CNT', 'PAT_CARE_PLAN_CNT', 'TCM_CNT', 'INIT_PAT_CARE_PLAN_CNT', 'CARECOORD_MIN', 'WELLNESS_MIN', 'PAT_CARE_PLAN_MIN', 'TCM_MIN', 'INIT_PAT_CARE_PLAN_MIN', 'VALID_URGENT_ALERTS', 'NP_ESC_ALERTS', 'CPT_CODING_DATES', 'VESTA_NP_VISIT', 'CG_AGENCY', 'CG_AIDE_UNKNOWN', 'CG_N_A', 'CG_PCA_FAMILY', 'CG_PCA_PROFESSIONAL', 'CG_UNPAID_CG', 'ONB_PRE_POST', 'TAR_PRE_POST', 'NLO_PRE_POST', 'NO_MTH', 'HR_TOTAL', 'AVG_HR_PER_MTH', 'LIFETIME_ZERO', 'HR_AVG_THIS_MONTH', 'PX_ACP_PRE_POST', 'PX_ASG_PRE_POST', 'PX_C24_PRE_POST', 'PX_CCM_PRE_POST', 'PX_CORE_PRE_POST', 'PX_DAA_PRE_POST', 'PX_LIFE_PRE_POST', 'PX_LITE_PRE_POST', 'PX_MCD_PRE_POST', 'PX_RPM_PRE_POST', 'ALL_CLAIMS', 'DENT', 'ED', 'HM', 'HMKR', 'HS', 'IP', 'IP_RHB', 'OP', 'OTH', 'PCA_T1019', 'PCA_T1020', 'PR', 'PSYC', 'RX', 'RXD', 'SNF', 'UNC', 'ALL_CLAIMS_N', 'DENT_N', 'ED_N', 'HM_N', 'HMKR_N', 'HS_N', 'IP_N', 'IP_RHB_N', 'OP_N', 'OTH_N', 'PCA_T1019_N', 'PCA_T1020_N', 'PR_N', 'PSYC_N', 'RX_N', 'RXD_N', 'SNF_N', 'UNC_N', 'ALL_CLAIMS_U', 'DENT_U', 'ED_U', 'HMKR_U', 'HM_U', 'HS_U', 'IP_RHB_U', 'IP_U', 'OP_U', 'OTH_U', 'PCA_T1019_U', 'PCA_T1020_U', 'PR_U', 'PSYC_U', 'SNF_U', 'UNC_U'] \n",
      "\n",
      "\n",
      "                           0\n",
      "CLNT                       0\n",
      "MEMBER_ID                  0\n",
      "DASH_ID                    0\n",
      "HR_MIN_DATE                0\n",
      "DISENROLL_DATE             0\n",
      "...                       ..\n",
      "NI_COST_PSYC               0\n",
      "NI_COST_RX                 0\n",
      "NI_COST_RXD                0\n",
      "NI_COST_UNC                0\n",
      "TOTAL_NON_IMPACTABLE_COST  0\n",
      "\n",
      "[168 rows x 1 columns]\n",
      "These columns were dropped after because missing values were not corrected :\n",
      " [] \n",
      "\n",
      "\n",
      "These are the features that were converted to dummy variables: \n",
      " ['CLNT', 'MEMBER_ID', 'DASH_ID', 'HR_MIN_DATE', 'DISENROLL_DATE', 'PLATFORM_STATUS', 'AVG_WKLY_HR', 'HR_ENROLL_MTH', 'DISENROLL_MTH', 'TARGETED_DATE', 'TARGETED_YM', 'TARGETING_SOURCE', 'AGENCY', 'GENDER', 'LANGUAGE_SPOKEN', 'ELIG_ENROLL_MTH', 'MONTH', 'RC', 'PART_C_RISK_SCORE', 'INITIAL_TARGET_GROUP_M', 'VESTA_ONBOARDED_STATUS', 'TEST_MONTH'] \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "features_to_drop = []\n",
    "for row in sumdf.iterrows():\n",
    "    if row[1][0] != 0:\n",
    "        features_to_drop.append(row[0])\n",
    "\n",
    "# Review features with missing values\n",
    "print('These are the features that initially had missing values within the data frame: \\n',features_to_drop,'\\n\\n')\n",
    "\n",
    "nulls_to_correct = ['DASH_ID', 'HR_MIN_DATE', 'DISENROLL_DATE', 'PLATFORM_STATUS', 'HR_LAST_4_WK', 'AVG_WKLY_HR', 'TARGETED_DATE', 'TARGETING_SOURCE', 'AGENCY', 'LANGUAGE_SPOKEN', 'CENTER_NAME', 'HR_COUNT', 'ALERT_COUNT', 'PREMIUM_MD', 'PREMIUM_MR_PART_C', 'PREMIUM_MR_PART_C_ACCRUAL', 'PREMIUM_MR_PART_C_PROJECTED', 'PREMIUM_MR_PART_D_LICS', 'PREMIUM_MR_PART_D_REINS', 'PREMIUM_MR_PART_D_PREMIUM', 'PREMIUM_MR_PART_D_TOTAL', 'PREMIUM_MR_TOTAL_PROJECTED', 'PREMIUM_MR_REVENUE_TOTAL', 'PREMIUM_TOTAL_PROJECTED', 'PREMIUM_TOTAL', 'INITIAL_TARGET_GROUP_M', 'CARECOORD_CNT', 'WELLNESS_CNT', 'PAT_CARE_PLAN_CNT', 'TCM_CNT', 'INIT_PAT_CARE_PLAN_CNT', 'CARECOORD_MIN', 'WELLNESS_MIN', 'PAT_CARE_PLAN_MIN', 'TCM_MIN', 'INIT_PAT_CARE_PLAN_MIN', 'VALID_URGENT_ALERTS', 'NP_ESC_ALERTS', 'CPT_CODING_DATES', 'VESTA_NP_VISIT', 'CG_AGENCY', 'CG_AIDE_UNKNOWN', 'CG_N_A', 'CG_PCA_FAMILY', 'CG_PCA_PROFESSIONAL', 'CG_UNPAID_CG', 'ONB_PRE_POST', 'TAR_PRE_POST', 'NLO_PRE_POST', 'NO_MTH', 'HR_TOTAL', 'AVG_HR_PER_MTH', 'LIFETIME_ZERO', 'HR_AVG_THIS_MONTH', 'PX_ACP_PRE_POST', 'PX_ASG_PRE_POST', 'PX_C24_PRE_POST', 'PX_CCM_PRE_POST', 'PX_CORE_PRE_POST', 'PX_DAA_PRE_POST', 'PX_LIFE_PRE_POST', 'PX_LITE_PRE_POST', 'PX_MCD_PRE_POST', 'PX_RPM_PRE_POST', 'ALL_CLAIMS', 'DENT', 'ED', 'HM', 'HMKR', 'HS', 'IP', 'IP_RHB', 'OP', 'OTH', 'PCA_T1019', 'PCA_T1020', 'PR', 'PSYC', 'RX', 'RXD', 'SNF', 'UNC', 'ALL_CLAIMS_N', 'DENT_N', 'ED_N', 'HM_N', 'HMKR_N', 'HS_N', 'IP_N', 'IP_RHB_N', 'OP_N', 'OTH_N', 'PCA_T1019_N', 'PCA_T1020_N', 'PR_N', 'PSYC_N', 'RX_N', 'RXD_N', 'SNF_N', 'UNC_N', 'ALL_CLAIMS_U', 'DENT_U', 'ED_U', 'HMKR_U', 'HM_U', 'HS_U', 'IP_RHB_U', 'IP_U', 'OP_U', 'OTH_U', 'PCA_T1019_U', 'PCA_T1020_U', 'PR_U', 'PSYC_U', 'SNF_U', 'UNC_U']\n",
    "\n",
    "# Fill selected features with 0 value\n",
    "for col in nulls_to_correct:\n",
    "    df[col] = df[col].fillna(0)\n",
    "\n",
    "# Check for missing values and drop columns with missing values\n",
    "sumdf = pd.DataFrame(df.isna().sum())\n",
    "print(sumdf)\n",
    "\n",
    "features_to_drop = []\n",
    "for row in sumdf.iterrows():\n",
    "    if row[1][0] != 0:\n",
    "        features_to_drop.append(row[0])\n",
    "\n",
    "print('These columns were dropped after because missing values were not corrected :\\n', features_to_drop,'\\n\\n')\n",
    "df = df.drop(columns = features_to_drop)\n",
    "\n",
    "# Convert object datatypes to dummy variables\n",
    "object_list = []\n",
    "\n",
    "for col in df.columns:\n",
    "    if df[col].dtypes == 'object':\n",
    "        object_list.append(col)\n",
    "\n",
    "\n",
    "print('These are the features that were converted to dummy variables: \\n',object_list,'\\n\\n')\n",
    "df = pd.get_dummies(df, columns = object_list, drop_first = True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory Usage of Dataframe: 174686245 bytes\n"
     ]
    }
   ],
   "source": [
    "original_memory = df.memory_usage().sum()\n",
    "print(f'Memory Usage of Dataframe: {df.memory_usage().sum()} bytes')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "#convert data types\n",
    "#changing all float64 to float32\n",
    "df[df.select_dtypes(np.float64).columns] = df.select_dtypes(np.float64).astype(np.float32)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory Usage of Original Dataframe: 174686245 bytes\n",
      "Memory Usage of New Dataframe: 162729693 bytes\n",
      "Memory usage reduced by:7.0%\n"
     ]
    }
   ],
   "source": [
    "new_memory = df.memory_usage().sum()\n",
    "print(f'Memory Usage of Original Dataframe: {original_memory} bytes')\n",
    "print(f'Memory Usage of New Dataframe: {new_memory} bytes')\n",
    "print(f'Memory usage reduced by:{round((original_memory-new_memory)/original_memory * 100,0)}%')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These are the features that were dropped because of low variability: \n",
      " ['CENTER_NAME', 'PREMIUM_MR_PART_D_LICS', 'PREMIUM_MR_PART_D_REINS', 'PREMIUM_MR_PART_D_PREMIUM', 'PREMIUM_MR_PART_D_TOTAL', 'PREMIUM_MR_TOTAL_PROJECTED', 'PREMIUM_MR_REVENUE_TOTAL', 'PX_MCD_PRE_POST', 'UNC', 'UNC_N', 'IP_U', 'UNC_U', 'NI_COST_UNC'] \n",
      "\n",
      "\n",
      "Memory Usage of Dataframe: 160498993 bytes\n"
     ]
    }
   ],
   "source": [
    "# Drop low variability columns\n",
    "df_var = df.var()\n",
    "df.columns.to_list()\n",
    "\n",
    "features_to_drop = []\n",
    "\n",
    "for i in range(len(df.columns.to_list())):\n",
    "    #print(df.columns.to_list()[i],df_var[i])\n",
    "    if df_var[i] == 0 and df.columns.to_list()[i] != 'ED':\n",
    "        features_to_drop.append(df.columns.to_list()[i])\n",
    "\n",
    "\n",
    "print('These are the features that were dropped because of low variability: \\n',features_to_drop,'\\n\\n')\n",
    "\n",
    "df = df.drop(columns = features_to_drop)\n",
    "print(f'Memory Usage of Dataframe: {df.memory_usage().sum()} bytes')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "data": {
      "text/plain": "   TARGETTED_HISTORICALLY  ENROLLED  ENGAGED  DISENROLLED  HR_LAST_4_WK  \\\n0                     1.0       1.0      0.0          1.0           0.0   \n1                     1.0       1.0      0.0          1.0           0.0   \n2                     1.0       0.0      0.0          0.0           0.0   \n3                     1.0       0.0      0.0          0.0           0.0   \n4                     1.0       0.0      0.0          0.0           0.0   \n\n   INSTITUTIONAL   AGE  ENROLLED_IN_DASH  DISENROLLED_IN_DASH  \\\n0            0.0  77.0               1.0                  0.0   \n1            0.0  77.0               1.0                  0.0   \n2            0.0  74.0               0.0                  0.0   \n3            0.0  74.0               0.0                  0.0   \n4            0.0  74.0               0.0                  0.0   \n\n   TARGETED_POST_V2  ...  TEST_MONTH_202202  TEST_MONTH_202203  \\\n0               0.0  ...                  1                  0   \n1               0.0  ...                  0                  0   \n2               1.0  ...                  0                  0   \n3               1.0  ...                  0                  0   \n4               1.0  ...                  0                  0   \n\n   TEST_MONTH_202204  TEST_MONTH_202205  TEST_MONTH_202206  TEST_MONTH_202207  \\\n0                  0                  0                  0                  0   \n1                  0                  0                  0                  0   \n2                  0                  0                  0                  0   \n3                  0                  0                  0                  0   \n4                  0                  0                  0                  0   \n\n   TEST_MONTH_202208  TEST_MONTH_202209  TEST_MONTH_202210  TEST_MONTH_202211  \n0                  0                  0                  0                  0  \n1                  0                  0                  0                  0  \n2                  0                  0                  0                  1  \n3                  0                  0                  1                  0  \n4                  0                  1                  0                  0  \n\n[5 rows x 6796 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>TARGETTED_HISTORICALLY</th>\n      <th>ENROLLED</th>\n      <th>ENGAGED</th>\n      <th>DISENROLLED</th>\n      <th>HR_LAST_4_WK</th>\n      <th>INSTITUTIONAL</th>\n      <th>AGE</th>\n      <th>ENROLLED_IN_DASH</th>\n      <th>DISENROLLED_IN_DASH</th>\n      <th>TARGETED_POST_V2</th>\n      <th>...</th>\n      <th>TEST_MONTH_202202</th>\n      <th>TEST_MONTH_202203</th>\n      <th>TEST_MONTH_202204</th>\n      <th>TEST_MONTH_202205</th>\n      <th>TEST_MONTH_202206</th>\n      <th>TEST_MONTH_202207</th>\n      <th>TEST_MONTH_202208</th>\n      <th>TEST_MONTH_202209</th>\n      <th>TEST_MONTH_202210</th>\n      <th>TEST_MONTH_202211</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>77.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>77.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>74.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>74.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>74.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 6796 columns</p>\n</div>"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory Usage of Dataframe: 160498993 bytes\n"
     ]
    }
   ],
   "source": [
    "# Split the data set\n",
    "X = df[[col for col in df.columns if col != 'ED']] #independent variables\n",
    "y = df[[col for col in df.columns if col == 'ED']] #dependent variable\n",
    "y = y.values.flatten()\n",
    "\n",
    "#convert y values to categorical values\n",
    "lab = preprocessing.LabelEncoder()\n",
    "y_transformed = lab.fit_transform(y)\n",
    "\n",
    "# Define MinMax Scaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Transform data\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Split X and y into training and testing sets\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y_transformed,test_size=0.30, random_state = 2)\n",
    "\n",
    "\n",
    "\n",
    "# Smote for balancing the training data set\n",
    "# smote = SMOTE(random_state = 2)\n",
    "# X_train,y_train = smote.fit_resample(X_train, y_train)\n",
    "print(f'Memory Usage of Dataframe: {df.memory_usage().sum()} bytes')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory Usage of Dataframe: 160498993 bytes\n",
      "CPU times: total: 49min 2s\n",
      "Wall time: 3min 9s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Create a Random Forest Classifier\n",
    "clf=RandomForestClassifier(n_estimators = 2000,min_samples_split = 2, min_samples_leaf = 1,\n",
    "                           max_depth = 50, bootstrap = False, n_jobs = -1,random_state = 2)\n",
    "\n",
    "# Train the model using the training sets\n",
    "clf.fit(X_train,y_train)\n",
    "print(f'Memory Usage of Dataframe: {df.memory_usage().sum()} bytes')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Input \u001B[1;32mIn [43]\u001B[0m, in \u001B[0;36m<cell line: 9>\u001B[1;34m()\u001B[0m\n\u001B[0;32m     12\u001B[0m \u001B[38;5;66;03m#Calulating Metrics\u001B[39;00m\n\u001B[0;32m     13\u001B[0m accuracy \u001B[38;5;241m=\u001B[39m metrics\u001B[38;5;241m.\u001B[39maccuracy_score(y_test, y_pred)\n\u001B[1;32m---> 14\u001B[0m precision \u001B[38;5;241m=\u001B[39m \u001B[43mmetrics\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mprecision_score\u001B[49m\u001B[43m(\u001B[49m\u001B[43my_test\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_pred\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     15\u001B[0m recall \u001B[38;5;241m=\u001B[39m metrics\u001B[38;5;241m.\u001B[39mrecall_score(y_test, y_pred)\n\u001B[0;32m     17\u001B[0m accuracy_list\u001B[38;5;241m.\u001B[39mappend(accuracy)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\NewBase\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1776\u001B[0m, in \u001B[0;36mprecision_score\u001B[1;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001B[0m\n\u001B[0;32m   1647\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mprecision_score\u001B[39m(\n\u001B[0;32m   1648\u001B[0m     y_true,\n\u001B[0;32m   1649\u001B[0m     y_pred,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1655\u001B[0m     zero_division\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mwarn\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m   1656\u001B[0m ):\n\u001B[0;32m   1657\u001B[0m     \u001B[38;5;124;03m\"\"\"Compute the precision.\u001B[39;00m\n\u001B[0;32m   1658\u001B[0m \n\u001B[0;32m   1659\u001B[0m \u001B[38;5;124;03m    The precision is the ratio ``tp / (tp + fp)`` where ``tp`` is the number of\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1774\u001B[0m \u001B[38;5;124;03m    array([0.5, 1. , 1. ])\u001B[39;00m\n\u001B[0;32m   1775\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m-> 1776\u001B[0m     p, _, _, _ \u001B[38;5;241m=\u001B[39m \u001B[43mprecision_recall_fscore_support\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1777\u001B[0m \u001B[43m        \u001B[49m\u001B[43my_true\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1778\u001B[0m \u001B[43m        \u001B[49m\u001B[43my_pred\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1779\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlabels\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlabels\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1780\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpos_label\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpos_label\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1781\u001B[0m \u001B[43m        \u001B[49m\u001B[43maverage\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maverage\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1782\u001B[0m \u001B[43m        \u001B[49m\u001B[43mwarn_for\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mprecision\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1783\u001B[0m \u001B[43m        \u001B[49m\u001B[43msample_weight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msample_weight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1784\u001B[0m \u001B[43m        \u001B[49m\u001B[43mzero_division\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mzero_division\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1785\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1786\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m p\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\NewBase\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1563\u001B[0m, in \u001B[0;36mprecision_recall_fscore_support\u001B[1;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001B[0m\n\u001B[0;32m   1561\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m beta \u001B[38;5;241m<\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m   1562\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbeta should be >=0 in the F-beta score\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m-> 1563\u001B[0m labels \u001B[38;5;241m=\u001B[39m \u001B[43m_check_set_wise_labels\u001B[49m\u001B[43m(\u001B[49m\u001B[43my_true\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_pred\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maverage\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlabels\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpos_label\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1565\u001B[0m \u001B[38;5;66;03m# Calculate tp_sum, pred_sum, true_sum ###\u001B[39;00m\n\u001B[0;32m   1566\u001B[0m samplewise \u001B[38;5;241m=\u001B[39m average \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msamples\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\NewBase\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1381\u001B[0m, in \u001B[0;36m_check_set_wise_labels\u001B[1;34m(y_true, y_pred, average, labels, pos_label)\u001B[0m\n\u001B[0;32m   1379\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m y_type \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmulticlass\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m   1380\u001B[0m             average_options\u001B[38;5;241m.\u001B[39mremove(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msamples\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m-> 1381\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m   1382\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTarget is \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m but average=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbinary\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m. Please \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   1383\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mchoose another average setting, one of \u001B[39m\u001B[38;5;132;01m%r\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m (y_type, average_options)\n\u001B[0;32m   1384\u001B[0m         )\n\u001B[0;32m   1385\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m pos_label \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m (\u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;241m1\u001B[39m):\n\u001B[0;32m   1386\u001B[0m     warnings\u001B[38;5;241m.\u001B[39mwarn(\n\u001B[0;32m   1387\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNote that pos_label (set to \u001B[39m\u001B[38;5;132;01m%r\u001B[39;00m\u001B[38;5;124m) is ignored when \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   1388\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124maverage != \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbinary\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m (got \u001B[39m\u001B[38;5;132;01m%r\u001B[39;00m\u001B[38;5;124m). You may use \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1391\u001B[0m         \u001B[38;5;167;01mUserWarning\u001B[39;00m,\n\u001B[0;32m   1392\u001B[0m     )\n",
      "\u001B[1;31mValueError\u001B[0m: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted']."
     ]
    }
   ],
   "source": [
    "# Create probabilities from the model on test data\n",
    "y_prob = clf.predict_proba(X_test)[:,1]\n",
    "\n",
    "# Store probabilites in Dataframe for threshold analysis\n",
    "threshold_list = [0.05,0.1,0.15,0.2,0.25,0.3,0.35,0.4,0.45,0.5,0.55,0.6,0.65,.7,.75,.8,.85,.9,.95,.99]\n",
    "accuracy_list = []\n",
    "precision_list = []\n",
    "recall_list = []\n",
    "for threshold in threshold_list:\n",
    "    y_pred = [1 if result >= threshold else 0 for result in y_prob]\n",
    "\n",
    "    #Calulating Metrics\n",
    "    accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "    precision = metrics.precision_score(y_test, y_pred)\n",
    "    recall = metrics.recall_score(y_test, y_pred)\n",
    "\n",
    "    accuracy_list.append(accuracy)\n",
    "    precision_list.append(precision)\n",
    "    recall_list.append(recall)\n",
    "\n",
    "    #print('Thereshold: ',threshold)\n",
    "    #print(\"Accuracy: \",accuracy)\n",
    "    #print(\"Precision: \",precision)\n",
    "    #print(\"Recall: \",recall)\n",
    "\n",
    "metric_df = pd.DataFrame()\n",
    "metric_df['Threshold'] = threshold_list\n",
    "metric_df['Accuracy'] = accuracy_list\n",
    "metric_df['Precision'] = precision_list\n",
    "metric_df['Recall'] = recall_list\n",
    "metric_df['F1'] = (2 * metric_df['Precision'] * metric_df['Recall']) / (metric_df['Precision'] + metric_df['Recall'])\n",
    "metric_df['Acc + Recall'] = metric_df['Accuracy'] + metric_df['Recall']\n",
    "\n",
    "metric_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'metric_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[1;32mIn [44]\u001B[0m, in \u001B[0;36m<cell line: 2>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m#Find the max accuracy and recall from the Metric Table and corresponding Threshold\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m threshold \u001B[38;5;241m=\u001B[39m \u001B[43mmetric_df\u001B[49m[metric_df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mAcc + Recall\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m==\u001B[39m metric_df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mAcc + Recall\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mmax()][\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mThreshold\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mitem()\n\u001B[0;32m      4\u001B[0m y_pred \u001B[38;5;241m=\u001B[39m [\u001B[38;5;241m1\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m result \u001B[38;5;241m>\u001B[39m\u001B[38;5;241m=\u001B[39m threshold \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;241m0\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m result \u001B[38;5;129;01min\u001B[39;00m y_prob]\n\u001B[0;32m      7\u001B[0m \u001B[38;5;66;03m# Creating confusion maxtrix\u001B[39;00m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'metric_df' is not defined"
     ]
    }
   ],
   "source": [
    "#Find the max accuracy and recall from the Metric Table and corresponding Threshold\n",
    "threshold = metric_df[metric_df['Acc + Recall'] == metric_df['Acc + Recall'].max()]['Threshold'].item()\n",
    "\n",
    "y_pred = [1 if result >= threshold else 0 for result in y_prob]\n",
    "\n",
    "\n",
    "# Creating confusion maxtrix\n",
    "cnf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "\n",
    "%matplotlib inline\n",
    "class_names=[0,1]\n",
    "fig, ax = plt.subplots()\n",
    "tick_marks = np.arange(len(class_names))\n",
    "plt.xticks(tick_marks, class_names)\n",
    "plt.yticks(tick_marks, class_names)\n",
    "\n",
    "# Create heatmap\n",
    "sns.heatmap(pd.DataFrame(cnf_matrix), annot=True, cmap=\"YlGnBu\" ,fmt='g')\n",
    "ax.xaxis.set_label_position(\"top\")\n",
    "\n",
    "# Axis labels\n",
    "plt.tight_layout()\n",
    "plt.title('Confusion matrix', y=1.1)\n",
    "plt.ylabel('Actual label')\n",
    "plt.xlabel('Predicted label')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
