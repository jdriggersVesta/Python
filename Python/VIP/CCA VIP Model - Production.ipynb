{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9f43ec2",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# ED-IP Prediction with Random Forests\n",
    "\n",
    "The goal of the model is to predict whether or not a member is going to have an ED or IP visit in the next 180 following the latest claim stratification. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23059ecf",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Importing Necessary dependencies\n",
    "import pandas as pd,datetime\n",
    "import snowflake.connector as sf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import time\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31578cb0",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Extracting Data Frame from Snowflake Tables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successful Connection\n",
      "Successful DataFrame Created\n",
      "Ready for Cleaning\n"
     ]
    }
   ],
   "source": [
    "# Snowflake credentials stored in environment variables\n",
    "\n",
    "username = os.getenv('Snowflake_User')\n",
    "password = os.getenv('Snowflake_password')\n",
    "account = os.getenv('Snowflake_account')\n",
    "\n",
    "# Define warehouse, if neccessary\n",
    "warehouse = 'DEVELOPER_BASIC'\n",
    "\n",
    "# Define Database, if not defined in SQL request\n",
    "#database = 'VESTA_STAGING'\n",
    "\n",
    "# Create connection object for Snowflake connection\n",
    "conn = sf.connect(user = username, password = password, account = account, warehouse = warehouse)\n",
    "\n",
    "# Execution function\n",
    "def execute_query(connection,query):\n",
    "    cursor = connection.cursor()\n",
    "    cursor.execute(query)\n",
    "    cursor.close\n",
    "\n",
    "try:\n",
    "    # If defining a database, uncomment code set and add database in connection parameter\n",
    "    #sql = 'use {}'.format(database)\n",
    "    #execute_query(conn,sql)1011\n",
    "    \n",
    "    # Define warehouse to use in Snowflake\n",
    "    sql = 'use warehouse {}'.format(warehouse)\n",
    "    execute_query(conn,sql)\n",
    "    \n",
    "    print('Successful Connection')\n",
    "    \n",
    "    # Query to Snowflake\n",
    "    sql = '''WITH EDIP AS ( //This is sub table for a self join\n",
    "\n",
    "    SELECT \n",
    "        *\n",
    "    FROM \"VESTA_DEVELOPMENT\".\"CLAIMS_REPORTING\".\"CCA_MEM_PROFILE_IP_ER_SNF\" //THIS NEEDS TO CHANGE BASED ON CLIENT\n",
    "    WHERE MEASURE = 'ED' or MEASURE = 'IP' \n",
    "\n",
    "    ),\n",
    "\n",
    "    EDIPTABLE AS ( //This table shows the Member ID, date start, and the number of ED/IP in the next 6 months\n",
    "\n",
    "    SELECT\n",
    "        SCORE.MEMBER_ID,\n",
    "        TO_DATE(CONCAT(LEFT(SCORE.DATA_DATE_START,4),'-',RIGHT(SCORE.DATA_DATE_START,2),'-01')) AS DATE_START,\n",
    "        COUNT(DISTINCT EDIP.DOS_FROM) AS ED_IP_VISITS_IN_NEXT_6_MONTHS\n",
    "    FROM \"VESTA_DEVELOPMENT\".\"ANALYST_SANDBOX\".\"CLNT_STRAT_VIP\" SCORE\n",
    "        LEFT JOIN EDIP \n",
    "            ON SCORE.MEMBER_ID = EDIP.MEMBER_ID\n",
    "                AND EDIP.DOS_FROM > TO_DATE(CONCAT(LEFT(SCORE.DATA_DATE_START,4),'-',RIGHT(SCORE.DATA_DATE_START,2),'-01'))\n",
    "                AND DATEDIFF(days,TO_DATE(CONCAT(LEFT(SCORE.DATA_DATE_START,4),'-',RIGHT(SCORE.DATA_DATE_START,2),'-01')),EDIP.DOS_FROM) >= 45\n",
    "                AND DATEDIFF(days, TO_DATE(CONCAT(LEFT(SCORE.DATA_DATE_START,4),'-',RIGHT(SCORE.DATA_DATE_START,2),'-01')),EDIP.DOS_FROM) <= 180\n",
    "    GROUP BY SCORE.MEMBER_ID,\n",
    "        DATE_START \n",
    "\n",
    "    )\n",
    "\n",
    "SELECT\n",
    "    //TO_DATE(CONCAT(LEFT(SCORE.DATA_DATE_START,4),'-',RIGHT(SCORE.DATA_DATE_START,2),'-01')) AS DATE_START,\n",
    "    //DATA_DATE_START,\n",
    "    //SCORE.MEMBER_ID,\n",
    "    CASE WHEN EDIPTABLE.ED_IP_VISITS_IN_NEXT_6_MONTHS > 0 THEN 1 ELSE 0 END as ED_IP_VISIT,\n",
    "    ACSC__COUNT,\n",
    "    ACSC__SCORE,\n",
    "    ACSC_A_FIB_AND_FLUTTER,\n",
    "    ACSC_ALCOHOL_RELATED,\n",
    "    ACSC_ANEMIA,\n",
    "    ACSC_ANGINA,\n",
    "    ACSC_ASTHMA,\n",
    "    ACSC_CELLULITIS,\n",
    "    ACSC_CONGESTIVE_HEART_FAILURE,\n",
    "    ACSC_CONSTIPATION,\n",
    "    ACSC_CONVULSION_EPILEPSY,\n",
    "    ACSC_COPD,\n",
    "    ACSC_DECUBITI_STAGE_3_,\n",
    "    ACSC_DEHYDRATION_GASTROENTERITIS,\n",
    "    ACSC_DIABETES_COMPLICATIONS,\n",
    "    ACSC_DYSPEPSIA,\n",
    "    ACSC_ENT_INFECTION,\n",
    "    ACSC_HYPERTENSION,\n",
    "    ACSC_HYPOGLYCEMIA,\n",
    "    ACSC_HYPOKALEMIA,\n",
    "    ACSC_INFLUENZA_PNEUMONIA,\n",
    "    ACSC_MIGRAINE_HEADACHE,\n",
    "    ACSC_NUTRITION_DEFICIENT,\n",
    "    ACSC_PERFORATED_BLEEDING_ULCER,\n",
    "    ACSC_PROXIMAL_FEMUR_FRACTURE,\n",
    "    ACSC_PYELONEPHRITIS,\n",
    "    ACSC_UTI,\n",
    "    ACSC_VACCINE_PREVENTABLE_DX,\n",
    "    DATEDIFF(year,DOB, TO_DATE(CONCAT(LEFT(SCORE.DATA_DATE_START,4),'-',RIGHT(SCORE.DATA_DATE_START,2),'-01'))) as AGE,\n",
    "    AMB_ACSC_COST,\n",
    "    AMB_ACSC_COUNT,\n",
    "    BH__COUNT,\n",
    "    BH__SCORE,\n",
    "    BH_ALTERED_MENTAL_STATE,\n",
    "    BH_ALZHEIMERS_DEMENTIA,\n",
    "    BH_ANXIETY,\n",
    "    BH_BI_POLAR,\n",
    "    BH_DEPRESSION,\n",
    "    BH_SCHIZOPHRENIA,\n",
    "    BH_SUBABUSE,\n",
    "    CRN__COUNT,\n",
    "    CRN_AFIB,\n",
    "    CRN_ASTHMA,\n",
    "    CRN_CARDIOVASCULAR_DX,\n",
    "    CRN_CHRONIC_KIDNEY_DISEASE,\n",
    "    CRN_CONGESTIVE_HEART_FAILURE,\n",
    "    CRN_COPD,\n",
    "    CRN_DIABETES_W__ACUTE_COMP,\n",
    "    CRN_DIABETES_W__CHRONIC_COMP,\n",
    "    CRN_DIABETES_W_OUT_COMP,\n",
    "    CRN_FALLS,\n",
    "    CRN_GASTRO_ESOPH_REFLUX,\n",
    "    CRN_HIP_FRACTURE,\n",
    "    CRN_HTN,\n",
    "    CRN_OBESITY,\n",
    "    CRN_OSTEOPOROSIS,\n",
    "    CRN_PARKINSONS_DISEASE,\n",
    "    CRN_PRESSURE_ULCER,\n",
    "    CRN_PRIOR_MI,\n",
    "    CRN_PRIOR_STROKE,\n",
    "    CRN_SCORE,\n",
    "    CRN_SLEEP_APNEA,\n",
    "    CRN_SMOKING,\n",
    "    CRN_UTI,\n",
    "    DYAD_CKD_DD,\n",
    "    DYAD_CKD_OP,\n",
    "    DYAD_COPD_DD,\n",
    "    DYAD_COPD_HF,\n",
    "    DYAD_COPD_OP,\n",
    "    DYAD_COUNT,\n",
    "    DYAD_DM_CKD,\n",
    "    DYAD_DM_OP,\n",
    "    DYAD_HBP_HF,\n",
    "    DYAD_HF_CKD,\n",
    "    ED_ACSC_COST,\n",
    "    ED_ACSC_COUNT,\n",
    "    GENDER,\n",
    "    CASE WHEN \"GROUP\" = 'E' THEN 'A' ELSE \"GROUP\" END as \"GROUP\",\n",
    "    HMKR_ACSC_COST,\n",
    "    HMKR_ACSC_COUNT,\n",
    "    HTI_RISK_SCORE_V2_1,\n",
    "    IP_ACSC_COST,\n",
    "    IP_ACSC_COUNT,\n",
    "    IP_READMIT_ACSC_COST,\n",
    "    IP_READMIT_ACSC_COUNT,\n",
    "    IP_RHB_ACSC_COST,\n",
    "    IP_RHB_ACSC_COUNT,\n",
    "    CASE WHEN LANGUAGE_SPOKEN is NULL THEN 'Unknown'\n",
    "         WHEN LANGUAGE_SPOKEN = 'English' THEN 'English'\n",
    "         WHEN LANGUAGE_SPOKEN = 'Chinese' THEN 'Chinese'\n",
    "         WHEN LANGUAGE_SPOKEN = 'Spanish' THEN 'Spanish'\n",
    "         WHEN LANGUAGE_SPOKEN = 'Russian' THEN 'Russian'\n",
    "    ELSE 'Other' END AS LANGUAGE_SPOKEN_CLEAN,\n",
    "    NI_COST_DENT,\n",
    "    NI_COST_ED,\n",
    "    NI_COST_HM,\n",
    "    NI_COST_HMKR,\n",
    "    NI_COST_HS,\n",
    "    NI_COST_IP,\n",
    "    NI_COST_IP_RHB,\n",
    "    NI_COST_OP,\n",
    "    NI_COST_OTH,\n",
    "    NI_COST_PCA_T1020,\n",
    "    NI_COST_PCA_T1019,\n",
    "    NI_COST_PR,\n",
    "    NI_COST_PSYC,\n",
    "    NI_COST_RX,\n",
    "    NI_COUNT_DENT,\n",
    "    NI_COUNT_ED,\n",
    "    NI_COUNT_HM,\n",
    "    NI_COUNT_HMKR,\n",
    "    NI_COUNT_HS,\n",
    "    NI_COUNT_IP,\n",
    "    NI_COUNT_IP_RHB,\n",
    "    NI_COUNT_OP,\n",
    "    NI_COUNT_OTH,\n",
    "    NI_COUNT_PCA_T1020,\n",
    "    NI_COUNT_PCA_T1019,\n",
    "    NI_COUNT_PR,\n",
    "    NI_COUNT_PSYC,\n",
    "    NI_COUNT_RX,\n",
    "    NON_IMPACTABLE_CLAIM_COUNT,\n",
    "    OP_ACSC_COST,\n",
    "    OP_ACSC_COUNT,\n",
    "    CAST(PART_C_RISK_SCORE as FLOAT) as PART_C_RISK_SCORE,\n",
    "    PCA_T1020_ACSC_COUNT,\n",
    "    PCA_T1020_ACSC_COST,\n",
    "    PCA_T1019_ACSC_COUNT,\n",
    "    PCA_T1019_ACSC_COST,\n",
    "    PR_ACSC_COST,\n",
    "    PR_ACSC_COUNT,\n",
    "    CASE WHEN RC is NULL THEN 'UNDEFINED' ELSE RC END AS RC_CLEAN,\n",
    "    SNF_COST,\n",
    "    SNF_COUNT,\n",
    "    TOTAL_IMPACTABLE_COST,\n",
    "    TOTAL_IMPACTABLE_COST_PRO,\n",
    "    TOTAL_NON_IMPACTABLE_COST\n",
    "FROM \"VESTA_DEVELOPMENT\".\"ANALYST_SANDBOX\".\"CLNT_STRAT_VIP\" SCORE\n",
    "    LEFT JOIN EDIPTABLE\n",
    "        ON SCORE.MEMBER_ID = EDIPTABLE.MEMBER_ID\n",
    "            AND TO_DATE(CONCAT(LEFT(SCORE.DATA_DATE_START,4),'-',RIGHT(SCORE.DATA_DATE_START,2),'-01')) = EDIPTABLE.DATE_START\n",
    "WHERE SCORE.CLNT = 'CCA' //THIS NEEDS TO CHANGE BASED ON CLIENT\n",
    "    AND TO_DATE(CONCAT(LEFT(SCORE.DATA_DATE_START,4),'-',RIGHT(SCORE.DATA_DATE_START,2),'-01')) \n",
    "    < TO_DATE(CONCAT(LEFT(CURRENT_DATE-210,7),'-01')) //This is looking at files that have had a reasonable amount of time to process'''\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(sql)\n",
    "    \n",
    "    # Dataframe creation\n",
    "    df = pd.DataFrame.from_records(iter(cursor), columns = [x[0] for x in cursor.description])\n",
    "    \n",
    "    print('Successful DataFrame Created')\n",
    "    \n",
    "    cursor.close\n",
    "    \n",
    "except Exception as e:\n",
    "        print(e)\n",
    "        \n",
    "finally:\n",
    "    conn.close\n",
    "    \n",
    "print('Ready for Cleaning')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "   ED_IP_VISIT  ACSC__COUNT  ACSC__SCORE  ACSC_A_FIB_AND_FLUTTER  \\\n0            0          0.0          0.0                     0.0   \n1            0          0.0          0.0                     0.0   \n2            0          0.0          0.0                     0.0   \n3            0          0.0          0.0                     0.0   \n4            0          0.0          0.0                     0.0   \n5            0          0.0          0.0                     0.0   \n6            0          0.0          0.0                     0.0   \n7            1          0.0          0.0                     0.0   \n8            0          0.0          0.0                     0.0   \n9            0          0.0          0.0                     0.0   \n\n   ACSC_ALCOHOL_RELATED  ACSC_ANEMIA  ACSC_ANGINA  ACSC_ASTHMA  \\\n0                   0.0          0.0          0.0          NaN   \n1                   0.0          0.0          0.0          NaN   \n2                   0.0          0.0          0.0          NaN   \n3                   0.0          0.0          0.0          NaN   \n4                   0.0          0.0          0.0          NaN   \n5                   0.0          0.0          0.0          NaN   \n6                   0.0          0.0          0.0          NaN   \n7                   0.0          0.0          0.0          NaN   \n8                   0.0          0.0          0.0          NaN   \n9                   0.0          0.0          0.0          NaN   \n\n   ACSC_CELLULITIS  ACSC_CONGESTIVE_HEART_FAILURE  ...  PCA_T1019_ACSC_COUNT  \\\n0              NaN                            0.0  ...                   0.0   \n1              NaN                            0.0  ...                   0.0   \n2              NaN                            0.0  ...                   0.0   \n3              NaN                            0.0  ...                   0.0   \n4              NaN                            0.0  ...                   0.0   \n5              NaN                            0.0  ...                   0.0   \n6              NaN                            0.0  ...                   0.0   \n7              NaN                            0.0  ...                   0.0   \n8              NaN                            0.0  ...                   0.0   \n9              NaN                            0.0  ...                   0.0   \n\n   PCA_T1019_ACSC_COST  PR_ACSC_COST  PR_ACSC_COUNT  RC_CLEAN  SNF_COST  \\\n0                  0.0           0.0            0.0    AD/CMI       0.0   \n1                  0.0           0.0            0.0       NHC       0.0   \n2                  0.0           0.0            0.0       NHC       0.0   \n3                  0.0           0.0            0.0       NHC       0.0   \n4                  0.0           0.0            0.0       NHC       0.0   \n5                  0.0           0.0            0.0     Other       0.0   \n6                  0.0           0.0            0.0       NHC       0.0   \n7                  0.0           0.0            0.0    AD/CMI       0.0   \n8                  0.0           0.0            0.0     Other       0.0   \n9                  0.0           0.0            0.0       NHC       0.0   \n\n   SNF_COUNT  TOTAL_IMPACTABLE_COST  TOTAL_IMPACTABLE_COST_PRO  \\\n0        0.0                    0.0                        0.0   \n1        0.0                    0.0                        0.0   \n2        0.0                    0.0                        0.0   \n3        0.0                    0.0                        0.0   \n4        0.0                    0.0                        0.0   \n5        0.0                    0.0                        0.0   \n6        0.0                    0.0                        0.0   \n7        0.0                    0.0                        0.0   \n8        0.0                    0.0                        0.0   \n9        0.0                    0.0                        0.0   \n\n   TOTAL_NON_IMPACTABLE_COST  \n0                    2260.04  \n1                       0.00  \n2                       0.00  \n3                       0.00  \n4                       0.00  \n5                       0.00  \n6                       0.00  \n7                     596.32  \n8                       0.00  \n9                       0.00  \n\n[10 rows x 133 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ED_IP_VISIT</th>\n      <th>ACSC__COUNT</th>\n      <th>ACSC__SCORE</th>\n      <th>ACSC_A_FIB_AND_FLUTTER</th>\n      <th>ACSC_ALCOHOL_RELATED</th>\n      <th>ACSC_ANEMIA</th>\n      <th>ACSC_ANGINA</th>\n      <th>ACSC_ASTHMA</th>\n      <th>ACSC_CELLULITIS</th>\n      <th>ACSC_CONGESTIVE_HEART_FAILURE</th>\n      <th>...</th>\n      <th>PCA_T1019_ACSC_COUNT</th>\n      <th>PCA_T1019_ACSC_COST</th>\n      <th>PR_ACSC_COST</th>\n      <th>PR_ACSC_COUNT</th>\n      <th>RC_CLEAN</th>\n      <th>SNF_COST</th>\n      <th>SNF_COUNT</th>\n      <th>TOTAL_IMPACTABLE_COST</th>\n      <th>TOTAL_IMPACTABLE_COST_PRO</th>\n      <th>TOTAL_NON_IMPACTABLE_COST</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>AD/CMI</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2260.04</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NHC</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NHC</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NHC</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NHC</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>Other</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NHC</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>1</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>AD/CMI</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>596.32</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>Other</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NHC</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.00</td>\n    </tr>\n  </tbody>\n</table>\n<p>10 rows × 133 columns</p>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Cleaning Operations"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These are the features that initially had missing values within the data frame: \n",
      " ['ACSC_A_FIB_AND_FLUTTER', 'ACSC_ALCOHOL_RELATED', 'ACSC_ANEMIA', 'ACSC_ANGINA', 'ACSC_ASTHMA', 'ACSC_CELLULITIS', 'ACSC_CONSTIPATION', 'ACSC_CONVULSION_EPILEPSY', 'ACSC_DECUBITI_STAGE_3_', 'ACSC_DEHYDRATION_GASTROENTERITIS', 'ACSC_ENT_INFECTION', 'ACSC_HYPOGLYCEMIA', 'ACSC_HYPOKALEMIA', 'ACSC_MIGRAINE_HEADACHE', 'ACSC_PERFORATED_BLEEDING_ULCER', 'ACSC_PROXIMAL_FEMUR_FRACTURE', 'ACSC_PYELONEPHRITIS', 'ACSC_VACCINE_PREVENTABLE_DX', 'CRN_PRIOR_MI', 'CRN_SMOKING', 'NI_COST_HS', 'NI_COST_IP_RHB', 'NI_COST_PSYC', 'NI_COUNT_HS', 'NI_COUNT_IP_RHB', 'NI_COUNT_PSYC'] \n",
      "\n",
      "\n",
      "These columns were dropped after because missing values were not corrected :\n",
      " [] \n",
      "\n",
      "\n",
      "These are the features that were converted to dummy variables: \n",
      " ['GENDER', 'GROUP', 'LANGUAGE_SPOKEN_CLEAN', 'RC_CLEAN'] \n",
      "\n",
      "\n",
      "ED_IP_VISIT                        int64\n",
      "ACSC__COUNT                      float64\n",
      "ACSC__SCORE                      float64\n",
      "ACSC_A_FIB_AND_FLUTTER           float64\n",
      "ACSC_ALCOHOL_RELATED             float64\n",
      "                                  ...   \n",
      "LANGUAGE_SPOKEN_CLEAN_Spanish      uint8\n",
      "LANGUAGE_SPOKEN_CLEAN_Unknown      uint8\n",
      "RC_CLEAN_Institutional             uint8\n",
      "RC_CLEAN_NHC                       uint8\n",
      "RC_CLEAN_Other                     uint8\n",
      "Length: 141, dtype: object\n",
      "Memory Usage of Dataframe: 81919676 bytes\n"
     ]
    },
    {
     "data": {
      "text/plain": "   ED_IP_VISIT  ACSC__COUNT  ACSC__SCORE  ACSC_A_FIB_AND_FLUTTER  \\\n0            0          0.0          0.0                     0.0   \n1            0          0.0          0.0                     0.0   \n2            0          0.0          0.0                     0.0   \n3            0          0.0          0.0                     0.0   \n4            0          0.0          0.0                     0.0   \n\n   ACSC_ALCOHOL_RELATED  ACSC_ANEMIA  ACSC_ANGINA  ACSC_ASTHMA  \\\n0                   0.0          0.0          0.0          0.0   \n1                   0.0          0.0          0.0          0.0   \n2                   0.0          0.0          0.0          0.0   \n3                   0.0          0.0          0.0          0.0   \n4                   0.0          0.0          0.0          0.0   \n\n   ACSC_CELLULITIS  ACSC_CONGESTIVE_HEART_FAILURE  ...  GROUP_B  GROUP_C  \\\n0              0.0                            0.0  ...        0        0   \n1              0.0                            0.0  ...        0        0   \n2              0.0                            0.0  ...        0        0   \n3              0.0                            0.0  ...        0        0   \n4              0.0                            0.0  ...        0        0   \n\n   GROUP_D  LANGUAGE_SPOKEN_CLEAN_Other  LANGUAGE_SPOKEN_CLEAN_Russian  \\\n0        1                            0                              0   \n1        1                            0                              0   \n2        1                            1                              0   \n3        1                            0                              0   \n4        1                            0                              0   \n\n   LANGUAGE_SPOKEN_CLEAN_Spanish  LANGUAGE_SPOKEN_CLEAN_Unknown  \\\n0                              1                              0   \n1                              1                              0   \n2                              0                              0   \n3                              0                              0   \n4                              0                              0   \n\n   RC_CLEAN_Institutional  RC_CLEAN_NHC  RC_CLEAN_Other  \n0                       0             0               0  \n1                       0             1               0  \n2                       0             1               0  \n3                       0             1               0  \n4                       0             1               0  \n\n[5 rows x 141 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ED_IP_VISIT</th>\n      <th>ACSC__COUNT</th>\n      <th>ACSC__SCORE</th>\n      <th>ACSC_A_FIB_AND_FLUTTER</th>\n      <th>ACSC_ALCOHOL_RELATED</th>\n      <th>ACSC_ANEMIA</th>\n      <th>ACSC_ANGINA</th>\n      <th>ACSC_ASTHMA</th>\n      <th>ACSC_CELLULITIS</th>\n      <th>ACSC_CONGESTIVE_HEART_FAILURE</th>\n      <th>...</th>\n      <th>GROUP_B</th>\n      <th>GROUP_C</th>\n      <th>GROUP_D</th>\n      <th>LANGUAGE_SPOKEN_CLEAN_Other</th>\n      <th>LANGUAGE_SPOKEN_CLEAN_Russian</th>\n      <th>LANGUAGE_SPOKEN_CLEAN_Spanish</th>\n      <th>LANGUAGE_SPOKEN_CLEAN_Unknown</th>\n      <th>RC_CLEAN_Institutional</th>\n      <th>RC_CLEAN_NHC</th>\n      <th>RC_CLEAN_Other</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 141 columns</p>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find features with missing values\n",
    "sumdf = pd.DataFrame(df.isna().sum())\n",
    "\n",
    "features_to_drop = []\n",
    "for row in sumdf.iterrows():\n",
    "    if row[1][0] != 0:\n",
    "        features_to_drop.append(row[0])\n",
    "\n",
    "# Review features with missing values\n",
    "print('These are the features that initially had missing values within the data frame: \\n',features_to_drop,'\\n\\n')\n",
    "\n",
    "Nulls_to_correct = ['ACSC_A_FIB_AND_FLUTTER', 'ACSC_ALCOHOL_RELATED', 'ACSC_ANEMIA', 'ACSC_ANGINA', \n",
    "                    'ACSC_ASTHMA', 'ACSC_CELLULITIS', 'ACSC_CONSTIPATION', 'ACSC_CONVULSION_EPILEPSY', \n",
    "                    'ACSC_DECUBITI_STAGE_3_', 'ACSC_DEHYDRATION_GASTROENTERITIS', 'ACSC_ENT_INFECTION', \n",
    "                    'ACSC_HYPOGLYCEMIA', 'ACSC_HYPOKALEMIA', 'ACSC_MIGRAINE_HEADACHE', 'ACSC_PERFORATED_BLEEDING_ULCER', \n",
    "                    'ACSC_PROXIMAL_FEMUR_FRACTURE', 'ACSC_PYELONEPHRITIS', 'ACSC_VACCINE_PREVENTABLE_DX', 'BH_SUBABUSE', \n",
    "                    'CRN_PRIOR_MI', 'CRN_SMOKING', 'NI_COST_DENT', 'NI_COST_HMKR', 'NI_COST_HS', 'NI_COST_IP_RHB', \n",
    "                    'NI_COST_PSYC', 'NI_COUNT_DENT', 'NI_COUNT_HMKR', 'NI_COUNT_HS', 'NI_COUNT_IP_RHB', 'NI_COUNT_PSYC'] \n",
    "\n",
    "# Fill selected features with 0 value\n",
    "for col in Nulls_to_correct:\n",
    "    df[col] = df[col].fillna(0)\n",
    "    \n",
    "# Check for missing values and drop columns with missing values\n",
    "sumdf = pd.DataFrame(df.isna().sum())\n",
    "\n",
    "features_to_drop = []\n",
    "for row in sumdf.iterrows():\n",
    "    if row[1][0] != 0:\n",
    "        features_to_drop.append(row[0])\n",
    "\n",
    "print('These columns were dropped after because missing values were not corrected :\\n', features_to_drop,'\\n\\n')        \n",
    "df = df.drop(columns = features_to_drop)\n",
    "\n",
    "# Convert object datatypes to dummy variables\n",
    "object_list = []\n",
    "\n",
    "for col in df.columns:\n",
    "    if df[col].dtypes == 'object':\n",
    "        object_list.append(col)\n",
    "        \n",
    "        \n",
    "print('These are the features that were converted to dummy variables: \\n',object_list,'\\n\\n')\n",
    "df = pd.get_dummies(df, columns = object_list, drop_first = True)\n",
    "\n",
    "print(df.dtypes)\n",
    "\n",
    "original_memory = df.memory_usage().sum()\n",
    "print(f'Memory Usage of Dataframe: {df.memory_usage().sum()} bytes')\n",
    "\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "#convert data types\n",
    "#changing all float64 to float32\n",
    "df[df.select_dtypes(np.float64).columns] = df.select_dtypes(np.float64).astype(np.float32)\n",
    "\n",
    "\n",
    "# df = df.astype('float32')\n",
    "#\n",
    "# df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory Usage of Original Dataframe: 81919676 bytes\n",
      "Memory Usage of New Dataframe: 42058440 bytes\n",
      "Memory usage reduced by:49.0%\n"
     ]
    }
   ],
   "source": [
    "new_memory = df.memory_usage().sum()\n",
    "print(f'Memory Usage of Original Dataframe: {original_memory} bytes')\n",
    "print(f'Memory Usage of New Dataframe: {new_memory} bytes')\n",
    "print(f'Memory usage reduced by:{round((original_memory-new_memory)/original_memory * 100,0)}%')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Option to remove low variability features\n",
    "\n",
    "This block is here to run as optional pre-processing. "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These are the features that were dropped because of low variability: \n",
      " [] \n",
      "\n",
      "\n",
      "Memory Usage of Dataframe: 42058440 bytes\n"
     ]
    }
   ],
   "source": [
    "# Drop low variability columns\n",
    "df_var = df.var()\n",
    "df.columns.to_list()\n",
    "\n",
    "features_to_drop = []\n",
    "\n",
    "for i in range(len(df.columns.to_list())):\n",
    "    #print(df.columns.to_list()[i],df_var[i])\n",
    "    if df_var[i] == 0 and df.columns.to_list()[i] != 'ED_IP_VISIT':\n",
    "        features_to_drop.append(df.columns.to_list()[i])\n",
    "\n",
    "        \n",
    "print('These are the features that were dropped because of low variability: \\n',features_to_drop,'\\n\\n')\n",
    "        \n",
    "df = df.drop(columns = features_to_drop)\n",
    "print(f'Memory Usage of Dataframe: {df.memory_usage().sum()} bytes')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Spliting, Scaling, and SMOTE (Synthetic Minority Oversampling Technique)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Split the data set\n",
    "X = df[[col for col in df.columns if col != 'ED_IP_VISIT']] #independent variables\n",
    "y = df[[col for col in df.columns if col == 'ED_IP_VISIT']] #dependent variable\n",
    "y = y.values.flatten()\n",
    "\n",
    "# Define MinMax Scaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Transform data\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Split X and y into training and testing sets\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.30, random_state = 2)\n",
    "\n",
    "# Smote for balancing the training data set\n",
    "smote = SMOTE(random_state = 2)\n",
    "X_train,y_train = smote.fit_resample(X_train, y_train)\n",
    "print(f'Memory Usage of Dataframe: {df.memory_usage().sum()} bytes')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Creating and Training Random Forest Classifier"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%time\n",
    "# Create a Random Forest Classifier\n",
    "clf=RandomForestClassifier(n_estimators = 2000,min_samples_split = 2, min_samples_leaf = 1,\n",
    "                           max_depth = 50, bootstrap = False, n_jobs = -1,random_state = 2)\n",
    "\n",
    "# Train the model using the training sets\n",
    "clf.fit(X_train,y_train)\n",
    "print(f'Memory Usage of Dataframe: {df.memory_usage().sum()} bytes')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Reporting on Performace"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Create probabilities from the model on test data\n",
    "y_prob = clf.predict_proba(X_test)[:,1]\n",
    "\n",
    "# Store probabilites in Datafram for threshold analysis\n",
    "threshold_list = [0.05,0.1,0.15,0.2,0.25,0.3,0.35,0.4,0.45,0.5,0.55,0.6,0.65,.7,.75,.8,.85,.9,.95,.99]\n",
    "accuracy_list = []\n",
    "precision_list = []\n",
    "recall_list = []\n",
    "for threshold in threshold_list:\n",
    "    y_pred = [1 if result >= threshold else 0 for result in y_prob]\n",
    "   \n",
    "    #Calulating Metrics\n",
    "    accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "    precision = metrics.precision_score(y_test, y_pred)\n",
    "    recall = metrics.recall_score(y_test, y_pred)\n",
    "    \n",
    "    accuracy_list.append(accuracy)\n",
    "    precision_list.append(precision)\n",
    "    recall_list.append(recall)\n",
    "    \n",
    "    #print('Thereshold: ',threshold)\n",
    "    #print(\"Accuracy: \",accuracy)\n",
    "    #print(\"Precision: \",precision)\n",
    "    #print(\"Recall: \",recall)\n",
    "    \n",
    "metric_df = pd.DataFrame()\n",
    "metric_df['Threshold'] = threshold_list\n",
    "metric_df['Accuracy'] = accuracy_list\n",
    "metric_df['Precision'] = precision_list\n",
    "metric_df['Recall'] = recall_list\n",
    "metric_df['F1'] = (2 * metric_df['Precision'] * metric_df['Recall']) / (metric_df['Precision'] + metric_df['Recall'])\n",
    "metric_df['Acc + Recall'] = metric_df['Accuracy'] + metric_df['Recall']\n",
    "\n",
    "metric_df\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "metric_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Confusion Matrix for Threshold with Max Accuracy + Recall"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Find the max accuracy and recall from the Metric Table and corresponding Threshold\n",
    "threshold = metric_df[metric_df['Acc + Recall'] == metric_df['Acc + Recall'].max()]['Threshold'].item()\n",
    "\n",
    "y_pred = [1 if result >= threshold else 0 for result in y_prob]\n",
    "\n",
    "\n",
    "# Creating confusion maxtrix\n",
    "cnf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "\n",
    "%matplotlib inline\n",
    "class_names=[0,1]\n",
    "fig, ax = plt.subplots()\n",
    "tick_marks = np.arange(len(class_names))\n",
    "plt.xticks(tick_marks, class_names)\n",
    "plt.yticks(tick_marks, class_names)\n",
    "\n",
    "# Create heatmap\n",
    "sns.heatmap(pd.DataFrame(cnf_matrix), annot=True, cmap=\"YlGnBu\" ,fmt='g')\n",
    "ax.xaxis.set_label_position(\"top\")\n",
    "\n",
    "# Axis labels\n",
    "plt.tight_layout()\n",
    "plt.title('Confusion matrix', y=1.1)\n",
    "plt.ylabel('Actual label')\n",
    "plt.xlabel('Predicted label')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#Calulating Metrics\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "precision = metrics.precision_score(y_test, y_pred)\n",
    "recall = metrics.recall_score(y_test, y_pred)\n",
    "    \n",
    "print('Thereshold: ',threshold)\n",
    "print(\"Accuracy: \",accuracy)\n",
    "print(\"Precision: \",precision)\n",
    "print(\"Recall: \",recall)\n",
    "print('F1: ', (2*precision*recall)/(precision+recall))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### ROC and AUC and Precision-Recall Curve"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = metrics.roc_curve(y_test,  y_prob)\n",
    "\n",
    "# Print(thresholds)\n",
    "auc = metrics.roc_auc_score(y_test, y_prob)\n",
    "plt.plot(fpr,tpr,label=\"data 1, auc=\"+str(auc))\n",
    "plt.plot([0, 1], [0, 1], color=\"red\", linestyle=\"--\")\n",
    "\n",
    "# Axis labels\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend()\n",
    "\n",
    "# Show the legend\n",
    "plt.legend(loc=4)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n",
    "# Calculate precision and recall for each threshold\n",
    "precision, recall, _ = metrics.precision_recall_curve(y_test, y_prob)\n",
    "\n",
    "# Calculate scores\n",
    "f1, auc = metrics.f1_score(y_test, y_pred), metrics.auc(recall, precision)\n",
    "\n",
    "# Plot the precision-recall curves\n",
    "no_skill = len(y_test[y_test==1]) / len(y_test)\n",
    "plt.plot([0, 1], [no_skill, no_skill], linestyle='--', label='No Skill')\n",
    "plt.plot(recall, precision, marker='.', label='Random Forest')\n",
    "\n",
    "# Axis labels\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "\n",
    "# Show the legend\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Ensemble of Random Forests"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 197.70816588401794 seconds ---\n",
      "--- 207.57880854606628 seconds ---\n",
      "--- 225.59165978431702 seconds ---\n",
      "--- 231.6109480857849 seconds ---\n",
      "--- 259.80773758888245 seconds ---\n",
      "--- 286.9357554912567 seconds ---\n",
      "--- 265.2345254421234 seconds ---\n",
      "--- 233.0310661792755 seconds ---\n",
      "--- 221.3514757156372 seconds ---\n",
      "--- 250.0125880241394 seconds ---\n"
     ]
    }
   ],
   "source": [
    "forest_dict = {}\n",
    "\n",
    "for i in range(0,10):\n",
    "    start_time = time.time()\n",
    "    # Split the data set\n",
    "    X = df[[col for col in df.columns if col != 'ED_IP_VISIT']] #independent variables\n",
    "    y = df[[col for col in df.columns if col == 'ED_IP_VISIT']] #dependent variable\n",
    "    y = y.values.flatten()\n",
    "\n",
    "    # Define MinMax Scaler\n",
    "    scaler = MinMaxScaler()\n",
    "\n",
    "    # Transform data\n",
    "    X = scaler.fit_transform(X)\n",
    "\n",
    "    # Split X and y into training and testing sets\n",
    "    X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.30, random_state = i)\n",
    "\n",
    "    # Smote for balancing the training data set\n",
    "    smote = SMOTE(random_state = i)\n",
    "    X_train,y_train = smote.fit_resample(X_train, y_train)\n",
    "    \n",
    "    # Create a Random Forest Classifier\n",
    "    clf=RandomForestClassifier(n_estimators = 2000,min_samples_split = 2, min_samples_leaf = 1,\n",
    "                               max_depth = 50, bootstrap = False, n_jobs = -1,random_state = i)\n",
    "\n",
    "    # Train the model using the training sets\n",
    "    clf.fit(X_train,y_train)\n",
    "    \n",
    "    #Store Random Forest\n",
    "    forest_dict[i] = clf\n",
    "    \n",
    "    print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "    \n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### New Query for Prediction"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[1;32mIn [1]\u001B[0m, in \u001B[0;36m<cell line: 3>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# Snowflake credentials stored in environment variables\u001B[39;00m\n\u001B[1;32m----> 3\u001B[0m username \u001B[38;5;241m=\u001B[39m \u001B[43mos\u001B[49m\u001B[38;5;241m.\u001B[39mgetenv(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mSnowflake_User\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m      4\u001B[0m password \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mgetenv(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mSnowflake_password\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m      5\u001B[0m account \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mgetenv(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mSnowflake_account\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "# Snowflake credentials stored in environment variables\n",
    "\n",
    "username = os.getenv('Snowflake_User')\n",
    "password = os.getenv('Snowflake_password')\n",
    "account = os.getenv('Snowflake_account')\n",
    "\n",
    "# Define warehouse, if neccessary\n",
    "warehouse = 'DEVELOPER_BASIC'\n",
    "\n",
    "# Define Database, if not defined in SQL request\n",
    "#database = 'VESTA_STAGING'\n",
    "\n",
    "# Create connection object for Snowflake connection\n",
    "conn = sf.connect(user = username, password = password, account = account, warehouse = warehouse)\n",
    "\n",
    "# Execution function\n",
    "def execute_query(connection,query):\n",
    "    cursor = connection.cursor()\n",
    "    cursor.execute(query)\n",
    "    cursor.close\n",
    "\n",
    "try:\n",
    "    # If defining a database, uncomment code set and add database in connection parameter\n",
    "    #sql = 'use {}'.format(database)\n",
    "    #execute_query(conn,sql)\n",
    "    \n",
    "    # Define warehouse to use in Snowflake\n",
    "    sql = 'use warehouse {}'.format(warehouse)\n",
    "    execute_query(conn,sql)\n",
    "    \n",
    "    print('Successful Connection')\n",
    "    \n",
    "    # Query to Snowflake\n",
    "    sql = '''\n",
    "WITH EDIP AS ( //This is sub table for a self join\n",
    "\n",
    "    SELECT \n",
    "        *\n",
    "    FROM \"VESTA_DEVELOPMENT\".\"CLAIMS_REPORTING\".\"CCA_MEM_PROFILE_IP_ER_SNF\" //THIS NEEDS TO CHANGE BASED ON CLIENT\n",
    "    WHERE MEASURE = 'ED' or MEASURE = 'IP' \n",
    "\n",
    "    ),\n",
    "\n",
    "EDIPTABLE AS ( //This table shows the Member ID, date start, and the number of ED/IP in the next 6 months\n",
    "\n",
    "    SELECT\n",
    "        SCORE.MEMBER_ID,\n",
    "        TO_DATE(CONCAT(LEFT(SCORE.DATA_DATE_START,4),'-',RIGHT(SCORE.DATA_DATE_START,2),'-01')) AS DATE_START,\n",
    "        COUNT(DISTINCT EDIP.DOS_FROM) AS ED_IP_VISITS_IN_NEXT_6_MONTHS\n",
    "    FROM \"VESTA_DEVELOPMENT\".\"ANALYST_SANDBOX\".\"CLNT_STRAT_VIP\" SCORE\n",
    "        LEFT JOIN EDIP \n",
    "            ON SCORE.MEMBER_ID = EDIP.MEMBER_ID\n",
    "                AND EDIP.DOS_FROM > TO_DATE(CONCAT(LEFT(SCORE.DATA_DATE_START,4),'-',RIGHT(SCORE.DATA_DATE_START,2),'-01'))\n",
    "                AND DATEDIFF(days,TO_DATE(CONCAT(LEFT(SCORE.DATA_DATE_START,4),'-',RIGHT(SCORE.DATA_DATE_START,2),'-01')),EDIP.DOS_FROM) >= 45\n",
    "                AND DATEDIFF(days, TO_DATE(CONCAT(LEFT(SCORE.DATA_DATE_START,4),'-',RIGHT(SCORE.DATA_DATE_START,2),'-01')),EDIP.DOS_FROM) <= 180\n",
    "    GROUP BY SCORE.MEMBER_ID,\n",
    "        DATE_START \n",
    "\n",
    "    )\n",
    "\n",
    "SELECT\n",
    "    TO_DATE(CONCAT(LEFT(SCORE.DATA_DATE_START,4),'-',RIGHT(SCORE.DATA_DATE_START,2),'-01')) AS DATE_START,\n",
    "    //DATA_DATE_START,\n",
    "    SCORE.MEMBER_ID,\n",
    "    CASE WHEN EDIPTABLE.ED_IP_VISITS_IN_NEXT_6_MONTHS > 0 THEN 1 ELSE 0 END as ED_IP_VISIT,\n",
    "    ACSC__COUNT,\n",
    "    ACSC__SCORE,\n",
    "    ACSC_A_FIB_AND_FLUTTER,\n",
    "    ACSC_ALCOHOL_RELATED,\n",
    "    ACSC_ANEMIA,\n",
    "    ACSC_ANGINA,\n",
    "    ACSC_ASTHMA,\n",
    "    ACSC_CELLULITIS,\n",
    "    ACSC_CONGESTIVE_HEART_FAILURE,\n",
    "    ACSC_CONSTIPATION,\n",
    "    ACSC_CONVULSION_EPILEPSY,\n",
    "    ACSC_COPD,\n",
    "    ACSC_DECUBITI_STAGE_3_,\n",
    "    ACSC_DEHYDRATION_GASTROENTERITIS,\n",
    "    ACSC_DIABETES_COMPLICATIONS,\n",
    "    ACSC_DYSPEPSIA,\n",
    "    ACSC_ENT_INFECTION,\n",
    "    ACSC_HYPERTENSION,\n",
    "    ACSC_HYPOGLYCEMIA,\n",
    "    ACSC_HYPOKALEMIA,\n",
    "    ACSC_INFLUENZA_PNEUMONIA,\n",
    "    ACSC_MIGRAINE_HEADACHE,\n",
    "    ACSC_NUTRITION_DEFICIENT,\n",
    "    ACSC_PERFORATED_BLEEDING_ULCER,\n",
    "    ACSC_PROXIMAL_FEMUR_FRACTURE,\n",
    "    ACSC_PYELONEPHRITIS,\n",
    "    ACSC_UTI,\n",
    "    ACSC_VACCINE_PREVENTABLE_DX,\n",
    "    DATEDIFF(year,DOB, TO_DATE(CONCAT(LEFT(SCORE.DATA_DATE_START,4),'-',RIGHT(SCORE.DATA_DATE_START,2),'-01'))) as AGE,\n",
    "    AMB_ACSC_COST,\n",
    "    AMB_ACSC_COUNT,\n",
    "    BH__COUNT,\n",
    "    BH__SCORE,\n",
    "    BH_ALTERED_MENTAL_STATE,\n",
    "    BH_ALZHEIMERS_DEMENTIA,\n",
    "    BH_ANXIETY,\n",
    "    BH_BI_POLAR,\n",
    "    BH_DEPRESSION,\n",
    "    BH_SCHIZOPHRENIA,\n",
    "    BH_SUBABUSE,\n",
    "    CRN__COUNT,\n",
    "    CRN_AFIB,\n",
    "    CRN_ASTHMA,\n",
    "    CRN_CARDIOVASCULAR_DX,\n",
    "    CRN_CHRONIC_KIDNEY_DISEASE,\n",
    "    CRN_CONGESTIVE_HEART_FAILURE,\n",
    "    CRN_COPD,\n",
    "    CRN_DIABETES_W__ACUTE_COMP,\n",
    "    CRN_DIABETES_W__CHRONIC_COMP,\n",
    "    CRN_DIABETES_W_OUT_COMP,\n",
    "    CRN_FALLS,\n",
    "    CRN_GASTRO_ESOPH_REFLUX,\n",
    "    CRN_HIP_FRACTURE,\n",
    "    CRN_HTN,\n",
    "    CRN_OBESITY,\n",
    "    CRN_OSTEOPOROSIS,\n",
    "    CRN_PARKINSONS_DISEASE,\n",
    "    CRN_PRESSURE_ULCER,\n",
    "    CRN_PRIOR_MI,\n",
    "    CRN_PRIOR_STROKE,\n",
    "    CRN_SCORE,\n",
    "    CRN_SLEEP_APNEA,\n",
    "    CRN_SMOKING,\n",
    "    CRN_UTI,\n",
    "    DYAD_CKD_DD,\n",
    "    DYAD_CKD_OP,\n",
    "    DYAD_COPD_DD,\n",
    "    DYAD_COPD_HF,\n",
    "    DYAD_COPD_OP,\n",
    "    DYAD_COUNT,\n",
    "    DYAD_DM_CKD,\n",
    "    DYAD_DM_OP,\n",
    "    DYAD_HBP_HF,\n",
    "    DYAD_HF_CKD,\n",
    "    ED_ACSC_COST,\n",
    "    ED_ACSC_COUNT,\n",
    "    GENDER,\n",
    "    CASE WHEN \"GROUP\" = 'E' THEN 'A' ELSE \"GROUP\" END as \"GROUP\",\n",
    "    HMKR_ACSC_COST,\n",
    "    HMKR_ACSC_COUNT,\n",
    "    HTI_RISK_SCORE_V2_1,\n",
    "    IP_ACSC_COST,\n",
    "    IP_ACSC_COUNT,\n",
    "    IP_READMIT_ACSC_COST,\n",
    "    IP_READMIT_ACSC_COUNT,\n",
    "    IP_RHB_ACSC_COST,\n",
    "    IP_RHB_ACSC_COUNT,\n",
    "    CASE WHEN LANGUAGE_SPOKEN is NULL THEN 'Unknown'\n",
    "         WHEN LANGUAGE_SPOKEN = 'English' THEN 'English'\n",
    "         WHEN LANGUAGE_SPOKEN = 'Chinese' THEN 'Chinese'\n",
    "         WHEN LANGUAGE_SPOKEN = 'Spanish' THEN 'Spanish'\n",
    "         WHEN LANGUAGE_SPOKEN = 'Russian' THEN 'Russian'\n",
    "    ELSE 'Other' END AS LANGUAGE_SPOKEN_CLEAN,\n",
    "    NI_COST_DENT,\n",
    "    NI_COST_ED,\n",
    "    NI_COST_HM,\n",
    "    NI_COST_HMKR,\n",
    "    NI_COST_HS,\n",
    "    NI_COST_IP,\n",
    "    NI_COST_IP_RHB,\n",
    "    NI_COST_OP,\n",
    "    NI_COST_OTH,\n",
    "    NI_COST_PCA_T1020,\n",
    "    NI_COST_PCA_T1019,\n",
    "    NI_COST_PR,\n",
    "    NI_COST_PSYC,\n",
    "    NI_COST_RX,\n",
    "    NI_COUNT_DENT,\n",
    "    NI_COUNT_ED,\n",
    "    NI_COUNT_HM,\n",
    "    NI_COUNT_HMKR,\n",
    "    NI_COUNT_HS,\n",
    "    NI_COUNT_IP,\n",
    "    NI_COUNT_IP_RHB,\n",
    "    NI_COUNT_OP,\n",
    "    NI_COUNT_OTH,\n",
    "    NI_COUNT_PCA_T1020,\n",
    "    NI_COUNT_PCA_T1019,\n",
    "    NI_COUNT_PR,\n",
    "    NI_COUNT_PSYC,\n",
    "    NI_COUNT_RX,\n",
    "    NON_IMPACTABLE_CLAIM_COUNT,\n",
    "    OP_ACSC_COST,\n",
    "    OP_ACSC_COUNT,\n",
    "    CAST(PART_C_RISK_SCORE as FLOAT) as PART_C_RISK_SCORE,\n",
    "    PCA_T1020_ACSC_COUNT,\n",
    "    PCA_T1020_ACSC_COST,\n",
    "    PCA_T1019_ACSC_COUNT,\n",
    "    PCA_T1019_ACSC_COST,\n",
    "    PR_ACSC_COST,\n",
    "    PR_ACSC_COUNT,\n",
    "    CASE WHEN RC is NULL THEN 'UNDEFINED' ELSE RC END AS RC_CLEAN,\n",
    "    SNF_COST,\n",
    "    SNF_COUNT,\n",
    "    TOTAL_IMPACTABLE_COST,\n",
    "    TOTAL_IMPACTABLE_COST_PRO,\n",
    "    TOTAL_NON_IMPACTABLE_COST\n",
    "FROM \"VESTA_DEVELOPMENT\".\"ANALYST_SANDBOX\".\"CLNT_STRAT_VIP\" SCORE\n",
    "    LEFT JOIN EDIPTABLE\n",
    "        ON SCORE.MEMBER_ID = EDIPTABLE.MEMBER_ID\n",
    "            AND TO_DATE(CONCAT(LEFT(SCORE.DATA_DATE_START,4),'-',RIGHT(SCORE.DATA_DATE_START,2),'-01')) = EDIPTABLE.DATE_START\n",
    "WHERE SCORE.CLNT = 'CCA' //THIS NEEDS TO CHANGE BASED ON CLIENT\n",
    "    AND TO_DATE(CONCAT(LEFT(SCORE.DATA_DATE_START,4),'-',RIGHT(SCORE.DATA_DATE_START,2),'-01')) \n",
    "        = (SELECT max(TO_DATE(CONCAT(LEFT(DATA_DATE_START,4),'-',RIGHT(DATA_DATE_START,2),'-01'))) FROM \"VESTA_DEVELOPMENT\".\"ANALYST_SANDBOX\".\"CLNT_STRAT_VIP\" WHERE CLNT = 'CCA') \n",
    "        // Most Recent Stratification for Client// THIS NEEDS TO CHANGE BASED ON CLIENT'''\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(sql)\n",
    "    \n",
    "    # Dataframe creation\n",
    "    test_df = pd.DataFrame.from_records(iter(cursor), columns = [x[0] for x in cursor.description])\n",
    "    \n",
    "    print('Successful DataFrame Created')\n",
    "    \n",
    "    cursor.close\n",
    "    \n",
    "except Exception as e:\n",
    "        print(e)\n",
    "        \n",
    "finally:\n",
    "    conn.close\n",
    "    \n",
    "print('Ready for Cleaning')  \n",
    "\n",
    "print(test_df.shape)\n",
    "test_df.head()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Cleaning Operations"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These are the features that initially had missing values within the data frame: \n",
      " ['ACSC_ANEMIA', 'ACSC_CELLULITIS', 'ACSC_CONSTIPATION', 'ACSC_DECUBITI_STAGE_3_', 'ACSC_HYPOGLYCEMIA', 'ACSC_HYPOKALEMIA', 'ACSC_PERFORATED_BLEEDING_ULCER', 'ACSC_VACCINE_PREVENTABLE_DX', 'CRN_SMOKING'] \n",
      "\n",
      "\n",
      "These columns were dropped after because missing values were not corrected :\n",
      " [] \n",
      "\n",
      "\n",
      "These are the features that were converted to dummy variables: \n",
      " ['GENDER', 'GROUP', 'LANGUAGE_SPOKEN_CLEAN', 'RC_CLEAN'] \n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "   ACSC__COUNT  ACSC__SCORE  ACSC_A_FIB_AND_FLUTTER  ACSC_ALCOHOL_RELATED  \\\n0          0.0          0.0                     0.0                   0.0   \n1          0.0          0.0                     0.0                   0.0   \n2          0.0          0.0                     0.0                   0.0   \n3          0.0          0.0                     0.0                   0.0   \n4          0.0          0.0                     0.0                   0.0   \n\n   ACSC_ANEMIA  ACSC_ANGINA  ACSC_ASTHMA  ACSC_CELLULITIS  \\\n0            0          0.0          0.0                0   \n1            0          0.0          0.0                0   \n2            0          0.0          0.0                0   \n3            0          0.0          0.0                0   \n4            0          0.0          0.0                0   \n\n   ACSC_CONGESTIVE_HEART_FAILURE  ACSC_CONSTIPATION  ...  GROUP_B  GROUP_C  \\\n0                            0.0                  0  ...        0        1   \n1                            0.0                  0  ...        0        0   \n2                            0.0                  0  ...        0        0   \n3                            0.0                  0  ...        0        0   \n4                            0.0                  0  ...        0        0   \n\n   GROUP_D  LANGUAGE_SPOKEN_CLEAN_Other  LANGUAGE_SPOKEN_CLEAN_Russian  \\\n0        0                            0                              0   \n1        0                            0                              0   \n2        0                            0                              1   \n3        0                            0                              0   \n4        0                            0                              0   \n\n   LANGUAGE_SPOKEN_CLEAN_Spanish  LANGUAGE_SPOKEN_CLEAN_Unknown  \\\n0                              0                              1   \n1                              1                              0   \n2                              0                              0   \n3                              0                              0   \n4                              1                              0   \n\n   RC_CLEAN_Institutional  RC_CLEAN_NHC  RC_CLEAN_Other  \n0                       0             0               0  \n1                       0             1               0  \n2                       0             1               0  \n3                       0             1               0  \n4                       0             1               0  \n\n[5 rows x 140 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ACSC__COUNT</th>\n      <th>ACSC__SCORE</th>\n      <th>ACSC_A_FIB_AND_FLUTTER</th>\n      <th>ACSC_ALCOHOL_RELATED</th>\n      <th>ACSC_ANEMIA</th>\n      <th>ACSC_ANGINA</th>\n      <th>ACSC_ASTHMA</th>\n      <th>ACSC_CELLULITIS</th>\n      <th>ACSC_CONGESTIVE_HEART_FAILURE</th>\n      <th>ACSC_CONSTIPATION</th>\n      <th>...</th>\n      <th>GROUP_B</th>\n      <th>GROUP_C</th>\n      <th>GROUP_D</th>\n      <th>LANGUAGE_SPOKEN_CLEAN_Other</th>\n      <th>LANGUAGE_SPOKEN_CLEAN_Russian</th>\n      <th>LANGUAGE_SPOKEN_CLEAN_Spanish</th>\n      <th>LANGUAGE_SPOKEN_CLEAN_Unknown</th>\n      <th>RC_CLEAN_Institutional</th>\n      <th>RC_CLEAN_NHC</th>\n      <th>RC_CLEAN_Other</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 140 columns</p>\n</div>"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove Member ID and Data Start Date from Data Frame for prediction\n",
    "data_date_start_list = test_df['DATE_START']\n",
    "test_df = test_df.drop(['DATE_START'], axis = 1)\n",
    "member_id_list = test_df['MEMBER_ID']\n",
    "test_df = test_df.drop(['MEMBER_ID'], axis = 1)\n",
    "\n",
    "#Remove ED_Visit from Data Frame\n",
    "y_test_df = test_df['ED_IP_VISIT']\n",
    "test_df = test_df.drop(['ED_IP_VISIT'], axis = 1)\n",
    "\n",
    "# Find features with missing values\n",
    "sumdf = pd.DataFrame(test_df.isna().sum())\n",
    "\n",
    "features_to_drop = []\n",
    "for row in sumdf.iterrows():\n",
    "    if row[1][0] != 0:\n",
    "        features_to_drop.append(row[0])\n",
    "\n",
    "# Review features with missing values\n",
    "print('These are the features that initially had missing values within the data frame: \\n',features_to_drop,'\\n\\n')\n",
    "\n",
    "Nulls_to_correct = ['ACSC_A_FIB_AND_FLUTTER', \n",
    "                    'ACSC_ALCOHOL_RELATED',\n",
    "                    'ACSC_ANEMIA',\n",
    "                    'ACSC_ANGINA',\n",
    "                    'ACSC_ASTHMA',\n",
    "                    'ACSC_CELLULITIS',\n",
    "                    'ACSC_CONSTIPATION',\n",
    "                    'ACSC_CONVULSION_EPILEPSY',\n",
    "                    'ACSC_COPD',\n",
    "                    'ACSC_DECUBITI_STAGE_3_',\n",
    "                    'ACSC_DEHYDRATION_GASTROENTERITIS',\n",
    "                    'ACSC_DYSPEPSIA',\n",
    "                    'ACSC_ENT_INFECTION',\n",
    "                    'ACSC_HYPERTENSION',\n",
    "                    'ACSC_HYPOGLYCEMIA',\n",
    "                    'ACSC_HYPOKALEMIA',\n",
    "                    'ACSC_MIGRAINE_HEADACHE',\n",
    "                    'ACSC_NUTRITION_DEFICIENT',\n",
    "                    'ACSC_PERFORATED_BLEEDING_ULCER',\n",
    "                    'ACSC_PROXIMAL_FEMUR_FRACTURE',\n",
    "                    'ACSC_PYELONEPHRITIS',\n",
    "                    'ACSC_VACCINE_PREVENTABLE_DX',\n",
    "                    'CRN_FALLS',\n",
    "                    'CRN_PRIOR_MI',\n",
    "                    'CRN_SMOKING',\n",
    "                    'NI_COST_HS',\n",
    "                    'NI_COST_IP_RHB',\n",
    "                    'NI_COST_OTH',\n",
    "                    'NI_COST_PCA_T1020',\n",
    "                    'NI_COST_PSYC',\n",
    "                    'NI_COUNT_HS',\n",
    "                    'NI_COUNT_IP_RHB',\n",
    "                    'NI_COUNT_OTH',\n",
    "                    'NI_COUNT_PCA_T1020',\n",
    "                    'NI_COUNT_PSYC'] \n",
    "\n",
    "# Fill selected features with 0 value\n",
    "for col in Nulls_to_correct:\n",
    "    test_df[col] = test_df[col].fillna(0)\n",
    "    \n",
    "# Check for missing values and drop columns with missing values\n",
    "sumdf = pd.DataFrame(test_df.isna().sum())\n",
    "\n",
    "features_to_drop = []\n",
    "for row in sumdf.iterrows():\n",
    "    if row[1][0] != 0:\n",
    "        features_to_drop.append(row[0])\n",
    "\n",
    "print('These columns were dropped after because missing values were not corrected :\\n', features_to_drop,'\\n\\n')        \n",
    "test_df = test_df.drop(columns = features_to_drop)\n",
    "\n",
    "# Convert object datatypes to dummy variables\n",
    "object_list = []\n",
    "\n",
    "for col in test_df.columns:\n",
    "    if test_df[col].dtypes == 'object':\n",
    "        object_list.append(col)\n",
    "        \n",
    "print('These are the features that were converted to dummy variables: \\n',object_list,'\\n\\n')\n",
    "test_df = pd.get_dummies(test_df, columns = object_list, drop_first = True)\n",
    "\n",
    "test_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "#Scale data for prediction with original model\n",
    "X = test_df\n",
    "X = scaler.fit_transform(X)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 4.240893363952637 seconds ---\n",
      "--- 10.71027946472168 seconds ---\n",
      "--- 13.159122228622437 seconds ---\n",
      "--- 18.05874228477478 seconds ---\n",
      "--- 19.002416610717773 seconds ---\n",
      "--- 12.457221269607544 seconds ---\n",
      "--- 9.648310899734497 seconds ---\n",
      "--- 5.142566919326782 seconds ---\n",
      "--- 7.357904434204102 seconds ---\n",
      "--- 1.8213460445404053 seconds ---\n"
     ]
    },
    {
     "data": {
      "text/plain": "            1         2         3         4       5         6         7   \\\n0     0.248500  0.239500  0.230500  0.243500  0.2595  0.260500  0.273000   \n1     0.412500  0.416500  0.439000  0.371500  0.4245  0.420500  0.355000   \n2     0.313968  0.255500  0.354000  0.355500  0.3040  0.342000  0.320486   \n3     0.207000  0.197000  0.233000  0.223000  0.2690  0.233000  0.214500   \n4     0.456000  0.462500  0.458000  0.427500  0.4615  0.515500  0.539500   \n...        ...       ...       ...       ...     ...       ...       ...   \n2040  0.194000  0.206500  0.191000  0.220000  0.2050  0.211500  0.175500   \n2041  0.069000  0.059000  0.080000  0.134500  0.0610  0.069000  0.050250   \n2042  0.126190  0.149279  0.111905  0.114242  0.1290  0.152721  0.117674   \n2043  0.220500  0.234250  0.191500  0.234500  0.2360  0.226500  0.199000   \n2044  0.187500  0.164500  0.150500  0.178500  0.1930  0.210000  0.166500   \n\n            8         9        10  \n0     0.222500  0.266000  0.25750  \n1     0.385500  0.416500  0.39950  \n2     0.325500  0.350000  0.34600  \n3     0.233000  0.229000  0.25250  \n4     0.507980  0.498500  0.44750  \n...        ...       ...      ...  \n2040  0.192000  0.231000  0.15950  \n2041  0.055528  0.078000  0.09300  \n2042  0.127006  0.115351  0.10650  \n2043  0.201000  0.210000  0.22075  \n2044  0.196000  0.176000  0.24150  \n\n[2045 rows x 10 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>10</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.248500</td>\n      <td>0.239500</td>\n      <td>0.230500</td>\n      <td>0.243500</td>\n      <td>0.2595</td>\n      <td>0.260500</td>\n      <td>0.273000</td>\n      <td>0.222500</td>\n      <td>0.266000</td>\n      <td>0.25750</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.412500</td>\n      <td>0.416500</td>\n      <td>0.439000</td>\n      <td>0.371500</td>\n      <td>0.4245</td>\n      <td>0.420500</td>\n      <td>0.355000</td>\n      <td>0.385500</td>\n      <td>0.416500</td>\n      <td>0.39950</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.313968</td>\n      <td>0.255500</td>\n      <td>0.354000</td>\n      <td>0.355500</td>\n      <td>0.3040</td>\n      <td>0.342000</td>\n      <td>0.320486</td>\n      <td>0.325500</td>\n      <td>0.350000</td>\n      <td>0.34600</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.207000</td>\n      <td>0.197000</td>\n      <td>0.233000</td>\n      <td>0.223000</td>\n      <td>0.2690</td>\n      <td>0.233000</td>\n      <td>0.214500</td>\n      <td>0.233000</td>\n      <td>0.229000</td>\n      <td>0.25250</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.456000</td>\n      <td>0.462500</td>\n      <td>0.458000</td>\n      <td>0.427500</td>\n      <td>0.4615</td>\n      <td>0.515500</td>\n      <td>0.539500</td>\n      <td>0.507980</td>\n      <td>0.498500</td>\n      <td>0.44750</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2040</th>\n      <td>0.194000</td>\n      <td>0.206500</td>\n      <td>0.191000</td>\n      <td>0.220000</td>\n      <td>0.2050</td>\n      <td>0.211500</td>\n      <td>0.175500</td>\n      <td>0.192000</td>\n      <td>0.231000</td>\n      <td>0.15950</td>\n    </tr>\n    <tr>\n      <th>2041</th>\n      <td>0.069000</td>\n      <td>0.059000</td>\n      <td>0.080000</td>\n      <td>0.134500</td>\n      <td>0.0610</td>\n      <td>0.069000</td>\n      <td>0.050250</td>\n      <td>0.055528</td>\n      <td>0.078000</td>\n      <td>0.09300</td>\n    </tr>\n    <tr>\n      <th>2042</th>\n      <td>0.126190</td>\n      <td>0.149279</td>\n      <td>0.111905</td>\n      <td>0.114242</td>\n      <td>0.1290</td>\n      <td>0.152721</td>\n      <td>0.117674</td>\n      <td>0.127006</td>\n      <td>0.115351</td>\n      <td>0.10650</td>\n    </tr>\n    <tr>\n      <th>2043</th>\n      <td>0.220500</td>\n      <td>0.234250</td>\n      <td>0.191500</td>\n      <td>0.234500</td>\n      <td>0.2360</td>\n      <td>0.226500</td>\n      <td>0.199000</td>\n      <td>0.201000</td>\n      <td>0.210000</td>\n      <td>0.22075</td>\n    </tr>\n    <tr>\n      <th>2044</th>\n      <td>0.187500</td>\n      <td>0.164500</td>\n      <td>0.150500</td>\n      <td>0.178500</td>\n      <td>0.1930</td>\n      <td>0.210000</td>\n      <td>0.166500</td>\n      <td>0.196000</td>\n      <td>0.176000</td>\n      <td>0.24150</td>\n    </tr>\n  </tbody>\n</table>\n<p>2045 rows × 10 columns</p>\n</div>"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create Data Frame to store results\n",
    "model_df = pd.DataFrame()\n",
    "\n",
    "for i,clf in forest_dict.items():\n",
    "    start_time = time.time()\n",
    "    np.random.seed(i)\n",
    "    model_df[i+1] = clf.predict_proba(X)[:,1]\n",
    "    print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "model_df  "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "             1         2         3         4       5         6         7  \\\n0     0.248500  0.239500  0.230500  0.243500  0.2595  0.260500  0.273000   \n1     0.412500  0.416500  0.439000  0.371500  0.4245  0.420500  0.355000   \n2     0.313968  0.255500  0.354000  0.355500  0.3040  0.342000  0.320486   \n3     0.207000  0.197000  0.233000  0.223000  0.2690  0.233000  0.214500   \n4     0.456000  0.462500  0.458000  0.427500  0.4615  0.515500  0.539500   \n...        ...       ...       ...       ...     ...       ...       ...   \n2040  0.194000  0.206500  0.191000  0.220000  0.2050  0.211500  0.175500   \n2041  0.069000  0.059000  0.080000  0.134500  0.0610  0.069000  0.050250   \n2042  0.126190  0.149279  0.111905  0.114242  0.1290  0.152721  0.117674   \n2043  0.220500  0.234250  0.191500  0.234500  0.2360  0.226500  0.199000   \n2044  0.187500  0.164500  0.150500  0.178500  0.1930  0.210000  0.166500   \n\n             8         9       10  VIP_SCORE  \n0     0.222500  0.266000  0.25750   0.250100  \n1     0.385500  0.416500  0.39950   0.404100  \n2     0.325500  0.350000  0.34600   0.326695  \n3     0.233000  0.229000  0.25250   0.229100  \n4     0.507980  0.498500  0.44750   0.477448  \n...        ...       ...      ...        ...  \n2040  0.192000  0.231000  0.15950   0.198600  \n2041  0.055528  0.078000  0.09300   0.074928  \n2042  0.127006  0.115351  0.10650   0.124987  \n2043  0.201000  0.210000  0.22075   0.217400  \n2044  0.196000  0.176000  0.24150   0.186400  \n\n[2045 rows x 11 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>10</th>\n      <th>VIP_SCORE</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.248500</td>\n      <td>0.239500</td>\n      <td>0.230500</td>\n      <td>0.243500</td>\n      <td>0.2595</td>\n      <td>0.260500</td>\n      <td>0.273000</td>\n      <td>0.222500</td>\n      <td>0.266000</td>\n      <td>0.25750</td>\n      <td>0.250100</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.412500</td>\n      <td>0.416500</td>\n      <td>0.439000</td>\n      <td>0.371500</td>\n      <td>0.4245</td>\n      <td>0.420500</td>\n      <td>0.355000</td>\n      <td>0.385500</td>\n      <td>0.416500</td>\n      <td>0.39950</td>\n      <td>0.404100</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.313968</td>\n      <td>0.255500</td>\n      <td>0.354000</td>\n      <td>0.355500</td>\n      <td>0.3040</td>\n      <td>0.342000</td>\n      <td>0.320486</td>\n      <td>0.325500</td>\n      <td>0.350000</td>\n      <td>0.34600</td>\n      <td>0.326695</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.207000</td>\n      <td>0.197000</td>\n      <td>0.233000</td>\n      <td>0.223000</td>\n      <td>0.2690</td>\n      <td>0.233000</td>\n      <td>0.214500</td>\n      <td>0.233000</td>\n      <td>0.229000</td>\n      <td>0.25250</td>\n      <td>0.229100</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.456000</td>\n      <td>0.462500</td>\n      <td>0.458000</td>\n      <td>0.427500</td>\n      <td>0.4615</td>\n      <td>0.515500</td>\n      <td>0.539500</td>\n      <td>0.507980</td>\n      <td>0.498500</td>\n      <td>0.44750</td>\n      <td>0.477448</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2040</th>\n      <td>0.194000</td>\n      <td>0.206500</td>\n      <td>0.191000</td>\n      <td>0.220000</td>\n      <td>0.2050</td>\n      <td>0.211500</td>\n      <td>0.175500</td>\n      <td>0.192000</td>\n      <td>0.231000</td>\n      <td>0.15950</td>\n      <td>0.198600</td>\n    </tr>\n    <tr>\n      <th>2041</th>\n      <td>0.069000</td>\n      <td>0.059000</td>\n      <td>0.080000</td>\n      <td>0.134500</td>\n      <td>0.0610</td>\n      <td>0.069000</td>\n      <td>0.050250</td>\n      <td>0.055528</td>\n      <td>0.078000</td>\n      <td>0.09300</td>\n      <td>0.074928</td>\n    </tr>\n    <tr>\n      <th>2042</th>\n      <td>0.126190</td>\n      <td>0.149279</td>\n      <td>0.111905</td>\n      <td>0.114242</td>\n      <td>0.1290</td>\n      <td>0.152721</td>\n      <td>0.117674</td>\n      <td>0.127006</td>\n      <td>0.115351</td>\n      <td>0.10650</td>\n      <td>0.124987</td>\n    </tr>\n    <tr>\n      <th>2043</th>\n      <td>0.220500</td>\n      <td>0.234250</td>\n      <td>0.191500</td>\n      <td>0.234500</td>\n      <td>0.2360</td>\n      <td>0.226500</td>\n      <td>0.199000</td>\n      <td>0.201000</td>\n      <td>0.210000</td>\n      <td>0.22075</td>\n      <td>0.217400</td>\n    </tr>\n    <tr>\n      <th>2044</th>\n      <td>0.187500</td>\n      <td>0.164500</td>\n      <td>0.150500</td>\n      <td>0.178500</td>\n      <td>0.1930</td>\n      <td>0.210000</td>\n      <td>0.166500</td>\n      <td>0.196000</td>\n      <td>0.176000</td>\n      <td>0.24150</td>\n      <td>0.186400</td>\n    </tr>\n  </tbody>\n</table>\n<p>2045 rows × 11 columns</p>\n</div>"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_df['VIP_SCORE'] = (model_df[1] + model_df[2] + model_df[3] + model_df[4] + \n",
    "    model_df[5] +model_df[6] + model_df[7] + model_df[8] + model_df[9] + model_df[10])/10\n",
    "\n",
    "model_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "#Merge Results back to Test Data Frame\n",
    "test_df['VIP_SCORE'] = model_df['VIP_SCORE']\n",
    "test_df['ED_IP_VISIT'] = y_test_df\n",
    "test_df['MEMBER_ID'] = member_id_list\n",
    "test_df['DATA_DATE_START'] = data_date_start_list"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "       MEMBER_ID  VIP_SCORE  ED_IP_VISIT DATA_DATE_START\n1209  5365610641   0.719090            0      2022-09-01\n620   5365907435   0.705026            0      2022-09-01\n1900  5365567268   0.679940            0      2022-09-01\n1032  5365613749   0.671700            0      2022-09-01\n1651  5365589013   0.640164            0      2022-09-01\n1220  5364525985   0.637605            0      2022-09-01\n1244  5365812800   0.632540            0      2022-09-01\n1081  5365600926   0.621448            0      2022-09-01\n1035  5365976489   0.617255            0      2022-09-01\n568   5365613068   0.616852            0      2022-09-01\n904   5364524630   0.612366            0      2022-09-01\n600   5365553003   0.603100            0      2022-09-01\n860   5365576553   0.583625            0      2022-09-01\n201   5364524348   0.572150            0      2022-09-01\n1663  5365639494   0.569966            0      2022-09-01",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>MEMBER_ID</th>\n      <th>VIP_SCORE</th>\n      <th>ED_IP_VISIT</th>\n      <th>DATA_DATE_START</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1209</th>\n      <td>5365610641</td>\n      <td>0.719090</td>\n      <td>0</td>\n      <td>2022-09-01</td>\n    </tr>\n    <tr>\n      <th>620</th>\n      <td>5365907435</td>\n      <td>0.705026</td>\n      <td>0</td>\n      <td>2022-09-01</td>\n    </tr>\n    <tr>\n      <th>1900</th>\n      <td>5365567268</td>\n      <td>0.679940</td>\n      <td>0</td>\n      <td>2022-09-01</td>\n    </tr>\n    <tr>\n      <th>1032</th>\n      <td>5365613749</td>\n      <td>0.671700</td>\n      <td>0</td>\n      <td>2022-09-01</td>\n    </tr>\n    <tr>\n      <th>1651</th>\n      <td>5365589013</td>\n      <td>0.640164</td>\n      <td>0</td>\n      <td>2022-09-01</td>\n    </tr>\n    <tr>\n      <th>1220</th>\n      <td>5364525985</td>\n      <td>0.637605</td>\n      <td>0</td>\n      <td>2022-09-01</td>\n    </tr>\n    <tr>\n      <th>1244</th>\n      <td>5365812800</td>\n      <td>0.632540</td>\n      <td>0</td>\n      <td>2022-09-01</td>\n    </tr>\n    <tr>\n      <th>1081</th>\n      <td>5365600926</td>\n      <td>0.621448</td>\n      <td>0</td>\n      <td>2022-09-01</td>\n    </tr>\n    <tr>\n      <th>1035</th>\n      <td>5365976489</td>\n      <td>0.617255</td>\n      <td>0</td>\n      <td>2022-09-01</td>\n    </tr>\n    <tr>\n      <th>568</th>\n      <td>5365613068</td>\n      <td>0.616852</td>\n      <td>0</td>\n      <td>2022-09-01</td>\n    </tr>\n    <tr>\n      <th>904</th>\n      <td>5364524630</td>\n      <td>0.612366</td>\n      <td>0</td>\n      <td>2022-09-01</td>\n    </tr>\n    <tr>\n      <th>600</th>\n      <td>5365553003</td>\n      <td>0.603100</td>\n      <td>0</td>\n      <td>2022-09-01</td>\n    </tr>\n    <tr>\n      <th>860</th>\n      <td>5365576553</td>\n      <td>0.583625</td>\n      <td>0</td>\n      <td>2022-09-01</td>\n    </tr>\n    <tr>\n      <th>201</th>\n      <td>5364524348</td>\n      <td>0.572150</td>\n      <td>0</td>\n      <td>2022-09-01</td>\n    </tr>\n    <tr>\n      <th>1663</th>\n      <td>5365639494</td>\n      <td>0.569966</td>\n      <td>0</td>\n      <td>2022-09-01</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#View Predicted Members DF\n",
    "predicted_df = test_df[['MEMBER_ID','VIP_SCORE','ED_IP_VISIT','DATA_DATE_START']]\n",
    "predicted_df = predicted_df.sort_values(by=['VIP_SCORE'],ascending = False)\n",
    "predicted_df.head(15)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "766ae136",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "       MEMBER_ID  VIP_SCORE  ED_IP_VISIT DATA_DATE_START\n1209  5365610641   0.719090            0      2022-09-01\n620   5365907435   0.705026            0      2022-09-01\n1900  5365567268   0.679940            0      2022-09-01\n1032  5365613749   0.671700            0      2022-09-01\n1651  5365589013   0.640164            0      2022-09-01\n1220  5364525985   0.637605            0      2022-09-01\n1244  5365812800   0.632540            0      2022-09-01\n1081  5365600926   0.621448            0      2022-09-01\n1035  5365976489   0.617255            0      2022-09-01\n568   5365613068   0.616852            0      2022-09-01\n904   5364524630   0.612366            0      2022-09-01\n600   5365553003   0.603100            0      2022-09-01\n860   5365576553   0.583625            0      2022-09-01\n201   5364524348   0.572150            0      2022-09-01\n1663  5365639494   0.569966            0      2022-09-01",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>MEMBER_ID</th>\n      <th>VIP_SCORE</th>\n      <th>ED_IP_VISIT</th>\n      <th>DATA_DATE_START</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1209</th>\n      <td>5365610641</td>\n      <td>0.719090</td>\n      <td>0</td>\n      <td>2022-09-01</td>\n    </tr>\n    <tr>\n      <th>620</th>\n      <td>5365907435</td>\n      <td>0.705026</td>\n      <td>0</td>\n      <td>2022-09-01</td>\n    </tr>\n    <tr>\n      <th>1900</th>\n      <td>5365567268</td>\n      <td>0.679940</td>\n      <td>0</td>\n      <td>2022-09-01</td>\n    </tr>\n    <tr>\n      <th>1032</th>\n      <td>5365613749</td>\n      <td>0.671700</td>\n      <td>0</td>\n      <td>2022-09-01</td>\n    </tr>\n    <tr>\n      <th>1651</th>\n      <td>5365589013</td>\n      <td>0.640164</td>\n      <td>0</td>\n      <td>2022-09-01</td>\n    </tr>\n    <tr>\n      <th>1220</th>\n      <td>5364525985</td>\n      <td>0.637605</td>\n      <td>0</td>\n      <td>2022-09-01</td>\n    </tr>\n    <tr>\n      <th>1244</th>\n      <td>5365812800</td>\n      <td>0.632540</td>\n      <td>0</td>\n      <td>2022-09-01</td>\n    </tr>\n    <tr>\n      <th>1081</th>\n      <td>5365600926</td>\n      <td>0.621448</td>\n      <td>0</td>\n      <td>2022-09-01</td>\n    </tr>\n    <tr>\n      <th>1035</th>\n      <td>5365976489</td>\n      <td>0.617255</td>\n      <td>0</td>\n      <td>2022-09-01</td>\n    </tr>\n    <tr>\n      <th>568</th>\n      <td>5365613068</td>\n      <td>0.616852</td>\n      <td>0</td>\n      <td>2022-09-01</td>\n    </tr>\n    <tr>\n      <th>904</th>\n      <td>5364524630</td>\n      <td>0.612366</td>\n      <td>0</td>\n      <td>2022-09-01</td>\n    </tr>\n    <tr>\n      <th>600</th>\n      <td>5365553003</td>\n      <td>0.603100</td>\n      <td>0</td>\n      <td>2022-09-01</td>\n    </tr>\n    <tr>\n      <th>860</th>\n      <td>5365576553</td>\n      <td>0.583625</td>\n      <td>0</td>\n      <td>2022-09-01</td>\n    </tr>\n    <tr>\n      <th>201</th>\n      <td>5364524348</td>\n      <td>0.572150</td>\n      <td>0</td>\n      <td>2022-09-01</td>\n    </tr>\n    <tr>\n      <th>1663</th>\n      <td>5365639494</td>\n      <td>0.569966</td>\n      <td>0</td>\n      <td>2022-09-01</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#View Predicted Members DF\n",
    "predicted_df = test_df[['MEMBER_ID','VIP_SCORE','ED_IP_VISIT','DATA_DATE_START']]\n",
    "predicted_df = predicted_df.sort_values(by=['VIP_SCORE'],ascending = False)\n",
    "predicted_df.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# convert from object to datetime and format-not needed in CTL so check sql to see what diffs are\n",
    "predicted_df['DATA_DATE_START'] = predicted_df['DATA_DATE_START'].astype('datetime64[ns]')\n",
    "predicted_df.info()\n",
    "predicted_df['DATA_DATE_START'] = predicted_df['DATA_DATE_START'].dt.strftime('%Y%m')\n",
    "predicted_df.head(15)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3172c7f3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "predicted_df.to_csv('CCA Model - 202208.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "id": "9d17587d",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Output and Update Tables in Snowflake for Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e144d0e4",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Snowflake credentials stored in environment variables\n",
    "\n",
    "username = os.getenv('Snowflake_User')\n",
    "password = os.getenv('Snowflake_password')\n",
    "account = os.getenv('Snowflake_account')\n",
    "\n",
    "\n",
    "#Define parameters if neccessary\n",
    "warehouse = os.getenv('Snowflake_warehouse')\n",
    "database = os.getenv('Snowflake_database')\n",
    "schema = os.getenv('Snowflake_schema')\n",
    "\n",
    "#Create connection object for Snowflake connection\n",
    "conn = sf.connect(user = username, password = password, account = account, warehouse = warehouse)\n",
    "\n",
    "#Execution function\n",
    "def execute_query(connection,query):\n",
    "    cursor = connection.cursor()\n",
    "    cursor.execute(query)\n",
    "    cursor.close\n",
    "\n",
    "try:\n",
    "    sql = 'USE DATABASE {}'.format(database)\n",
    "    execute_query(conn,sql)\n",
    "    \n",
    "    sql = 'USE SCHEMA {}.{}'.format(database,schema)\n",
    "    execute_query(conn,sql)\n",
    "    \n",
    "    #Define warehouse to use in Snowflake\n",
    "    sql = 'use warehouse {}'.format(warehouse)\n",
    "    execute_query(conn,sql)\n",
    "    \n",
    "    print('Successful Connection')\n",
    "    \n",
    "    #Query to Snowflake\n",
    "    sql = \"CREATE TABLE IF NOT EXISTS VIP_SCORING (CLNT string,MEMBER_ID string, VIP_SCORE float ,DATA_DATE_START string)\"\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(sql)\n",
    "    \n",
    "    entry_list = []\n",
    "    for row in predicted_df.iterrows():\n",
    "        client = 'CCA'\n",
    "        member_id = str(row[1][0])\n",
    "        vip_score = row[1][1]\n",
    "        data_date = str(row[1][3])\n",
    "        entry = (client,member_id,vip_score,data_date)\n",
    "        entry_list.append(entry)       \n",
    "    entry = str(entry_list)[1:len(str(entry_list))-1]\n",
    "    sql = 'INSERT INTO VIP_SCORING (CLNT,MEMBER_ID, VIP_SCORE, DATA_DATE_START) VALUES {}'.format(entry)\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(sql)  \n",
    "    cursor.close\n",
    "\n",
    "    print('Database updated')\n",
    "    \n",
    "except Exception as e:\n",
    "        print(e)\n",
    "        \n",
    "finally:\n",
    "    conn.close"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88077bed",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# ITEMS BELOW THIS ARE FOR ANALYSIS ONLY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1182c6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Prediction List\n",
    "for row in predicted_df.iterrows():\n",
    "    print('Member: ',row[1][0],' VIP_SCORE: ',round(row[1][1],4), ' ED_IP_VISIT: ',row[1][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc46052",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "final_threshold = 0.3\n",
    "\n",
    "final_y_pred = [1 if result >= final_threshold else 0 for result in test_df['VIP_SCORE'].tolist()]\n",
    "\n",
    "# Creating confusion maxtrix\n",
    "new_cnf_matrix = metrics.confusion_matrix(y_test_df,final_y_pred)\n",
    "\n",
    "%matplotlib inline\n",
    "class_names=[0,1]\n",
    "fig, ax = plt.subplots()\n",
    "tick_marks = np.arange(len(class_names))\n",
    "plt.xticks(tick_marks, class_names)\n",
    "plt.yticks(tick_marks, class_names)\n",
    "\n",
    "# Create heatmap\n",
    "sns.heatmap(pd.DataFrame(new_cnf_matrix), annot=True, cmap=\"YlGnBu\" ,fmt='g')\n",
    "ax.xaxis.set_label_position(\"top\")\n",
    "\n",
    "# Axis labels\n",
    "plt.tight_layout()\n",
    "plt.title('Confusion matrix', y=1.1)\n",
    "plt.ylabel('Actual label')\n",
    "plt.xlabel('Predicted label')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n",
    "#Calulating Metrics\n",
    "accuracy = metrics.accuracy_score(y_test_df, final_y_pred)\n",
    "precision = metrics.precision_score(y_test_df, final_y_pred)\n",
    "recall = metrics.recall_score(y_test_df, final_y_pred)\n",
    "    \n",
    "print('Thereshold: ',final_threshold)\n",
    "print(\"Accuracy: \",accuracy)\n",
    "print(\"Precision: \",precision)\n",
    "print(\"Recall: \",recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c1fe52b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Realtime Accuracy\n",
    "X = []\n",
    "Y = []\n",
    "count = 1\n",
    "sums = 0\n",
    "for row in predicted_df.iterrows():\n",
    "    sums += row[1][2]\n",
    "    accuracy = round(sums/count *100,2)\n",
    "    X.append(count)\n",
    "    Y.append(accuracy)\n",
    "    print('After',count, 'prediction, the realtime accuarcy is ',accuracy)\n",
    "    count +=1\n",
    "    \n",
    "plt.plot(X, Y, marker='.', label='Random Forest')\n",
    "\n",
    "acc = np.where(np.array(Y) <= 60)\n",
    "\n",
    "acc = np.where(np.array(Y) <= 60)\n",
    "#for i,x in enumerate(acc[0]):\n",
    "    #print(i,x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee71bfc5",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Important Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3856ab0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "feature_list = [x for x in df.columns if x != 'ED_IP_VISIT']\n",
    "\n",
    "importance_df = pd.DataFrame()\n",
    "\n",
    "for i,clf in forest_dict.items():\n",
    "    start_time = time.time()\n",
    "    importances = list(clf.feature_importances_)\n",
    "    feature_importances = [(feature, round(importance, 15)) for feature, importance in zip(feature_list, importances)]\n",
    "    importance_df[i+1] = feature_importances\n",
    "    print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "importance_avg_list = []\n",
    "\n",
    "for row in importance_df.iterrows():\n",
    "    feature_name = row[1][1][0]\n",
    "    avg = round((row[1][1][1] + row[1][2][1] + row[1][3][1] + row[1][4][1] + row[1][5][1] + row[1][6][1] + row[1][7][1] \n",
    "            + row[1][8][1] + row[1][9][1] + row[1][10][1])/10,4)\n",
    "    \n",
    "    importance_avg_list.append((feature_name,avg))\n",
    "    \n",
    "# Sort the feature importances by most important first\n",
    "feature_importances = sorted(importance_avg_list, key = lambda x: x[1], reverse = True)\n",
    "\n",
    "feature_importances[0:10]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fb55d49",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Random Search with Cross Validation - Hyperparameter Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f7c30d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "\n",
    "print(random_grid)\n",
    "\n",
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "rf = RandomForestClassifier(random_state = 22822)\n",
    "\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "scoring = {\"Accuracy\":make_scorer(metrics.accuracy_score),\"Precision\":make_scorer(metrics.precision_score),\n",
    "            \"Recall\":make_scorer(metrics.recall_score),\"AUC\":make_scorer(metrics.roc_auc_score)}\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_random = RandomizedSearchCV(estimator=rf, param_distributions=random_grid,\n",
    "                              n_iter = 100, scoring='balanced_accuracy', \n",
    "                              cv = 3, verbose=6, random_state=42, n_jobs=-1,\n",
    "                              return_train_score=True)\n",
    "\n",
    "# Fit the random search model\n",
    "rf_random.fit(X_train,y_train);\n",
    "\n",
    "#Best parameters found\n",
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f54ca9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "rf_random.cv_results_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}