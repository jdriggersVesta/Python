{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72278115",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Importing Necessary dependencies\n",
    "import pandas as pd\n",
    "import snowflake.connector as sf\n",
    "import numpy as np\n",
    "import time\n",
    "import boto3\n",
    "import os\n",
    "import zipfile\n",
    "import smtplib, ssl\n",
    "import shutil\n",
    "import csv\n",
    "from snowflake.connector.pandas_tools import write_pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "#Create Log for review\n",
    "start_time = time.time()\n",
    "claimslog = []"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully created CTL File Temporary Folder at 2022-11-18 09:21:55\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    #Create Local Directory to store files in temporarily\n",
    "    os.makedirs('C:\\\\Users\\\\Jad Driggers\\\\Documents\\\\Vesta\\\\CTLFILES')\n",
    "    os.chdir('C:\\\\Users\\\\Jad Driggers\\\\Documents\\\\Vesta\\\\CTLFILES')\n",
    "    root_directory = os.getcwd()\n",
    "    claimslog.append('Successfully created CTL File Temporary Folder at ' + time.strftime('%Y-%m-%d %H:%M:%S',\n",
    "                                                                                          time.localtime(time.time())))\n",
    "except Exception as e:\n",
    "    claimslog.append('There was an error with creating the temporary CTL File - ' + str(e))\n",
    "    print('Successfully created CTL File Temporary Folder at ' + time.strftime('%Y-%m-%d %H:%M:%S',\n",
    "                                                                               time.localtime(time.time())))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AWS connection object created at 2022-11-18 09:21:59\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    #Create Connection Object for Connecting to AWS\n",
    "    s3 = boto3.resource(\n",
    "        service_name='s3',\n",
    "        region_name='us-east-1',\n",
    "        aws_access_key_id=os.getenv('aws_access_key_id'),\n",
    "        aws_secret_access_key=os.getenv('aws_secret_access_key'))\n",
    "    print('AWS connection object created at ' + time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(time.time())))\n",
    "    claimslog.append(\n",
    "        'AWS connection object created at ' + time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(time.time())))\n",
    "except Exception as e:\n",
    "    print('There was an error with creating the AWS connection object - ' + str(e))\n",
    "    claimslog.append('There was an error with creating the AWS connection object - ' + str(e))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for CCA Files that start like CL_VESTA_Claims_Monthly_202211081555.txt and CL_VESTA_Enrollment_202211081449.txt and CL_VESTA_Pharmacy_Monthly_202211081603.txt at 2022-11-18 09:45:09\n"
     ]
    }
   ],
   "source": [
    "#Create the file name format for locating the proper CTL files to parse\n",
    "\n",
    "filename_format_list = ['CL_VESTA_Claims_Monthly_202211081555.txt', 'CL_VESTA_Enrollment_202211081449.txt', 'CL_VESTA_Pharmacy_Monthly_202211081603.txt']\n",
    "claimslog.append('Looking for CTL Files that start like ' + \" and \".join(filename_format_list) + ' at ' + time.strftime(\n",
    "    '%Y-%m-%d %H:%M:%S', time.localtime(time.time())))\n",
    "print('Looking for CCA Files that start like ' + \" and \".join(filename_format_list) + ' at ' + time.strftime(\n",
    "    '%Y-%m-%d %H:%M:%S', time.localtime(time.time())))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CL_VESTA_Claims_Monthly_202211081555.txt', 'CL_VESTA_Enrollment_202211081449.txt', 'CL_VESTA_Pharmacy_Monthly_202211081603.txt']\n"
     ]
    }
   ],
   "source": [
    "print(filename_format_list)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "#Creating a list to store all the keys (file names) to download\n",
    "\n",
    "key_list = []\n",
    "\n",
    "try:\n",
    "    #Searching the S3 bucket for the most current Ping Files\n",
    "    for obj in s3.Bucket('hometeam-clinical-data').objects.all():\n",
    "        for filename_format in filename_format_list:\n",
    "            if filename_format in str(obj):\n",
    "                #print(obj.key)\n",
    "                key_list.append(obj.key)\n",
    "\n",
    "except Exception as e:\n",
    "    claimslog.append('There was an error while looking for most CCA Files - ' + str(e))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files were successfully downloaded at 2022-11-18 09:46:22\n",
      "Files were successfully downloaded at 2022-11-18 09:46:34\n",
      "Files were successfully downloaded at 2022-11-18 09:47:03\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    #Downloading each of the files found in the key list\n",
    "    for file in key_list:\n",
    "        s3.Bucket('hometeam-clinical-data').download_file(file, file.split('/')[2])\n",
    "        print(\n",
    "            'Files were successfully downloaded at ' + time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(time.time())))\n",
    "    claimslog.append(\n",
    "        'Files were successfully downloaded at ' + time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(time.time())))\n",
    "except Exception as e:\n",
    "    claimslog.append('There was an error while trying to download the CCA Files - ' + str(e))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "#On local computer, change directory and set directory for unzipping of files.\n",
    "os.chdir('C:\\\\Users\\\\Jad Driggers\\\\Documents\\\\Vesta\\\\CTLFILES')\n",
    "root_directory = os.getcwd()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mIndexError\u001B[0m                                Traceback (most recent call last)",
      "Input \u001B[1;32mIn [13]\u001B[0m, in \u001B[0;36m<cell line: 10>\u001B[1;34m()\u001B[0m\n\u001B[0;32m     31\u001B[0m         df_error_list\u001B[38;5;241m.\u001B[39mappend(i)\n\u001B[0;32m     33\u001B[0m \u001B[38;5;66;03m#Check to see if the list row in the data frame is an empty row, if so, drop it\u001B[39;00m\n\u001B[1;32m---> 34\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(df_list[\u001B[43mdf_error_list\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m]\u001B[49m]) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m     35\u001B[0m     df_error_list\u001B[38;5;241m.\u001B[39mpop()\n\u001B[0;32m     37\u001B[0m \u001B[38;5;66;03m#The error exists between two rows, so looking at the second occurance of an error\u001B[39;00m\n\u001B[0;32m     38\u001B[0m \u001B[38;5;66;03m#and deleting the first item should fix the error\u001B[39;00m\n",
      "\u001B[1;31mIndexError\u001B[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "%time\n",
    "#Create dictionary to store dataframes as they are created\n",
    "df_dict = {}\n",
    "error_dict = {}\n",
    "\n",
    "#Set current directory\n",
    "cwd = os.chdir('C:\\\\Users\\\\Jad Driggers\\\\Documents\\\\Vesta\\\\CTLFILES')\n",
    "\n",
    "#Loop through all txt files in the directory\n",
    "for i, file in enumerate(os.listdir(cwd)):\n",
    "    if '.txt' in file:\n",
    "\n",
    "        #empty lists to story the data while cleaning\n",
    "        df_list = []\n",
    "        df_error_list = []\n",
    "\n",
    "        #open the txt file\n",
    "        with open(file, 'r') as csvfile:\n",
    "            reader = csv.reader(csvfile, delimiter='\\t')\n",
    "\n",
    "            #read through each line and find any rows with errors\n",
    "            for i, row in enumerate(reader):\n",
    "                if i == 0:\n",
    "                    #capture the correct number of columns for the dataframe\n",
    "                    correct_columns = len(row)\n",
    "\n",
    "                df_list.append(row)\n",
    "\n",
    "                #create list of rows with errors\n",
    "                if len(row) < correct_columns:\n",
    "                    df_error_list.append(i)\n",
    "\n",
    "            #Check to see if the list row in the data frame is an empty row, if so, drop it\n",
    "            if len(df_list[df_error_list[-1]]) == 0:\n",
    "                df_error_list.pop()\n",
    "\n",
    "            #The error exists between two rows, so looking at the second occurance of an error\n",
    "            #and deleting the first item should fix the error\n",
    "            for i, error in enumerate(df_error_list):\n",
    "                if i % 2 != 0:\n",
    "                    df_list[error].pop(0)\n",
    "\n",
    "            #Loop back through the error list and join first errors to second errors to make a complete row\n",
    "            for i, error in enumerate(df_error_list):\n",
    "                if i % 2 == 0:\n",
    "                    df_list[error] = df_list[error] + df_list[error + 1]\n",
    "\n",
    "            #Loop back through the entire data frame list to delete those rows that are smaller than the correct\n",
    "            #number of columns\n",
    "            for i, item in enumerate(df_list):\n",
    "                if len(item) < correct_columns:\n",
    "                    del df_list[i]\n",
    "\n",
    "            df = pd.DataFrame(df_list[1:])\n",
    "            df.columns = df_list[0]\n",
    "            df = df.rename(columns={df.columns[0]: df.columns[0][3:]})\n",
    "            df = df.astype(str)\n",
    "            df.columns = map(lambda x: str(x).upper(), df.columns)\n",
    "            df_dict[csvfile.name.replace(' ', '_').split(\".\")[0]] = df\n",
    "            error_dict[csvfile.name.replace(' ', '_').split(\".\")[0]] = df_error_list\n",
    "\n",
    "        csvfile.close()\n",
    "\n",
    "for key, value in df_dict.items():\n",
    "    print(key)\n",
    "\n",
    "print(error_dict)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Delete all contents in the temporary CCA Folder\n",
    "os.chdir('C:\\\\Users\\\\Jad Driggers\\\\Documents\\\\Vesta')\n",
    "shutil.rmtree('C:\\\\Users\\\\Jad Driggers\\\\Documents\\\\Vesta\\\\CTLFILES')\n",
    "claimslog.append('Successfully Deleted all contents in temporary CTL Folder at ' + time.strftime('%Y-%m-%d %H:%M:%S',\n",
    "                                                                                                 time.localtime(\n",
    "                                                                                                     time.time())))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_dict[]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a58ff69",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Create Connection Object for Connecting to AWS\n",
    "def AWSConnection():\n",
    "    try:\n",
    "        s3 = boto3.resource(\n",
    "            service_name='s3',\n",
    "            region_name='us-east-1',\n",
    "            aws_access_key_id=os.getenv('aws_access_key_id'),\n",
    "            aws_secret_access_key=os.getenv('aws_secret_access_key'))\n",
    "        claimslog.append('AWS connection object created at '\n",
    "                         + time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(time.time())))\n",
    "        return s3\n",
    "    except Exception as e:\n",
    "        claimslog.append('There was an error with creating the AWS connection object - ' + str(e))\n",
    "\n",
    "    # Search S3 Bucket and Download Files Locally\n",
    "\n",
    "\n",
    "def S3SearchAndDownload(connection, filename_list):\n",
    "    #Creating a list to store all the keys (file names) to download\n",
    "    key_list = []\n",
    "\n",
    "    try:\n",
    "        #Searching the S3 bucket for the most current Ping Files\n",
    "        for obj in connection.Bucket('hometeam-clinical-data').objects.all():\n",
    "            for filename_format in filename_format_list:\n",
    "                if filename_format in str(obj):\n",
    "                    #print(obj.key)\n",
    "                    key_list.append(obj.key)\n",
    "\n",
    "    except Exception as e:\n",
    "        claimslog.append('There was an error while looking for most CCA Files - ' + str(e))\n",
    "\n",
    "    try:\n",
    "        #Downloading each of the files found in the key list\n",
    "        for file in key_list:\n",
    "            s3.Bucket('hometeam-clinical-data').download_file(file, file.split('/')[2])\n",
    "        claimslog.append('Files were successfully downloaded at '\n",
    "                         + time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(time.time())))\n",
    "    except Exception as e:\n",
    "        claimslog.append('There was an error while trying to download the CTL Files - ' + str(e))\n",
    "\n",
    "\n",
    "# Unzipping files \n",
    "def UnzipFiles():\n",
    "    # On local computer, change directory and set directory for unzipping of files.\n",
    "    os.chdir('C:\\\\Users\\\\Jad Driggers\\\\Documents\\\\Vesta\\\\CTLFILES')\n",
    "    root_directory = os.getcwd()\n",
    "\n",
    "    # Locate only Zipped Files\n",
    "    files_to_unzip = []\n",
    "    for filename in os.listdir(root_directory):\n",
    "        if 'zip' in filename:\n",
    "            files_to_unzip.append(filename)\n",
    "    try:\n",
    "        # Unzip each file in the Zipped files list\n",
    "        for zipped_file in files_to_unzip:\n",
    "            with zipfile.ZipFile(root_directory + \"\\\\\" + zipped_file, 'r') as zip_ref:\n",
    "                # print(zipped_file)\n",
    "                zip_ref.extractall(root_directory)\n",
    "        shutil.unpack_archive(root_directory + \"\\\\\" + zipped_file, root_directory + \"\\\\\" + zipped_file.split('.')[0])\n",
    "        claimslog.append('Successfully Unzipped each file at '\n",
    "                         + time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(time.time())))\n",
    "    except Exception as e:\n",
    "        claimslog.append('There was an error while trying to unzip each file - ' + str(e))\n",
    "\n",
    "\n",
    "# CTL Files Dictionary\n",
    "def CreateDFDict():\n",
    "    # Create dictionary to store dataframes as they are created \n",
    "    df_dict = {}\n",
    "    error_dict = {}\n",
    "\n",
    "    # Set current directory\n",
    "    cwd = os.chdir('C:\\\\Users\\\\Jad Driggers\\\\Documents\\\\Vesta\\\\CTLFILES')\n",
    "\n",
    "    # Loop through all txt files in the directory\n",
    "    for i, file in enumerate(os.listdir(cwd)):\n",
    "        if '.txt' in file:\n",
    "\n",
    "            # Empty lists to story the data while cleaning\n",
    "            df_list = []\n",
    "            df_error_list = []\n",
    "\n",
    "            # Open the txt file\n",
    "            with open(file, 'r') as csvfile:\n",
    "                reader = csv.reader(csvfile, delimiter='|')\n",
    "\n",
    "                # Read through each line and find any rows with errors\n",
    "                for i, row in enumerate(reader):\n",
    "                    if i == 0:\n",
    "                        # Capture the correct number of columns for the dataframe\n",
    "                        correct_columns = len(row)\n",
    "\n",
    "                    df_list.append(row)\n",
    "\n",
    "                    # Create list of rows with errors\n",
    "                    if len(row) < correct_columns:\n",
    "                        df_error_list.append(i)\n",
    "\n",
    "                # Review error list\n",
    "                if df_error_list:\n",
    "\n",
    "                    # Check to see if the list row in the data frame is an empty row, if so, drop it\n",
    "                    if len(df_list[df_error_list[-1]]) == 0:\n",
    "                        df_error_list.pop()\n",
    "\n",
    "                    # The error exists between two rows, so looking at the second occurance of an error \n",
    "                    # and deleting the first item should fix the error\n",
    "                    for i, error in enumerate(df_error_list):\n",
    "                        if i % 2 != 0:\n",
    "                            df_list[error].pop(0)\n",
    "\n",
    "                    # Loop back through the error list and join first errors to second errors to make a complete row\n",
    "                    for i, error in enumerate(df_error_list):\n",
    "                        if i % 2 == 0:\n",
    "                            df_list[error] = df_list[error] + df_list[error + 1]\n",
    "\n",
    "                # Loop back through the entire data frame list to delete those rows that are smaller than the correct\n",
    "                # number of columns\n",
    "                for i, item in enumerate(df_list):\n",
    "                    if len(item) < correct_columns:\n",
    "                        del df_list[i]\n",
    "\n",
    "                df = pd.DataFrame(df_list[1:])\n",
    "                df.columns = df_list[0]\n",
    "                df = df.astype(str)\n",
    "                df.columns = map(lambda x: str(x).upper(), df.columns)\n",
    "                df_dict[csvfile.name.replace(' ', '_').split(\".\")[0]] = df\n",
    "                error_dict[csvfile.name.replace(' ', '_').split(\".\")[0]] = df_error_list\n",
    "\n",
    "            csvfile.close()\n",
    "\n",
    "    for key, value in df_dict.items():\n",
    "        print(key)\n",
    "\n",
    "    print(error_dict)\n",
    "\n",
    "    return df_dict\n",
    "\n",
    "\n",
    "# Delete all files in local folder\n",
    "def FolderDeletion():\n",
    "    os.chdir('C:\\\\Users\\\\Jad Driggers\\\\Documents\\\\Vesta\\\\CTLFILES')\n",
    "    shutil.rmtree('C:\\\\Users\\\\Jad Driggers\\\\Documents\\\\Vesta\\\\CTLFILES')\n",
    "    claimslog.append('Successfully Deleted all contents in temporary CTL Folder at ' +\n",
    "                     time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(time.time())))\n",
    "\n",
    "\n",
    "# Create a dictionary that stores the columns in the data frame and the max length of the values in those columns\n",
    "# in order to create table in snowflake to minimize table size\n",
    "def SQLTableStructure():\n",
    "    #Create two dictionaries to store the columns and the max len of values in those columns\n",
    "    max_col_len = {}\n",
    "    col_dict = {}\n",
    "\n",
    "    #Vectorizing the lenth function\n",
    "    measurer = np.vectorize(len)\n",
    "\n",
    "    #Looping through df_dictionary to capture column names and max len of values in those columns\n",
    "    max_col_len = {}\n",
    "    for key, value in df_dict.items():\n",
    "        col_len = measurer(df_dict[key].astype(str)).max(axis=0)\n",
    "        max_col_len[key] = col_len\n",
    "        col_dict[key] = df_dict[key].columns.tolist()\n",
    "\n",
    "    #Function for joining the two dictionaries with similar keys (claim files)    \n",
    "    def common_entries(*dcts):\n",
    "        if not dcts:\n",
    "            return\n",
    "        for i in set(dcts[0]).intersection(*dcts[1:]):\n",
    "            yield (i,) + tuple(d[i] for d in dcts)\n",
    "\n",
    "    mylist = list(common_entries(col_dict, max_col_len))\n",
    "\n",
    "    #Creating new dictionary and zipping the column names with respective max len of values in those columns\n",
    "    sql_dict = {}\n",
    "    for x in mylist:\n",
    "        sql_dict[x[0]] = list(zip(x[1], x[2]))\n",
    "\n",
    "    #Iterating through the list values to prep for SQL to Snowflake\n",
    "    sql_script_dict_table = {}\n",
    "    for key, value in sql_dict.items():\n",
    "        script_string_table = ''\n",
    "        for (col, max_len) in sql_dict[key]:\n",
    "            script_string_table += str(col) + ' VARCHAR(' + str(max_len + 10) + '),'\n",
    "        sql_script_dict_table[key] = \"(\" + script_string_table[:-1] + \")\"\n",
    "\n",
    "    return sql_script_dict_table\n",
    "\n",
    "\n",
    "# Create Snowflake Object\n",
    "def SnowflakeConnection():\n",
    "    #Creating of parameters for securing connection to Snowflake\n",
    "    username = os.getenv('Snowflake_User')\n",
    "    password = os.getenv('Snowflake_password')\n",
    "    account = os.getenv('Snowflake_account')\n",
    "\n",
    "\n",
    "    #Define parameters if neccessary\n",
    "    warehouse = 'DEVELOPER_STANDARD'\n",
    "    database = 'VESTA_DEVELOPMENT'\n",
    "    schema = 'ANALYST_SANDBOX'\n",
    "\n",
    "    #Create connection object for Snowflake connection\n",
    "    conn = sf.connect(user=username, password=password, account=account, warehouse=warehouse)\n",
    "    return conn\n",
    "\n",
    "\n",
    "# Snowflake execution function\n",
    "def execute_query(connection, query):\n",
    "    cursor = connection.cursor()\n",
    "    cursor.execute(query)\n",
    "    cursor.close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0aa54e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Create Log for review\n",
    "start_time = time.time()\n",
    "claimslog = []\n",
    "\n",
    "# Create local folder\n",
    "FolderCreation()\n",
    "\n",
    "# Create AWS connection object\n",
    "s3 = AWSConnection()\n",
    "\n",
    "# Create the filename format for locating the proper CTL files to parse\n",
    "filename_format_list = ['CL_VESTA_Claims_Monthly_202203081839.txt',\n",
    "                        'CL_Vesta_Pharmacy_Catchup_202203081328.txt',\n",
    "                        'CL_VESTA_Enrollment_202203081316.txt']\n",
    "\n",
    "# Search AWS for files and download locally\n",
    "S3SearchAndDownload(s3, filename_format_list)\n",
    "\n",
    "# Not neccessary with CTL\n",
    "# UnzipFiles()\n",
    "\n",
    "# Create dataframe dictionary of CTL files\n",
    "df_dict = CreateDFDict()\n",
    "\n",
    "# Delete all local CTL files and local CTL folder\n",
    "FolderDeletion()\n",
    "\n",
    "# Detemine the table structure and size for Snowflake\n",
    "sql_table = SQLTableStructure()\n",
    "\n",
    "# # Creating of parameters for securing connection to Snowflake\n",
    "# username =\n",
    "# password =\n",
    "# account =\n",
    "\n",
    "# # Define parameters if neccessary\n",
    "# warehouse =\n",
    "# database =\n",
    "# schema =\n",
    "\n",
    "# # Create connection object for Snowflake connection\n",
    "# conn = sf.connect(user=username, password=password, account=account, warehouse=warehouse)\n",
    "\n",
    "# # Define Database to use in Snowflake\n",
    "# sql = 'USE DATABASE {}'.format(database)\n",
    "# execute_query(conn,sql)\n",
    "\n",
    "# # Define Schema to use in Snowflake\n",
    "# sql = 'USE SCHEMA {}.{}'.format(database,schema)\n",
    "# execute_query(conn,sql)\n",
    "\n",
    "# # Define Warehouse to use in Snowflake\n",
    "# sql = 'USE WAREHOUSE {}'.format(warehouse)\n",
    "# execute_query(conn,sql)\n",
    "\n",
    "# # Create CTL_ENROLL_RAW\n",
    "# try:\n",
    "#     sql = 'CREATE TABLE IF NOT EXISTS CTL_ENROLL_RAW_TEST ' + sql_table['CL_VESTA_Enrollment_202203081316']\n",
    "#     execute_query(conn,sql)\n",
    "#     success, nchucks, nrows, _ = write_pandas(conn,df_dict['CL_VESTA_Enrollment_202203081316'],'CTL_ENROLL_RAW_TEST')\n",
    "# except Exception as e:\n",
    "#         print(e)  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ff9492",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48090a39",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_dict['CL_VESTA_Claims_Monthly_202203081839'][df_dict['CL_VESTA_Claims_Monthly_202203081839']['PROCEDURE_CODE'].str.contains('0013A')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f14b91",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "claimslog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c566bff",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "my_string = '\\n'.join(claimslog)\n",
    "\n",
    "port = 465  # For SSL\n",
    "smtp_server = \"smtp.gmail.com\"\n",
    "sender_email = \"VestaPingLog@gmail.com\"  # Enter your address\n",
    "receiver_email_list = [\"jdriggers@vestahealthcare.com\", \"john@vestahealthcare.com\",\n",
    "                       'joe@vestahealthcare.com']  # Enter receiver address\n",
    "password = os.getenv('Vesta_Ping_Log_Email')\n",
    "message = \"Subject: Ping Logs \\n\" + '''\n",
    "             \n",
    "''' + my_string\n",
    "\n",
    "context = ssl.create_default_context()\n",
    "with smtplib.SMTP_SSL(smtp_server, port, context=context) as server:\n",
    "    server.login(sender_email, password)\n",
    "    for receiver_email in receiver_email_list:\n",
    "        server.sendmail(sender_email, receiver_email, message)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}