{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72278115",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Necessary dependencies\n",
    "import pandas as pd\n",
    "import snowflake.connector as sf\n",
    "import numpy as np\n",
    "import time\n",
    "import boto3\n",
    "import os\n",
    "import zipfile\n",
    "import smtplib, ssl\n",
    "import shutil\n",
    "import csv\n",
    "from snowflake.connector.pandas_tools import write_pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ba74034",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Log for review\n",
    "start_time = time.time()\n",
    "claimslog = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a58ff69",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    #Create Local Directory to store files in temporarily\n",
    "    os.makedirs('C:\\\\Users\\\\Jad Driggers\\\\Documents\\\\Vesta\\\\CCAFILES')\n",
    "    os.chdir('C:\\\\Users\\\\Jad Driggers\\\\Documents\\\\Vesta\\\\CCAFILES')\n",
    "    root_directory = os.getcwd()\n",
    "    claimslog.append('Successfully created CCA File Temporary Folder at ' + time.strftime('%Y-%m-%d %H:%M:%S',\n",
    "                                                                                          time.localtime(time.time())))\n",
    "except Exception as e:\n",
    "    claimslog.append('There was an error with creating the temporary CCA File - ' + str(e))\n",
    "    print('Successfully created CCA File Temporary Folder at ' + time.strftime('%Y-%m-%d %H:%M:%S',\n",
    "                                                                               time.localtime(time.time())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1967f2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AWS connection object created at 2023-01-13 08:59:13\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    #Create Connection Object for Connecting to AWS\n",
    "    s3 = boto3.resource(\n",
    "        service_name='s3',\n",
    "        region_name='us-east-1',\n",
    "        aws_access_key_id=os.getenv('aws_access_key_id'),\n",
    "        aws_secret_access_key=os.getenv('aws_secret_access_key'))\n",
    "    print('AWS connection object created at ' + time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(time.time())))\n",
    "    claimslog.append(\n",
    "        'AWS connection object created at ' + time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(time.time())))\n",
    "except Exception as e:\n",
    "    print('There was an error with creating the AWS connection object - ' + str(e))\n",
    "    claimslog.append('There was an error with creating the AWS connection object - ' + str(e))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a96227da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for CCA Files that start like Element claims 202301.zip and Element MDS 202301.zip at 2023-01-13 08:59:15\n"
     ]
    }
   ],
   "source": [
    "#Create the file name format for locating the proper CCA files to parse\n",
    "\n",
    "filename_format_list = ['Element claims 202301.zip', 'Element MDS 202301.zip']\n",
    "claimslog.append('Looking for CCA Files that start like ' + \" and \".join(filename_format_list) + ' at ' + time.strftime(\n",
    "    '%Y-%m-%d %H:%M:%S', time.localtime(time.time())))\n",
    "print('Looking for CCA Files that start like ' + \" and \".join(filename_format_list) + ' at ' + time.strftime(\n",
    "    '%Y-%m-%d %H:%M:%S', time.localtime(time.time())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "79a82ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a list to store all the keys (file names) to download\n",
    "\n",
    "key_list = []\n",
    "\n",
    "try:\n",
    "    #Searching the S3 bucket for the most current Ping Files\n",
    "    for obj in s3.Bucket('hometeam-clinical-data').objects.all():\n",
    "        for filename_format in filename_format_list:\n",
    "            if filename_format in str(obj):\n",
    "                #print(obj.key)\n",
    "                key_list.append(obj.key)\n",
    "\n",
    "except Exception as e:\n",
    "    claimslog.append('There was an error while looking for most CCA Files - ' + str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['raw/cca/Element MDS 202301.zip', 'raw/cca/Element claims 202301.zip']\n"
     ]
    }
   ],
   "source": [
    "print(key_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e6ccf1d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files were successfully downloaded at 2023-01-13 08:59:26\n",
      "Files were successfully downloaded at 2023-01-13 08:59:35\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    #Downloading each of the files found in the key list\n",
    "    for file in key_list:\n",
    "        s3.Bucket('hometeam-clinical-data').download_file(file, file.split('/')[2])\n",
    "        print(\n",
    "            'Files were successfully downloaded at ' + time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(time.time())))\n",
    "    claimslog.append(\n",
    "        'Files were successfully downloaded at ' + time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(time.time())))\n",
    "except Exception as e:\n",
    "    claimslog.append('There was an error while trying to download the CCA Files - ' + str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": "{'ResponseMetadata': {'RequestId': '20RZG4JBQ0T13AF5',\n  'HostId': '4RQwd7IJvIhsbfFN59jJIY8+EGog2QmwzJMeZhys1GiBLelGL39zF5pMA2WjJHOtizkOW16RPqA=',\n  'HTTPStatusCode': 204,\n  'HTTPHeaders': {'x-amz-id-2': '4RQwd7IJvIhsbfFN59jJIY8+EGog2QmwzJMeZhys1GiBLelGL39zF5pMA2WjJHOtizkOW16RPqA=',\n   'x-amz-request-id': '20RZG4JBQ0T13AF5',\n   'date': 'Fri, 13 Jan 2023 14:00:04 GMT',\n   'x-amz-version-id': 'EvFT21x2n2kGJdtzCxdRTOERDdKi.UgK',\n   'x-amz-delete-marker': 'true',\n   'server': 'AmazonS3'},\n  'RetryAttempts': 0},\n 'DeleteMarker': True,\n 'VersionId': 'EvFT21x2n2kGJdtzCxdRTOERDdKi.UgK'}"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Move files into Monthly_Claims folder\n",
    "bucket = 'hometeam-clinical-data'\n",
    "copy_source = {\n",
    "    'Bucket': bucket,\n",
    "    'Key': 'raw/cca/Element MDS 202301.zip',\n",
    "    }\n",
    "\n",
    "copy_source2 = {\n",
    "    'Bucket': bucket,\n",
    "    'Key': 'raw/cca/Element claims 202301.zip',\n",
    "}\n",
    "s3.meta.client.copy(copy_source,bucket, 'raw/cca/Monthly_Claims/Element MDS 202301.zip')\n",
    "s3.meta.client.copy(copy_source2,bucket, 'raw/cca/Monthly_Claims/Element claims 202301.zip')\n",
    "#s3.meta.client.delete_object('hometeam-clinical-data','Element MDS 202210.zip')\n",
    "# s3.client.delete_object(Bucket=bucket, Key='Element MDS 202210.zip')\n",
    "s3_object = s3.Object('hometeam-clinical-data', 'raw/cca/Monthly_Claims/Element MDS 202301.zip')\n",
    "s3_object.delete()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ca78188d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#On local computer, change directory and set directory for unzipping of files.\n",
    "os.chdir('C:\\\\Users\\\\Jad Driggers\\\\Documents\\\\Vesta\\\\CCAFILES')\n",
    "root_directory = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "29382098",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Locate only Zipped Files\n",
    "files_to_unzip = []\n",
    "for filename in os.listdir(root_directory):\n",
    "    if 'zip' in filename:\n",
    "        files_to_unzip.append(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5dec649e",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    #Unzip each file in the Zipped files list\n",
    "    for zipped_file in files_to_unzip:\n",
    "        with zipfile.ZipFile(root_directory + \"\\\\\" + zipped_file, 'r') as zip_ref:\n",
    "            #print(zipped_file)\n",
    "            zip_ref.extractall(root_directory)\n",
    "    shutil.unpack_archive(root_directory + \"\\\\\" + zipped_file, root_directory + \"\\\\\" + zipped_file.split('.')[0])\n",
    "    claimslog.append(\n",
    "        'Successfully Unzipped each file at ' + time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(time.time())))\n",
    "except Exception as e:\n",
    "    claimslog.append('There was an error while trying to unzip each file - ' + str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Element_claims_member_contact\n",
      "Element_claims_member_demographics\n",
      "Element_claims_member_dx\n",
      "Element_claims_member_enrollment\n",
      "Element_claims_member_HCC\n",
      "Element_claims_PCP_contact\n",
      "Element_claims\n",
      "Element_MDS\n"
     ]
    }
   ],
   "source": [
    "#% % timeit\n",
    "#Create dictionary to store dataframes as they are created \n",
    "df_dict = {}\n",
    "error_dict = {}\n",
    "\n",
    "#Set current directory\n",
    "cwd = os.chdir('C:\\\\Users\\\\Jad Driggers\\\\Documents\\\\Vesta\\\\CCAFILES')\n",
    "\n",
    "#Loop through all txt files in the directory\n",
    "for i, file in enumerate(os.listdir(cwd)):\n",
    "    if '.txt' in file:\n",
    "\n",
    "        #empty lists to store the data while cleaning\n",
    "        df_list = []\n",
    "        df_error_list = []\n",
    "\n",
    "        #open the txt file\n",
    "        with open(file, 'r') as csvfile:\n",
    "            reader = csv.reader(csvfile, delimiter='\\t')\n",
    "\n",
    "            #read through each line and find any rows with errors\n",
    "            for i, row in enumerate(reader):\n",
    "                if i == 0:\n",
    "                    #capture the correct number of columns for the dataframe\n",
    "                    correct_columns = len(row)\n",
    "\n",
    "                df_list.append(row)\n",
    "\n",
    "                #create list of rows with errors\n",
    "                if len(row) < correct_columns:\n",
    "                    df_error_list.append(i)\n",
    "\n",
    "            #Check to see if the list row in the data frame is an empty row, if so, drop it\n",
    "            if len(df_list[df_error_list[-1]]) == 0:\n",
    "                df_error_list.pop()\n",
    "\n",
    "            #The error exists between two rows, so looking at the second occurance of an error \n",
    "            #and deleting the first item should fix the error\n",
    "            for i, error in enumerate(df_error_list):\n",
    "                if i % 2 != 0:\n",
    "                    df_list[error].pop(0)\n",
    "\n",
    "            #Loop back through the error list and join first errors to second errors to make a complete row\n",
    "            for i, error in enumerate(df_error_list):\n",
    "                if i % 2 == 0:\n",
    "                    df_list[error] = df_list[error] + df_list[error + 1]\n",
    "\n",
    "            #Loop back through the entire data frame list to delete those rows that are smaller than the correct\n",
    "            #number of columns\n",
    "            for i, item in enumerate(df_list):\n",
    "                if len(item) < correct_columns:\n",
    "                    del df_list[i]\n",
    "\n",
    "            df = pd.DataFrame(df_list[1:])\n",
    "            df.columns = df_list[0]\n",
    "            df = df.rename(columns={df.columns[0]: df.columns[0][3:]})\n",
    "            df = df.astype(str)\n",
    "            df.columns = map(lambda x: str(x).upper(), df.columns)\n",
    "            df_dict[csvfile.name.replace(' ', '_').split(\".\")[0]] = df\n",
    "            error_dict[csvfile.name.replace(' ', '_').split(\".\")[0]] = df_error_list\n",
    "\n",
    "        csvfile.close()\n",
    "\n",
    "for key, value in df_dict.items():\n",
    "    print(key)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e675666d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Delete all contents in the temporary CCA Folder\n",
    "os.chdir('C:\\\\Users\\\\Jad Driggers\\\\Documents\\\\Vesta')\n",
    "shutil.rmtree('C:\\\\Users\\\\Jad Driggers\\\\Documents\\\\Vesta\\\\CCAFILES')\n",
    "claimslog.append('Successfully Deleted all contents in temporary CCA Folder at ' + time.strftime('%Y-%m-%d %H:%M:%S',\n",
    "                                                                                                 time.localtime(\n",
    "                                                                                                     time.time())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "28ec5abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict['Element_claims_member_demographics'].rename(columns={\"CCAID\": \"MEMBER_ID\",\n",
    "                                                              \"NAME\": \"MNAME\",\n",
    "                                                              \"PCL_SITENAME\": \"PCL\",\n",
    "                                                              \"PCL_SUMMARYNAME\": \"PCL_SUMMARY\",\n",
    "                                                              \"PCL_CAPSITE\": \"PCL_CAP\",\n",
    "                                                              \"DUAL\": \"DUAL_\",\n",
    "                                                              \"GC_ENGAGEMENTSTATUS\": \"GC_ENGAGEMENT_STATUS\",\n",
    "                                                              \"MDS_UNREACHABLEFLAG\": \"MDS_UNREACHABLE\"},\n",
    "                                                     errors=\"raise\",\n",
    "                                                     inplace=True)\n",
    "df_dict['Element_claims_member_contact'].rename(columns={\"CCAID\": \"MEMBER_ID\",\n",
    "                                                         \"ENR_SPAN_START\": \"ENROLL_ST\",\n",
    "                                                         \"ENR_SPAN_END\": \"ENROLL_ED\",\n",
    "                                                         \"ENROLL_STATUS\": \"ENROLL_STATUS2\",\n",
    "                                                         \"NAME\": \"FULL_NAME\",\n",
    "                                                         \"AGE_NOW\": \"AGE\",\n",
    "                                                         \"GENDER\": \"SEX\",\n",
    "                                                         \"LANGUAGE\": \"LANGUAGE_SPOKEN\",\n",
    "                                                         \"ADDRESS1\": \"ADDRESS_1\",\n",
    "                                                         \"ADDRESS2\": \"ADDRESS_2\",\n",
    "                                                         \"LATEST_PHONE\": \"PHONE_1\"},\n",
    "                                                errors=\"raise\",\n",
    "                                                inplace=True)\n",
    "df_dict['Element_claims_member_enrollment'].rename(columns={\"CCAID\": \"MEMBER_ID\",\n",
    "                                                            \"PCP_PROVK\": \"PCP_ID\",\n",
    "                                                            \"PCL_SITENAME\": \"PCL\",\n",
    "                                                            \"DUAL\": \"DUAL_\"},\n",
    "                                                   errors=\"raise\",\n",
    "                                                   inplace=True)\n",
    "df_dict['Element_claims'].rename(columns={\"CCAID\": \"MEMBER_ID\",\n",
    "                                          \"HICN\": \"MEDICARE_ID\",\n",
    "                                          \"CLAIM_NUM\": \"CLAIM_ID\",\n",
    "                                          \"TABLEROWID\": \"CLAIM_LINE\",\n",
    "                                          \"HOSPITAL_CLAIM_TYPE\": \"HOS_CLAIM_TYPE\",\n",
    "                                          \"SERVICE_CODE\": \"CODE\",\n",
    "                                          \"SERVICE_DESC\": \"CODE_DESC\",\n",
    "                                          \"DATE_TO\": \"DATE_THRU\",\n",
    "                                          \"BILLTYPE\": \"BILL_TYPE\",\n",
    "                                          \"BILLTYPE_DESCR\": \"BILL_TYPE_DESCR\",\n",
    "                                          \"DATE_PAID\": \"PAID_DTE\",\n",
    "                                          \"CLAIMCATEGORY_GL1\": \"CLAIM_GROUP\"},\n",
    "                                 errors=\"raise\",\n",
    "                                 inplace=True)\n",
    "df_dict['Element_claims_member_dx'].rename(columns={\"CCAID\": \"MEMBER_ID\",\n",
    "                                                    \"HICN\": \"MEDICARE_ID\",\n",
    "                                                    \"CLAIM_NUM\": \"CLAIM_ID\",\n",
    "                                                    \"DIAGREFNO\": \"DIAG_NUM\"},\n",
    "                                           errors=\"raise\",\n",
    "                                           inplace=True)\n",
    "df_dict['Element_MDS'].rename(columns={\"CCAID\": \"MEMBER_ID\",\n",
    "                                       \"ASSESSMENT_DATE\": \"ENC_DATE\"},\n",
    "                              errors=\"raise\",\n",
    "                              inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "02503b8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 293.6168444156647 seconds ---\n"
     ]
    }
   ],
   "source": [
    "#Create two dictionaries to store the columns and the max len of values in those columns\n",
    "max_col_len = {}\n",
    "col_dict = {}\n",
    "\n",
    "#Vectorizing the length function\n",
    "measurer = np.vectorize(len)\n",
    "\n",
    "#Looping through df_dictionary to capture column names and max len of values in those columns\n",
    "max_col_len = {}\n",
    "for key, value in df_dict.items():\n",
    "    col_len = measurer(df_dict[key].astype(str)).max(axis=0)\n",
    "    max_col_len[key] = col_len\n",
    "    col_dict[key] = df_dict[key].columns.tolist()\n",
    "\n",
    "\n",
    "#Function for joining the two dictionaries with similar keys (claim files)\n",
    "def common_entries(*dcts):\n",
    "    if not dcts:\n",
    "        return\n",
    "    for i in set(dcts[0]).intersection(*dcts[1:]):\n",
    "        yield (i,) + tuple(d[i] for d in dcts)\n",
    "\n",
    "\n",
    "mylist = list(common_entries(col_dict, max_col_len))\n",
    "\n",
    "#Creating new dictionary and zipping the column names with respective max len of values in those columns\n",
    "sql_dict = {}\n",
    "for x in mylist:\n",
    "    sql_dict[x[0]] = list(zip(x[1], x[2]))\n",
    "\n",
    "#Iterating through the list values to prep for SQL to Snowflake\n",
    "sql_script_dict_table = {}\n",
    "for key, value in sql_dict.items():\n",
    "    script_string_table = ''\n",
    "    for (col, max_len) in sql_dict[key]:\n",
    "        script_string_table += str(col) + ' VARCHAR(' + str(max_len + 10) + '),'\n",
    "    sql_script_dict_table[key] = \"(\" + script_string_table[:-1] + \")\"\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eb8dc8c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "       MEMBER_ID          MBI        HICN       MMIS_ID PRODUCT   ENROLL_ST  \\\n0     5364521168  1PQ7T86FD63  281042735M  100027225505     SCO  2004-07-01   \n1     5364521169  2HH6A83NK63  281043939M  100027225513     SCO  2004-07-01   \n2     5364521215  7PE4CW7HF86  036205064D  100005437941     SCO  2004-09-01   \n3     5364521236  4KR5DX1YF65  011767159M  100016631432     SCO  2004-09-01   \n4     5364521251  5YU3H27TQ86  019604163A  100218304242     SCO  2004-10-01   \n...          ...          ...         ...           ...     ...         ...   \n3167  5366075073  5QQ8G88RR24              100004881395     SCO  2022-12-01   \n3168  5366075117  7EQ5W89FW40              100207992163     SCO  2022-12-01   \n3169  5366075504  4MQ4U76AV07              100020312763     SCO  2022-12-01   \n3170  5366075516  4DE9HF7NT36              100210660815     SCO  2022-12-01   \n3171  5366075518  3V75MU5TV62              100210942486     SCO  2022-12-01   \n\n       ENROLL_ED ENROLL_STATUS2                 FULL_NAME         DOB  ...  \\\n0     9999-12-30       Enrolled           Semen Yudkovich  1935-09-19  ...   \n1     2022-02-28    Disenrolled       Margarita Yudkovich  1935-10-27  ...   \n2     2020-01-31    Disenrolled             Barbara Davis  1931-01-30  ...   \n3     2021-03-31    Disenrolled           Semen Tyutyunik  1926-05-05  ...   \n4     9999-12-30       Enrolled            Eduardo Santos  1935-11-03  ...   \n...          ...            ...                       ...         ...  ...   \n3167  9999-12-30       Enrolled               Marcia Pena  1947-03-08  ...   \n3168  9999-12-30       Enrolled  BIENVENIDO DIAZ BASTARDO  1943-05-20  ...   \n3169  9999-12-30       Enrolled         Sebastian Lovasco  1942-03-04  ...   \n3170  9999-12-30       Enrolled            Odylia Guerine  1955-03-11  ...   \n3171  9999-12-30       Enrolled              SAAD D SANAD  1957-11-14  ...   \n\n                        ADDRESS_1 ADDRESS_2     CITY STATE    ZIP COUNTY  \\\n0               67 Silsbee Street     # 502     Lynn    MA  01901  ESSEX   \n1       67 Silsbee Street Apt 502               Lynn    MA  01901  ESSEX   \n2             28 Essex St Room 4B               Lynn    MA  01902  ESSEX   \n3                19 Willow Street   Apt 208     Lynn    MA  01901  ESSEX   \n4       160 Neptune Blvd. Apt 507               Lynn    MA  01905  ESSEX   \n...                           ...       ...      ...   ...    ...    ...   \n3167      196 LAFAYETTE ST APT 2R              Salem    MA  01970  ESSEX   \n3168   29 A NORTH COMMON ST APT14               LYNN    MA  01902  ESSEX   \n3169             92 Wenham Street            Danvers    MA  01923  ESSEX   \n3170  501 Washington Street # 215               Lynn    MA  01901  ESSEX   \n3171      347 Chestnut Street # 1               Lynn    MA  01902  ESSEX   \n\n      ADDR_START    ADDR_END                  PHONE_1            CURRENT_AS_OF  \n0     2004-05-01                (781) 581-3902 [Home]  2023-01-12 19:49:27.000  \n1     2004-07-01  2022-02-28    (781) 581-3902 [Home]  2023-01-12 19:49:27.000  \n2     2012-08-10  2020-01-31    (781) 599-0190 [Home]  2023-01-12 19:49:27.000  \n3     2004-05-01  2021-03-31    (781) 598-1391 [Home]  2023-01-12 19:49:27.000  \n4     2004-05-01                (339) 440-5236 [Home]  2023-01-12 19:49:27.000  \n...          ...         ...                      ...                      ...  \n3167  2020-12-01              (781) 732-0897 [Mobile]  2023-01-12 19:49:27.000  \n3168  2022-12-01                (781) 309-0649 [Home]  2023-01-12 19:49:27.000  \n3169  2022-12-01                (978) 798-4563 [Home]  2023-01-12 19:49:27.000  \n3170  2022-12-01                (781) 389-0485 [Home]  2023-01-12 19:49:27.000  \n3171  2022-12-01                (781) 475-6374 [Home]  2023-01-12 19:49:27.000  \n\n[3172 rows x 25 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>MEMBER_ID</th>\n      <th>MBI</th>\n      <th>HICN</th>\n      <th>MMIS_ID</th>\n      <th>PRODUCT</th>\n      <th>ENROLL_ST</th>\n      <th>ENROLL_ED</th>\n      <th>ENROLL_STATUS2</th>\n      <th>FULL_NAME</th>\n      <th>DOB</th>\n      <th>...</th>\n      <th>ADDRESS_1</th>\n      <th>ADDRESS_2</th>\n      <th>CITY</th>\n      <th>STATE</th>\n      <th>ZIP</th>\n      <th>COUNTY</th>\n      <th>ADDR_START</th>\n      <th>ADDR_END</th>\n      <th>PHONE_1</th>\n      <th>CURRENT_AS_OF</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>5364521168</td>\n      <td>1PQ7T86FD63</td>\n      <td>281042735M</td>\n      <td>100027225505</td>\n      <td>SCO</td>\n      <td>2004-07-01</td>\n      <td>9999-12-30</td>\n      <td>Enrolled</td>\n      <td>Semen Yudkovich</td>\n      <td>1935-09-19</td>\n      <td>...</td>\n      <td>67 Silsbee Street</td>\n      <td># 502</td>\n      <td>Lynn</td>\n      <td>MA</td>\n      <td>01901</td>\n      <td>ESSEX</td>\n      <td>2004-05-01</td>\n      <td></td>\n      <td>(781) 581-3902 [Home]</td>\n      <td>2023-01-12 19:49:27.000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>5364521169</td>\n      <td>2HH6A83NK63</td>\n      <td>281043939M</td>\n      <td>100027225513</td>\n      <td>SCO</td>\n      <td>2004-07-01</td>\n      <td>2022-02-28</td>\n      <td>Disenrolled</td>\n      <td>Margarita Yudkovich</td>\n      <td>1935-10-27</td>\n      <td>...</td>\n      <td>67 Silsbee Street Apt 502</td>\n      <td></td>\n      <td>Lynn</td>\n      <td>MA</td>\n      <td>01901</td>\n      <td>ESSEX</td>\n      <td>2004-07-01</td>\n      <td>2022-02-28</td>\n      <td>(781) 581-3902 [Home]</td>\n      <td>2023-01-12 19:49:27.000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5364521215</td>\n      <td>7PE4CW7HF86</td>\n      <td>036205064D</td>\n      <td>100005437941</td>\n      <td>SCO</td>\n      <td>2004-09-01</td>\n      <td>2020-01-31</td>\n      <td>Disenrolled</td>\n      <td>Barbara Davis</td>\n      <td>1931-01-30</td>\n      <td>...</td>\n      <td>28 Essex St Room 4B</td>\n      <td></td>\n      <td>Lynn</td>\n      <td>MA</td>\n      <td>01902</td>\n      <td>ESSEX</td>\n      <td>2012-08-10</td>\n      <td>2020-01-31</td>\n      <td>(781) 599-0190 [Home]</td>\n      <td>2023-01-12 19:49:27.000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>5364521236</td>\n      <td>4KR5DX1YF65</td>\n      <td>011767159M</td>\n      <td>100016631432</td>\n      <td>SCO</td>\n      <td>2004-09-01</td>\n      <td>2021-03-31</td>\n      <td>Disenrolled</td>\n      <td>Semen Tyutyunik</td>\n      <td>1926-05-05</td>\n      <td>...</td>\n      <td>19 Willow Street</td>\n      <td>Apt 208</td>\n      <td>Lynn</td>\n      <td>MA</td>\n      <td>01901</td>\n      <td>ESSEX</td>\n      <td>2004-05-01</td>\n      <td>2021-03-31</td>\n      <td>(781) 598-1391 [Home]</td>\n      <td>2023-01-12 19:49:27.000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5364521251</td>\n      <td>5YU3H27TQ86</td>\n      <td>019604163A</td>\n      <td>100218304242</td>\n      <td>SCO</td>\n      <td>2004-10-01</td>\n      <td>9999-12-30</td>\n      <td>Enrolled</td>\n      <td>Eduardo Santos</td>\n      <td>1935-11-03</td>\n      <td>...</td>\n      <td>160 Neptune Blvd. Apt 507</td>\n      <td></td>\n      <td>Lynn</td>\n      <td>MA</td>\n      <td>01905</td>\n      <td>ESSEX</td>\n      <td>2004-05-01</td>\n      <td></td>\n      <td>(339) 440-5236 [Home]</td>\n      <td>2023-01-12 19:49:27.000</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3167</th>\n      <td>5366075073</td>\n      <td>5QQ8G88RR24</td>\n      <td></td>\n      <td>100004881395</td>\n      <td>SCO</td>\n      <td>2022-12-01</td>\n      <td>9999-12-30</td>\n      <td>Enrolled</td>\n      <td>Marcia Pena</td>\n      <td>1947-03-08</td>\n      <td>...</td>\n      <td>196 LAFAYETTE ST APT 2R</td>\n      <td></td>\n      <td>Salem</td>\n      <td>MA</td>\n      <td>01970</td>\n      <td>ESSEX</td>\n      <td>2020-12-01</td>\n      <td></td>\n      <td>(781) 732-0897 [Mobile]</td>\n      <td>2023-01-12 19:49:27.000</td>\n    </tr>\n    <tr>\n      <th>3168</th>\n      <td>5366075117</td>\n      <td>7EQ5W89FW40</td>\n      <td></td>\n      <td>100207992163</td>\n      <td>SCO</td>\n      <td>2022-12-01</td>\n      <td>9999-12-30</td>\n      <td>Enrolled</td>\n      <td>BIENVENIDO DIAZ BASTARDO</td>\n      <td>1943-05-20</td>\n      <td>...</td>\n      <td>29 A NORTH COMMON ST APT14</td>\n      <td></td>\n      <td>LYNN</td>\n      <td>MA</td>\n      <td>01902</td>\n      <td>ESSEX</td>\n      <td>2022-12-01</td>\n      <td></td>\n      <td>(781) 309-0649 [Home]</td>\n      <td>2023-01-12 19:49:27.000</td>\n    </tr>\n    <tr>\n      <th>3169</th>\n      <td>5366075504</td>\n      <td>4MQ4U76AV07</td>\n      <td></td>\n      <td>100020312763</td>\n      <td>SCO</td>\n      <td>2022-12-01</td>\n      <td>9999-12-30</td>\n      <td>Enrolled</td>\n      <td>Sebastian Lovasco</td>\n      <td>1942-03-04</td>\n      <td>...</td>\n      <td>92 Wenham Street</td>\n      <td></td>\n      <td>Danvers</td>\n      <td>MA</td>\n      <td>01923</td>\n      <td>ESSEX</td>\n      <td>2022-12-01</td>\n      <td></td>\n      <td>(978) 798-4563 [Home]</td>\n      <td>2023-01-12 19:49:27.000</td>\n    </tr>\n    <tr>\n      <th>3170</th>\n      <td>5366075516</td>\n      <td>4DE9HF7NT36</td>\n      <td></td>\n      <td>100210660815</td>\n      <td>SCO</td>\n      <td>2022-12-01</td>\n      <td>9999-12-30</td>\n      <td>Enrolled</td>\n      <td>Odylia Guerine</td>\n      <td>1955-03-11</td>\n      <td>...</td>\n      <td>501 Washington Street # 215</td>\n      <td></td>\n      <td>Lynn</td>\n      <td>MA</td>\n      <td>01901</td>\n      <td>ESSEX</td>\n      <td>2022-12-01</td>\n      <td></td>\n      <td>(781) 389-0485 [Home]</td>\n      <td>2023-01-12 19:49:27.000</td>\n    </tr>\n    <tr>\n      <th>3171</th>\n      <td>5366075518</td>\n      <td>3V75MU5TV62</td>\n      <td></td>\n      <td>100210942486</td>\n      <td>SCO</td>\n      <td>2022-12-01</td>\n      <td>9999-12-30</td>\n      <td>Enrolled</td>\n      <td>SAAD D SANAD</td>\n      <td>1957-11-14</td>\n      <td>...</td>\n      <td>347 Chestnut Street # 1</td>\n      <td></td>\n      <td>Lynn</td>\n      <td>MA</td>\n      <td>01902</td>\n      <td>ESSEX</td>\n      <td>2022-12-01</td>\n      <td></td>\n      <td>(781) 475-6374 [Home]</td>\n      <td>2023-01-12 19:49:27.000</td>\n    </tr>\n  </tbody>\n</table>\n<p>3172 rows Ã— 25 columns</p>\n</div>"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dict['Element_claims_member_contact']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "#Creating of parameters for securing connection to Snowflake-credentials stored in local environment variables\n",
    "username = os.getenv('Snowflake_User')\n",
    "password = os.getenv('Snowflake_password')\n",
    "account = os.getenv('Snowflake_account')\n",
    "\n",
    "#Define parameters if neccessary\n",
    "warehouse = 'DEVELOPER_STANDARD'\n",
    "database = 'VESTA_DEVELOPMENT'\n",
    "schema = 'ANALYST_SANDBOX'\n",
    "\n",
    "#Create connection object for Snowflake connection\n",
    "conn = sf.connect(user=username, password=password, account=account, warehouse=warehouse)\n",
    "\n",
    "\n",
    "#Execution function\n",
    "def execute_query(connection, query):\n",
    "    cursor = connection.cursor()\n",
    "    cursor.execute(query)\n",
    "    cursor.close\n",
    "\n",
    "\n",
    "#Define Database to use in Snowflake\n",
    "sql = 'USE DATABASE {}'.format(database)\n",
    "execute_query(conn, sql)\n",
    "\n",
    "#Define Schema to use in Snowflake\n",
    "sql = 'USE SCHEMA {}.{}'.format(database, schema)\n",
    "execute_query(conn, sql)\n",
    "\n",
    "#Define Warehouse to use in Snowflake\n",
    "sql = 'USE WAREHOUSE {}'.format(warehouse)\n",
    "execute_query(conn, sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### SQL to drop tables prior to creating and uploading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "################################## Contact Table\n",
    "try:\n",
    "    sql = 'DROP TABLE IF EXISTS CCA_CONTACT_RAW_TEST'\n",
    "    execute_query(conn, sql)\n",
    "\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "################################## Claims Table\n",
    "try:\n",
    "    sql = 'DROP TABLE IF EXISTS CCA_CLAIMS_RAW_TEST'\n",
    "    execute_query(conn, sql)\n",
    "\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "################################## Demographic Table\n",
    "try:\n",
    "    sql = 'DROP TABLE IF EXISTS CCA_DEMO_RAW_TEST'\n",
    "    execute_query(conn, sql)\n",
    "\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "################################## DX Table\n",
    "try:\n",
    "    sql = 'DROP TABLE IF EXISTS CCA_DX_RAW_TEST'\n",
    "    execute_query(conn, sql)\n",
    "\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "################################## Enroll Table\n",
    "try:\n",
    "    sql = 'DROP TABLE IF EXISTS CCA_ENROLL_RAW_TEST'\n",
    "    execute_query(conn, sql)\n",
    "\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "################################## PCP Table\n",
    "try:\n",
    "    sql = 'DROP TABLE IF EXISTS CCA_PCP_RAW_TEST'\n",
    "    execute_query(conn, sql)\n",
    "\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "    ################################## MDS Table\n",
    "try:\n",
    "    sql = 'DROP TABLE IF EXISTS CCA_MDS_RAW_TEST'\n",
    "    execute_query(conn, sql)\n",
    "\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1d315275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 309.63251543045044 seconds ---\n"
     ]
    }
   ],
   "source": [
    "\n",
    "################################## MEMBER CONTACT SQL\n",
    "\n",
    "try:\n",
    "    sql = 'CREATE TABLE IF NOT EXISTS CCA_CONTACT_RAW_TEST ' + sql_script_dict_table['Element_claims_member_contact']\n",
    "    execute_query(conn, sql)\n",
    "\n",
    "    success, nchucks, nrows, _ = write_pandas(conn, df_dict['Element_claims_member_contact'], 'CCA_CONTACT_RAW_TEST')\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "###################################\n",
    "\n",
    "################################## CLAIMS SQL\n",
    "\n",
    "try:\n",
    "    sql = 'CREATE TABLE IF NOT EXISTS CCA_CLAIMS_RAW_TEST ' + sql_script_dict_table['Element_claims']\n",
    "    execute_query(conn, sql)\n",
    "\n",
    "    success, nchucks, nrows, _ = write_pandas(conn, df_dict['Element_claims'], 'CCA_CLAIMS_RAW_TEST')\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "# ###################################\n",
    "#\n",
    "# ################################## DEMO SQL\n",
    "#\n",
    "try:\n",
    "    sql = 'CREATE TABLE IF NOT EXISTS CCA_DEMO_RAW_TEST ' + sql_script_dict_table['Element_claims_member_demographics']\n",
    "    execute_query(conn, sql)\n",
    "\n",
    "    success, nchucks, nrows, _ = write_pandas(conn, df_dict['Element_claims_member_demographics'], 'CCA_DEMO_RAW_TEST')\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "# ###################################\n",
    "#\n",
    "# ################################## DX SQL\n",
    "\n",
    "try:\n",
    "    sql = 'CREATE TABLE IF NOT EXISTS CCA_DX_RAW_TEST ' + sql_script_dict_table['Element_claims_member_dx']\n",
    "    execute_query(conn, sql)\n",
    "\n",
    "    success, nchucks, nrows, _ = write_pandas(conn, df_dict['Element_claims_member_dx'], 'CCA_DX_RAW_TEST')\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "# ###################################\n",
    "#\n",
    "# ################################## ENROLLMENT SQL\n",
    "\n",
    "try:\n",
    "    sql = 'CREATE TABLE IF NOT EXISTS CCA_ENROLL_RAW_TEST' + sql_script_dict_table['Element_claims_member_enrollment']\n",
    "    execute_query(conn, sql)\n",
    "\n",
    "    success, nchucks, nrows, _ = write_pandas(conn, df_dict['Element_claims_member_enrollment'], 'CCA_ENROLL_RAW_TEST')\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "# ###################################\n",
    "#\n",
    "# ################################## PCP SQL\n",
    "\n",
    "try:\n",
    "    sql = 'CREATE TABLE IF NOT EXISTS CCA_PCP_RAW_TEST' + sql_script_dict_table['Element_claims_PCP_contact']\n",
    "    execute_query(conn, sql)\n",
    "\n",
    "    success, nchucks, nrows, _ = write_pandas(conn, df_dict['Element_claims_PCP_contact'], 'CCA_PCP_RAW_TEST')\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "# # ###################################\n",
    "#\n",
    "# ################################## MDS SQL\n",
    "\n",
    "try:\n",
    "    sql = 'CREATE TABLE IF NOT EXISTS CCA_MDS_RAW_TEST' + sql_script_dict_table['Element_MDS']\n",
    "    execute_query(conn, sql)\n",
    "\n",
    "    success, nchucks, nrows, _ = write_pandas(conn, df_dict['Element_MDS'], 'CCA_MDS_RAW_TEST')\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "###################################\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7c566bff",
   "metadata": {},
   "outputs": [
    {
     "ename": "SMTPAuthenticationError",
     "evalue": "(535, b'5.7.8 Username and Password not accepted. Learn more at\\n5.7.8  https://support.google.com/mail/?p=BadCredentials v10-20020a05620a440a00b006fab416015csm2548837qkp.25 - gsmtp')",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mSMTPAuthenticationError\u001B[0m                   Traceback (most recent call last)",
      "Input \u001B[1;32mIn [24]\u001B[0m, in \u001B[0;36m<cell line: 14>\u001B[1;34m()\u001B[0m\n\u001B[0;32m     13\u001B[0m context \u001B[38;5;241m=\u001B[39m ssl\u001B[38;5;241m.\u001B[39mcreate_default_context()\n\u001B[0;32m     14\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m smtplib\u001B[38;5;241m.\u001B[39mSMTP_SSL(smtp_server, port, context\u001B[38;5;241m=\u001B[39mcontext) \u001B[38;5;28;01mas\u001B[39;00m server:\n\u001B[1;32m---> 15\u001B[0m     \u001B[43mserver\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlogin\u001B[49m\u001B[43m(\u001B[49m\u001B[43msender_email\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpassword\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     16\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m receiver_email \u001B[38;5;129;01min\u001B[39;00m receiver_email_list:\n\u001B[0;32m     17\u001B[0m         server\u001B[38;5;241m.\u001B[39msendmail(sender_email, receiver_email, message)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\NewBase\\lib\\smtplib.py:750\u001B[0m, in \u001B[0;36mSMTP.login\u001B[1;34m(self, user, password, initial_response_ok)\u001B[0m\n\u001B[0;32m    747\u001B[0m         last_exception \u001B[38;5;241m=\u001B[39m e\n\u001B[0;32m    749\u001B[0m \u001B[38;5;66;03m# We could not login successfully.  Return result of last attempt.\u001B[39;00m\n\u001B[1;32m--> 750\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m last_exception\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\NewBase\\lib\\smtplib.py:739\u001B[0m, in \u001B[0;36mSMTP.login\u001B[1;34m(self, user, password, initial_response_ok)\u001B[0m\n\u001B[0;32m    737\u001B[0m method_name \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mauth_\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;241m+\u001B[39m authmethod\u001B[38;5;241m.\u001B[39mlower()\u001B[38;5;241m.\u001B[39mreplace(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m-\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m_\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m    738\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 739\u001B[0m     (code, resp) \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mauth\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    740\u001B[0m \u001B[43m        \u001B[49m\u001B[43mauthmethod\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mgetattr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmethod_name\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    741\u001B[0m \u001B[43m        \u001B[49m\u001B[43minitial_response_ok\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minitial_response_ok\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    742\u001B[0m     \u001B[38;5;66;03m# 235 == 'Authentication successful'\u001B[39;00m\n\u001B[0;32m    743\u001B[0m     \u001B[38;5;66;03m# 503 == 'Error: already authenticated'\u001B[39;00m\n\u001B[0;32m    744\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m code \u001B[38;5;129;01min\u001B[39;00m (\u001B[38;5;241m235\u001B[39m, \u001B[38;5;241m503\u001B[39m):\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\NewBase\\lib\\smtplib.py:662\u001B[0m, in \u001B[0;36mSMTP.auth\u001B[1;34m(self, mechanism, authobject, initial_response_ok)\u001B[0m\n\u001B[0;32m    660\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m code \u001B[38;5;129;01min\u001B[39;00m (\u001B[38;5;241m235\u001B[39m, \u001B[38;5;241m503\u001B[39m):\n\u001B[0;32m    661\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m (code, resp)\n\u001B[1;32m--> 662\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m SMTPAuthenticationError(code, resp)\n",
      "\u001B[1;31mSMTPAuthenticationError\u001B[0m: (535, b'5.7.8 Username and Password not accepted. Learn more at\\n5.7.8  https://support.google.com/mail/?p=BadCredentials v10-20020a05620a440a00b006fab416015csm2548837qkp.25 - gsmtp')"
     ]
    }
   ],
   "source": [
    "my_string = '\\n'.join(claimslog)\n",
    "\n",
    "port = 465  # For SSL\n",
    "smtp_server = \"smtp.gmail.com\"\n",
    "sender_email = \"VestaPingLog@gmail.com\"  # Enter your address\n",
    "receiver_email_list = [\"jdriggers@vestahealthcare.com\", \"john@vestahealthcare.com\",\n",
    "                       'joe@vestahealthcare.com']  # Enter receiver address\n",
    "password = os.getenv('Vesta_Ping_Log_Email') #Need password for VestaPingLog@gmail.com\n",
    "message = \"Subject: Ping Logs \\n\" + '''\n",
    "             \n",
    "''' + my_string\n",
    "\n",
    "context = ssl.create_default_context()\n",
    "with smtplib.SMTP_SSL(smtp_server, port, context=context) as server:\n",
    "    server.login(sender_email, password)\n",
    "    for receiver_email in receiver_email_list:\n",
    "        server.sendmail(sender_email, receiver_email, message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('NewBase')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "4bb5f7e03c56d6e91378b915f266587dc28bbd5e1a358e8c73c01ed5dd6d43c1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
