{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72278115",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Necessary dependencies\n",
    "import pandas as pd\n",
    "import snowflake.connector as sf\n",
    "import numpy as np\n",
    "import time\n",
    "import boto3\n",
    "import os\n",
    "import zipfile\n",
    "import smtplib, ssl\n",
    "import shutil\n",
    "import csv\n",
    "from snowflake.connector.pandas_tools import write_pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ba74034",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Log for review\n",
    "start_time = time.time()\n",
    "claimslog = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a58ff69",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    #Create Local Directory to store files in temporarily\n",
    "    os.makedirs('C:\\\\Users\\\\Jad Driggers\\\\Documents\\\\Vesta\\\\CCAFILES')\n",
    "    os.chdir('C:\\\\Users\\\\Jad Driggers\\\\Documents\\\\Vesta\\\\CCAFILES')\n",
    "    root_directory = os.getcwd()\n",
    "    claimslog.append('Successfully created CCA File Temporary Folder at ' + time.strftime('%Y-%m-%d %H:%M:%S',\n",
    "                                                                                          time.localtime(time.time())))\n",
    "except Exception as e:\n",
    "    claimslog.append('There was an error with creating the temporary CCA File - ' + str(e))\n",
    "    print('Successfully created CCA File Temporary Folder at ' + time.strftime('%Y-%m-%d %H:%M:%S',\n",
    "                                                                               time.localtime(time.time())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1967f2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AWS connection object created at 2022-12-16 15:35:50\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    #Create Connection Object for Connecting to AWS\n",
    "    s3 = boto3.resource(\n",
    "        service_name='s3',\n",
    "        region_name='us-east-1',\n",
    "        aws_access_key_id=os.getenv('aws_access_key_id'),\n",
    "        aws_secret_access_key=os.getenv('aws_secret_access_key'))\n",
    "    print('AWS connection object created at ' + time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(time.time())))\n",
    "    claimslog.append(\n",
    "        'AWS connection object created at ' + time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(time.time())))\n",
    "except Exception as e:\n",
    "    print('There was an error with creating the AWS connection object - ' + str(e))\n",
    "    claimslog.append('There was an error with creating the AWS connection object - ' + str(e))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a96227da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for CCA Files that start like Element claims 202212.zip and Element MDS 202212.zip at 2022-12-16 15:35:54\n"
     ]
    }
   ],
   "source": [
    "#Create the file name format for locating the proper CCA files to parse\n",
    "\n",
    "filename_format_list = ['Element claims 202212.zip', 'Element MDS 202212.zip']\n",
    "claimslog.append('Looking for CCA Files that start like ' + \" and \".join(filename_format_list) + ' at ' + time.strftime(\n",
    "    '%Y-%m-%d %H:%M:%S', time.localtime(time.time())))\n",
    "print('Looking for CCA Files that start like ' + \" and \".join(filename_format_list) + ' at ' + time.strftime(\n",
    "    '%Y-%m-%d %H:%M:%S', time.localtime(time.time())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "79a82ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a list to store all the keys (file names) to download\n",
    "\n",
    "key_list = []\n",
    "\n",
    "try:\n",
    "    #Searching the S3 bucket for the most current Ping Files\n",
    "    for obj in s3.Bucket('hometeam-clinical-data').objects.all():\n",
    "        for filename_format in filename_format_list:\n",
    "            if filename_format in str(obj):\n",
    "                #print(obj.key)\n",
    "                key_list.append(obj.key)\n",
    "\n",
    "except Exception as e:\n",
    "    claimslog.append('There was an error while looking for most CCA Files - ' + str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['raw/cca/Element MDS 202212.zip', 'raw/cca/Element claims 202212.zip']\n"
     ]
    }
   ],
   "source": [
    "print(key_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e6ccf1d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files were successfully downloaded at 2022-12-16 15:37:21\n",
      "Files were successfully downloaded at 2022-12-16 15:37:33\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    #Downloading each of the files found in the key list\n",
    "    for file in key_list:\n",
    "        s3.Bucket('hometeam-clinical-data').download_file(file, file.split('/')[2])\n",
    "        print(\n",
    "            'Files were successfully downloaded at ' + time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(time.time())))\n",
    "    claimslog.append(\n",
    "        'Files were successfully downloaded at ' + time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(time.time())))\n",
    "except Exception as e:\n",
    "    claimslog.append('There was an error while trying to download the CCA Files - ' + str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": "{'ResponseMetadata': {'RequestId': 'P928AS9WDP0VP36C',\n  'HostId': 'BxI3py9dDMktm/GD9ejTdwSukLCCYrq/2y2bJ9pHosL3c/Vvbs3+TDMq0kAO+Etjsr4xFxJ+Tyg=',\n  'HTTPStatusCode': 204,\n  'HTTPHeaders': {'x-amz-id-2': 'BxI3py9dDMktm/GD9ejTdwSukLCCYrq/2y2bJ9pHosL3c/Vvbs3+TDMq0kAO+Etjsr4xFxJ+Tyg=',\n   'x-amz-request-id': 'P928AS9WDP0VP36C',\n   'date': 'Fri, 16 Dec 2022 20:32:01 GMT',\n   'x-amz-version-id': '.fki0l0uct8rwI41tSIbHWPFyZ27j3a6',\n   'x-amz-delete-marker': 'true',\n   'server': 'AmazonS3'},\n  'RetryAttempts': 0},\n 'DeleteMarker': True,\n 'VersionId': '.fki0l0uct8rwI41tSIbHWPFyZ27j3a6'}"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Move files into Monthly_Claims folder\n",
    "bucket = 'hometeam-clinical-data'\n",
    "copy_source = {\n",
    "    'Bucket': bucket,\n",
    "    'Key': 'raw/cca/Element MDS 202212.zip',\n",
    "    }\n",
    "\n",
    "copy_source2 = {\n",
    "    'Bucket': bucket,\n",
    "    'Key': 'raw/cca/Element claims 202212.zip',\n",
    "}\n",
    "s3.meta.client.copy(copy_source,bucket, 'raw/cca/Monthly_Claims/Element MDS 202212.zip')\n",
    "s3.meta.client.copy(copy_source2,bucket, 'raw/cca/Monthly_Claims/Element claims 202212.zip')\n",
    "#s3.meta.client.delete_object('hometeam-clinical-data','Element MDS 202210.zip')\n",
    "# s3.client.delete_object(Bucket=bucket, Key='Element MDS 202210.zip')\n",
    "s3_object = s3.Object('hometeam-clinical-data', 'raw/cca/Monthly_Claims/Element MDS 202212.zip')\n",
    "s3_object.delete()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ca78188d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#On local computer, change directory and set directory for unzipping of files.\n",
    "os.chdir('C:\\\\Users\\\\Jad Driggers\\\\Documents\\\\Vesta\\\\CCAFILES')\n",
    "root_directory = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "29382098",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Locate only Zipped Files\n",
    "files_to_unzip = []\n",
    "for filename in os.listdir(root_directory):\n",
    "    if 'zip' in filename:\n",
    "        files_to_unzip.append(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5dec649e",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    #Unzip each file in the Zipped files list\n",
    "    for zipped_file in files_to_unzip:\n",
    "        with zipfile.ZipFile(root_directory + \"\\\\\" + zipped_file, 'r') as zip_ref:\n",
    "            #print(zipped_file)\n",
    "            zip_ref.extractall(root_directory)\n",
    "    shutil.unpack_archive(root_directory + \"\\\\\" + zipped_file, root_directory + \"\\\\\" + zipped_file.split('.')[0])\n",
    "    claimslog.append(\n",
    "        'Successfully Unzipped each file at ' + time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(time.time())))\n",
    "except Exception as e:\n",
    "    claimslog.append('There was an error while trying to unzip each file - ' + str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Element_claims_member_contact\n",
      "Element_claims_member_demographics\n",
      "Element_claims_member_dx\n",
      "Element_claims_member_enrollment\n",
      "Element_claims_member_HCC\n",
      "Element_claims_PCP_contact\n",
      "Element_claims\n",
      "Element_MDS\n"
     ]
    }
   ],
   "source": [
    "#% % timeit\n",
    "#Create dictionary to store dataframes as they are created \n",
    "df_dict = {}\n",
    "error_dict = {}\n",
    "\n",
    "#Set current directory\n",
    "cwd = os.chdir('C:\\\\Users\\\\Jad Driggers\\\\Documents\\\\Vesta\\\\CCAFILES')\n",
    "\n",
    "#Loop through all txt files in the directory\n",
    "for i, file in enumerate(os.listdir(cwd)):\n",
    "    if '.txt' in file:\n",
    "\n",
    "        #empty lists to store the data while cleaning\n",
    "        df_list = []\n",
    "        df_error_list = []\n",
    "\n",
    "        #open the txt file\n",
    "        with open(file, 'r') as csvfile:\n",
    "            reader = csv.reader(csvfile, delimiter='\\t')\n",
    "\n",
    "            #read through each line and find any rows with errors\n",
    "            for i, row in enumerate(reader):\n",
    "                if i == 0:\n",
    "                    #capture the correct number of columns for the dataframe\n",
    "                    correct_columns = len(row)\n",
    "\n",
    "                df_list.append(row)\n",
    "\n",
    "                #create list of rows with errors\n",
    "                if len(row) < correct_columns:\n",
    "                    df_error_list.append(i)\n",
    "\n",
    "            #Check to see if the list row in the data frame is an empty row, if so, drop it\n",
    "            if len(df_list[df_error_list[-1]]) == 0:\n",
    "                df_error_list.pop()\n",
    "\n",
    "            #The error exists between two rows, so looking at the second occurance of an error \n",
    "            #and deleting the first item should fix the error\n",
    "            for i, error in enumerate(df_error_list):\n",
    "                if i % 2 != 0:\n",
    "                    df_list[error].pop(0)\n",
    "\n",
    "            #Loop back through the error list and join first errors to second errors to make a complete row\n",
    "            for i, error in enumerate(df_error_list):\n",
    "                if i % 2 == 0:\n",
    "                    df_list[error] = df_list[error] + df_list[error + 1]\n",
    "\n",
    "            #Loop back through the entire data frame list to delete those rows that are smaller than the correct\n",
    "            #number of columns\n",
    "            for i, item in enumerate(df_list):\n",
    "                if len(item) < correct_columns:\n",
    "                    del df_list[i]\n",
    "\n",
    "            df = pd.DataFrame(df_list[1:])\n",
    "            df.columns = df_list[0]\n",
    "            df = df.rename(columns={df.columns[0]: df.columns[0][3:]})\n",
    "            df = df.astype(str)\n",
    "            df.columns = map(lambda x: str(x).upper(), df.columns)\n",
    "            df_dict[csvfile.name.replace(' ', '_').split(\".\")[0]] = df\n",
    "            error_dict[csvfile.name.replace(' ', '_').split(\".\")[0]] = df_error_list\n",
    "\n",
    "        csvfile.close()\n",
    "\n",
    "for key, value in df_dict.items():\n",
    "    print(key)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e675666d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Delete all contents in the temporary CCA Folder\n",
    "os.chdir('C:\\\\Users\\\\Jad Driggers\\\\Documents\\\\Vesta')\n",
    "shutil.rmtree('C:\\\\Users\\\\Jad Driggers\\\\Documents\\\\Vesta\\\\CCAFILES')\n",
    "claimslog.append('Successfully Deleted all contents in temporary CCA Folder at ' + time.strftime('%Y-%m-%d %H:%M:%S',\n",
    "                                                                                                 time.localtime(\n",
    "                                                                                                     time.time())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "28ec5abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict['Element_claims_member_demographics'].rename(columns={\"CCAID\": \"MEMBER_ID\",\n",
    "                                                              \"NAME\": \"MNAME\",\n",
    "                                                              \"PCL_SITENAME\": \"PCL\",\n",
    "                                                              \"PCL_SUMMARYNAME\": \"PCL_SUMMARY\",\n",
    "                                                              \"PCL_CAPSITE\": \"PCL_CAP\",\n",
    "                                                              \"DUAL\": \"DUAL_\",\n",
    "                                                              \"GC_ENGAGEMENTSTATUS\": \"GC_ENGAGEMENT_STATUS\",\n",
    "                                                              \"MDS_UNREACHABLEFLAG\": \"MDS_UNREACHABLE\"},\n",
    "                                                     errors=\"raise\",\n",
    "                                                     inplace=True)\n",
    "df_dict['Element_claims_member_contact'].rename(columns={\"CCAID\": \"MEMBER_ID\",\n",
    "                                                         \"ENR_SPAN_START\": \"ENROLL_ST\",\n",
    "                                                         \"ENR_SPAN_END\": \"ENROLL_ED\",\n",
    "                                                         \"ENROLL_STATUS\": \"ENROLL_STATUS2\",\n",
    "                                                         \"NAME\": \"FULL_NAME\",\n",
    "                                                         \"AGE_NOW\": \"AGE\",\n",
    "                                                         \"GENDER\": \"SEX\",\n",
    "                                                         \"LANGUAGE\": \"LANGUAGE_SPOKEN\",\n",
    "                                                         \"ADDRESS1\": \"ADDRESS_1\",\n",
    "                                                         \"ADDRESS2\": \"ADDRESS_2\",\n",
    "                                                         \"LATEST_PHONE\": \"PHONE_1\"},\n",
    "                                                errors=\"raise\",\n",
    "                                                inplace=True)\n",
    "df_dict['Element_claims_member_enrollment'].rename(columns={\"CCAID\": \"MEMBER_ID\",\n",
    "                                                            \"PCP_PROVK\": \"PCP_ID\",\n",
    "                                                            \"PCL_SITENAME\": \"PCL\",\n",
    "                                                            \"DUAL\": \"DUAL_\"},\n",
    "                                                   errors=\"raise\",\n",
    "                                                   inplace=True)\n",
    "df_dict['Element_claims'].rename(columns={\"CCAID\": \"MEMBER_ID\",\n",
    "                                          \"HICN\": \"MEDICARE_ID\",\n",
    "                                          \"CLAIM_NUM\": \"CLAIM_ID\",\n",
    "                                          \"TABLEROWID\": \"CLAIM_LINE\",\n",
    "                                          \"HOSPITAL_CLAIM_TYPE\": \"HOS_CLAIM_TYPE\",\n",
    "                                          \"SERVICE_CODE\": \"CODE\",\n",
    "                                          \"SERVICE_DESC\": \"CODE_DESC\",\n",
    "                                          \"DATE_TO\": \"DATE_THRU\",\n",
    "                                          \"BILLTYPE\": \"BILL_TYPE\",\n",
    "                                          \"BILLTYPE_DESCR\": \"BILL_TYPE_DESCR\",\n",
    "                                          \"DATE_PAID\": \"PAID_DTE\",\n",
    "                                          \"CLAIMCATEGORY_GL1\": \"CLAIM_GROUP\"},\n",
    "                                 errors=\"raise\",\n",
    "                                 inplace=True)\n",
    "df_dict['Element_claims_member_dx'].rename(columns={\"CCAID\": \"MEMBER_ID\",\n",
    "                                                    \"HICN\": \"MEDICARE_ID\",\n",
    "                                                    \"CLAIM_NUM\": \"CLAIM_ID\",\n",
    "                                                    \"DIAGREFNO\": \"DIAG_NUM\"},\n",
    "                                           errors=\"raise\",\n",
    "                                           inplace=True)\n",
    "df_dict['Element_MDS'].rename(columns={\"CCAID\": \"MEMBER_ID\",\n",
    "                                       \"ASSESSMENT_DATE\": \"ENC_DATE\"},\n",
    "                              errors=\"raise\",\n",
    "                              inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "02503b8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 370.15873074531555 seconds ---\n"
     ]
    }
   ],
   "source": [
    "#Create two dictionaries to store the columns and the max len of values in those columns\n",
    "max_col_len = {}\n",
    "col_dict = {}\n",
    "\n",
    "#Vectorizing the length function\n",
    "measurer = np.vectorize(len)\n",
    "\n",
    "#Looping through df_dictionary to capture column names and max len of values in those columns\n",
    "max_col_len = {}\n",
    "for key, value in df_dict.items():\n",
    "    col_len = measurer(df_dict[key].astype(str)).max(axis=0)\n",
    "    max_col_len[key] = col_len\n",
    "    col_dict[key] = df_dict[key].columns.tolist()\n",
    "\n",
    "\n",
    "#Function for joining the two dictionaries with similar keys (claim files)\n",
    "def common_entries(*dcts):\n",
    "    if not dcts:\n",
    "        return\n",
    "    for i in set(dcts[0]).intersection(*dcts[1:]):\n",
    "        yield (i,) + tuple(d[i] for d in dcts)\n",
    "\n",
    "\n",
    "mylist = list(common_entries(col_dict, max_col_len))\n",
    "\n",
    "#Creating new dictionary and zipping the column names with respective max len of values in those columns\n",
    "sql_dict = {}\n",
    "for x in mylist:\n",
    "    sql_dict[x[0]] = list(zip(x[1], x[2]))\n",
    "\n",
    "#Iterating through the list values to prep for SQL to Snowflake\n",
    "sql_script_dict_table = {}\n",
    "for key, value in sql_dict.items():\n",
    "    script_string_table = ''\n",
    "    for (col, max_len) in sql_dict[key]:\n",
    "        script_string_table += str(col) + ' VARCHAR(' + str(max_len + 10) + '),'\n",
    "    sql_script_dict_table[key] = \"(\" + script_string_table[:-1] + \")\"\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eb8dc8c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "       MEMBER_ID          MBI        HICN       MMIS_ID PRODUCT   ENROLL_ST  \\\n0     5364521168  1PQ7T86FD63  281042735M  100027225505     SCO  2004-07-01   \n1     5364521169  2HH6A83NK63  281043939M  100027225513     SCO  2004-07-01   \n2     5364521215  7PE4CW7HF86  036205064D  100005437941     SCO  2004-09-01   \n3     5364521236  4KR5DX1YF65  011767159M  100016631432     SCO  2004-09-01   \n4     5364521251  5YU3H27TQ86  019604163A  100218304242     SCO  2004-10-01   \n...          ...          ...         ...           ...     ...         ...   \n3142  5366070702  9KW1C85DD28              100221657412     SCO  2022-11-01   \n3143  5366070866                           100035368751     SCO  2022-11-01   \n3144  5366070873                           100005738123     SCO  2022-11-01   \n3145  5366070928  1KT8GY1FH59              100033762004     SCO  2022-11-01   \n3146  5366070930  9D56V50DF68              100225072246     SCO  2022-11-01   \n\n       ENROLL_ED ENROLL_STATUS2                  FULL_NAME         DOB  ...  \\\n0     9999-12-30       Enrolled            Semen Yudkovich  1935-09-19  ...   \n1     2022-02-28    Disenrolled        Margarita Yudkovich  1935-10-27  ...   \n2     2020-01-31    Disenrolled              Barbara Davis  1931-01-30  ...   \n3     2021-03-31    Disenrolled            Semen Tyutyunik  1926-05-05  ...   \n4     9999-12-30       Enrolled             Eduardo Santos  1935-11-03  ...   \n...          ...            ...                        ...         ...  ...   \n3142  9999-12-30       Enrolled     Yvelisse Aponte Derich  1947-04-06  ...   \n3143  9999-12-30       Enrolled  Victor Espinosa Rodriguez  1953-08-11  ...   \n3144  9999-12-30       Enrolled                   RUN NOUM  1955-06-05  ...   \n3145  9999-12-30       Enrolled          BARBARA F JOHNSON  1951-01-10  ...   \n3146  9999-12-30       Enrolled             Michael Fuller  1948-04-05  ...   \n\n                      ADDRESS_1 ADDRESS_2     CITY STATE    ZIP COUNTY  \\\n0             67 Silsbee Street     # 502     Lynn    MA  01901  ESSEX   \n1     67 Silsbee Street Apt 502               Lynn    MA  01901  ESSEX   \n2           28 Essex St Room 4B               Lynn    MA  01902  ESSEX   \n3              19 Willow Street   Apt 208     Lynn    MA  01901  ESSEX   \n4     160 Neptune Blvd. Apt 507               Lynn    MA  01905  ESSEX   \n...                         ...       ...      ...   ...    ...    ...   \n3142       18 Walnut st Apt 210            PEABODY    MA  01960  ESSEX   \n3143     26 Myrtle Street Apt 2               Lynn    MA  01905  ESSEX   \n3144        21 Morris Street #2               Lynn    MA  01905  ESSEX   \n3145       170 S COMMON ST #405               LYNN    MA  01902  ESSEX   \n3146       195 Union Street #41               Lynn    MA  01902  ESSEX   \n\n      ADDR_START    ADDR_END                PHONE_1            CURRENT_AS_OF  \n0     2004-05-01              (781) 581-3902 [Home]  2022-12-15 12:58:59.000  \n1     2004-07-01  2022-02-28  (781) 581-3902 [Home]  2022-12-15 12:58:59.000  \n2     2012-08-10  2020-01-31  (781) 599-0190 [Home]  2022-12-15 12:58:59.000  \n3     2004-05-01  2021-03-31  (781) 598-1391 [Home]  2022-12-15 12:58:59.000  \n4     2004-05-01              (339) 440-5236 [Home]  2022-12-15 12:58:59.000  \n...          ...         ...                    ...                      ...  \n3142  2022-10-28              (978) 397-6169 [Home]  2022-12-15 12:58:59.000  \n3143  2022-11-01              (781) 632-7483 [Home]  2022-12-15 12:58:59.000  \n3144  2022-11-01              (781) 853-3330 [Home]  2022-12-15 12:58:59.000  \n3145  2022-11-01              (781) 854-1088 [Home]  2022-12-15 12:58:59.000  \n3146  2022-11-01              (781) 990-9122 [Home]  2022-12-15 12:58:59.000  \n\n[3147 rows x 25 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>MEMBER_ID</th>\n      <th>MBI</th>\n      <th>HICN</th>\n      <th>MMIS_ID</th>\n      <th>PRODUCT</th>\n      <th>ENROLL_ST</th>\n      <th>ENROLL_ED</th>\n      <th>ENROLL_STATUS2</th>\n      <th>FULL_NAME</th>\n      <th>DOB</th>\n      <th>...</th>\n      <th>ADDRESS_1</th>\n      <th>ADDRESS_2</th>\n      <th>CITY</th>\n      <th>STATE</th>\n      <th>ZIP</th>\n      <th>COUNTY</th>\n      <th>ADDR_START</th>\n      <th>ADDR_END</th>\n      <th>PHONE_1</th>\n      <th>CURRENT_AS_OF</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>5364521168</td>\n      <td>1PQ7T86FD63</td>\n      <td>281042735M</td>\n      <td>100027225505</td>\n      <td>SCO</td>\n      <td>2004-07-01</td>\n      <td>9999-12-30</td>\n      <td>Enrolled</td>\n      <td>Semen Yudkovich</td>\n      <td>1935-09-19</td>\n      <td>...</td>\n      <td>67 Silsbee Street</td>\n      <td># 502</td>\n      <td>Lynn</td>\n      <td>MA</td>\n      <td>01901</td>\n      <td>ESSEX</td>\n      <td>2004-05-01</td>\n      <td></td>\n      <td>(781) 581-3902 [Home]</td>\n      <td>2022-12-15 12:58:59.000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>5364521169</td>\n      <td>2HH6A83NK63</td>\n      <td>281043939M</td>\n      <td>100027225513</td>\n      <td>SCO</td>\n      <td>2004-07-01</td>\n      <td>2022-02-28</td>\n      <td>Disenrolled</td>\n      <td>Margarita Yudkovich</td>\n      <td>1935-10-27</td>\n      <td>...</td>\n      <td>67 Silsbee Street Apt 502</td>\n      <td></td>\n      <td>Lynn</td>\n      <td>MA</td>\n      <td>01901</td>\n      <td>ESSEX</td>\n      <td>2004-07-01</td>\n      <td>2022-02-28</td>\n      <td>(781) 581-3902 [Home]</td>\n      <td>2022-12-15 12:58:59.000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5364521215</td>\n      <td>7PE4CW7HF86</td>\n      <td>036205064D</td>\n      <td>100005437941</td>\n      <td>SCO</td>\n      <td>2004-09-01</td>\n      <td>2020-01-31</td>\n      <td>Disenrolled</td>\n      <td>Barbara Davis</td>\n      <td>1931-01-30</td>\n      <td>...</td>\n      <td>28 Essex St Room 4B</td>\n      <td></td>\n      <td>Lynn</td>\n      <td>MA</td>\n      <td>01902</td>\n      <td>ESSEX</td>\n      <td>2012-08-10</td>\n      <td>2020-01-31</td>\n      <td>(781) 599-0190 [Home]</td>\n      <td>2022-12-15 12:58:59.000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>5364521236</td>\n      <td>4KR5DX1YF65</td>\n      <td>011767159M</td>\n      <td>100016631432</td>\n      <td>SCO</td>\n      <td>2004-09-01</td>\n      <td>2021-03-31</td>\n      <td>Disenrolled</td>\n      <td>Semen Tyutyunik</td>\n      <td>1926-05-05</td>\n      <td>...</td>\n      <td>19 Willow Street</td>\n      <td>Apt 208</td>\n      <td>Lynn</td>\n      <td>MA</td>\n      <td>01901</td>\n      <td>ESSEX</td>\n      <td>2004-05-01</td>\n      <td>2021-03-31</td>\n      <td>(781) 598-1391 [Home]</td>\n      <td>2022-12-15 12:58:59.000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5364521251</td>\n      <td>5YU3H27TQ86</td>\n      <td>019604163A</td>\n      <td>100218304242</td>\n      <td>SCO</td>\n      <td>2004-10-01</td>\n      <td>9999-12-30</td>\n      <td>Enrolled</td>\n      <td>Eduardo Santos</td>\n      <td>1935-11-03</td>\n      <td>...</td>\n      <td>160 Neptune Blvd. Apt 507</td>\n      <td></td>\n      <td>Lynn</td>\n      <td>MA</td>\n      <td>01905</td>\n      <td>ESSEX</td>\n      <td>2004-05-01</td>\n      <td></td>\n      <td>(339) 440-5236 [Home]</td>\n      <td>2022-12-15 12:58:59.000</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3142</th>\n      <td>5366070702</td>\n      <td>9KW1C85DD28</td>\n      <td></td>\n      <td>100221657412</td>\n      <td>SCO</td>\n      <td>2022-11-01</td>\n      <td>9999-12-30</td>\n      <td>Enrolled</td>\n      <td>Yvelisse Aponte Derich</td>\n      <td>1947-04-06</td>\n      <td>...</td>\n      <td>18 Walnut st Apt 210</td>\n      <td></td>\n      <td>PEABODY</td>\n      <td>MA</td>\n      <td>01960</td>\n      <td>ESSEX</td>\n      <td>2022-10-28</td>\n      <td></td>\n      <td>(978) 397-6169 [Home]</td>\n      <td>2022-12-15 12:58:59.000</td>\n    </tr>\n    <tr>\n      <th>3143</th>\n      <td>5366070866</td>\n      <td></td>\n      <td></td>\n      <td>100035368751</td>\n      <td>SCO</td>\n      <td>2022-11-01</td>\n      <td>9999-12-30</td>\n      <td>Enrolled</td>\n      <td>Victor Espinosa Rodriguez</td>\n      <td>1953-08-11</td>\n      <td>...</td>\n      <td>26 Myrtle Street Apt 2</td>\n      <td></td>\n      <td>Lynn</td>\n      <td>MA</td>\n      <td>01905</td>\n      <td>ESSEX</td>\n      <td>2022-11-01</td>\n      <td></td>\n      <td>(781) 632-7483 [Home]</td>\n      <td>2022-12-15 12:58:59.000</td>\n    </tr>\n    <tr>\n      <th>3144</th>\n      <td>5366070873</td>\n      <td></td>\n      <td></td>\n      <td>100005738123</td>\n      <td>SCO</td>\n      <td>2022-11-01</td>\n      <td>9999-12-30</td>\n      <td>Enrolled</td>\n      <td>RUN NOUM</td>\n      <td>1955-06-05</td>\n      <td>...</td>\n      <td>21 Morris Street #2</td>\n      <td></td>\n      <td>Lynn</td>\n      <td>MA</td>\n      <td>01905</td>\n      <td>ESSEX</td>\n      <td>2022-11-01</td>\n      <td></td>\n      <td>(781) 853-3330 [Home]</td>\n      <td>2022-12-15 12:58:59.000</td>\n    </tr>\n    <tr>\n      <th>3145</th>\n      <td>5366070928</td>\n      <td>1KT8GY1FH59</td>\n      <td></td>\n      <td>100033762004</td>\n      <td>SCO</td>\n      <td>2022-11-01</td>\n      <td>9999-12-30</td>\n      <td>Enrolled</td>\n      <td>BARBARA F JOHNSON</td>\n      <td>1951-01-10</td>\n      <td>...</td>\n      <td>170 S COMMON ST #405</td>\n      <td></td>\n      <td>LYNN</td>\n      <td>MA</td>\n      <td>01902</td>\n      <td>ESSEX</td>\n      <td>2022-11-01</td>\n      <td></td>\n      <td>(781) 854-1088 [Home]</td>\n      <td>2022-12-15 12:58:59.000</td>\n    </tr>\n    <tr>\n      <th>3146</th>\n      <td>5366070930</td>\n      <td>9D56V50DF68</td>\n      <td></td>\n      <td>100225072246</td>\n      <td>SCO</td>\n      <td>2022-11-01</td>\n      <td>9999-12-30</td>\n      <td>Enrolled</td>\n      <td>Michael Fuller</td>\n      <td>1948-04-05</td>\n      <td>...</td>\n      <td>195 Union Street #41</td>\n      <td></td>\n      <td>Lynn</td>\n      <td>MA</td>\n      <td>01902</td>\n      <td>ESSEX</td>\n      <td>2022-11-01</td>\n      <td></td>\n      <td>(781) 990-9122 [Home]</td>\n      <td>2022-12-15 12:58:59.000</td>\n    </tr>\n  </tbody>\n</table>\n<p>3147 rows × 25 columns</p>\n</div>"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dict['Element_claims_member_contact']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "#Creating of parameters for securing connection to Snowflake-credentials stored in local environment variables\n",
    "username = os.getenv('Snowflake_User')\n",
    "password = os.getenv('Snowflake_password')\n",
    "account = os.getenv('Snowflake_account')\n",
    "\n",
    "#Define parameters if neccessary\n",
    "warehouse = 'DEVELOPER_STANDARD'\n",
    "database = 'VESTA_DEVELOPMENT'\n",
    "schema = 'ANALYST_SANDBOX'\n",
    "\n",
    "#Create connection object for Snowflake connection\n",
    "conn = sf.connect(user=username, password=password, account=account, warehouse=warehouse)\n",
    "\n",
    "\n",
    "#Execution function\n",
    "def execute_query(connection, query):\n",
    "    cursor = connection.cursor()\n",
    "    cursor.execute(query)\n",
    "    cursor.close\n",
    "\n",
    "\n",
    "#Define Database to use in Snowflake\n",
    "sql = 'USE DATABASE {}'.format(database)\n",
    "execute_query(conn, sql)\n",
    "\n",
    "#Define Schema to use in Snowflake\n",
    "sql = 'USE SCHEMA {}.{}'.format(database, schema)\n",
    "execute_query(conn, sql)\n",
    "\n",
    "#Define Warehouse to use in Snowflake\n",
    "sql = 'USE WAREHOUSE {}'.format(warehouse)\n",
    "execute_query(conn, sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### SQL to drop tables prior to creating and uploading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "################################## Contact Table\n",
    "try:\n",
    "    sql = 'DROP TABLE IF EXISTS CCA_CONTACT_RAW_TEST'\n",
    "    execute_query(conn, sql)\n",
    "\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "################################## Claims Table\n",
    "try:\n",
    "    sql = 'DROP TABLE IF EXISTS CCA_CLAIMS_RAW_TEST'\n",
    "    execute_query(conn, sql)\n",
    "\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "################################## Demographic Table\n",
    "try:\n",
    "    sql = 'DROP TABLE IF EXISTS CCA_DEMO_RAW_TEST'\n",
    "    execute_query(conn, sql)\n",
    "\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "################################## DX Table\n",
    "try:\n",
    "    sql = 'DROP TABLE IF EXISTS CCA_DX_RAW_TEST'\n",
    "    execute_query(conn, sql)\n",
    "\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "################################## Enroll Table\n",
    "try:\n",
    "    sql = 'DROP TABLE IF EXISTS CCA_ENROLL_RAW_TEST'\n",
    "    execute_query(conn, sql)\n",
    "\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "################################## PCP Table\n",
    "try:\n",
    "    sql = 'DROP TABLE IF EXISTS CCA_PCP_RAW_TEST'\n",
    "    execute_query(conn, sql)\n",
    "\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "    ################################## MDS Table\n",
    "try:\n",
    "    sql = 'DROP TABLE IF EXISTS CCA_MDS_RAW_TEST'\n",
    "    execute_query(conn, sql)\n",
    "\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1d315275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 483.2472846508026 seconds ---\n"
     ]
    }
   ],
   "source": [
    "\n",
    "################################## MEMBER CONTACT SQL\n",
    "\n",
    "try:\n",
    "    sql = 'CREATE TABLE IF NOT EXISTS CCA_CONTACT_RAW_TEST ' + sql_script_dict_table['Element_claims_member_contact']\n",
    "    execute_query(conn, sql)\n",
    "\n",
    "    success, nchucks, nrows, _ = write_pandas(conn, df_dict['Element_claims_member_contact'], 'CCA_CONTACT_RAW_TEST')\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "###################################\n",
    "\n",
    "################################## CLAIMS SQL\n",
    "\n",
    "try:\n",
    "    sql = 'CREATE TABLE IF NOT EXISTS CCA_CLAIMS_RAW_TEST ' + sql_script_dict_table['Element_claims']\n",
    "    execute_query(conn, sql)\n",
    "\n",
    "    success, nchucks, nrows, _ = write_pandas(conn, df_dict['Element_claims'], 'CCA_CLAIMS_RAW_TEST')\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "# ###################################\n",
    "#\n",
    "# ################################## DEMO SQL\n",
    "#\n",
    "try:\n",
    "    sql = 'CREATE TABLE IF NOT EXISTS CCA_DEMO_RAW_TEST ' + sql_script_dict_table['Element_claims_member_demographics']\n",
    "    execute_query(conn, sql)\n",
    "\n",
    "    success, nchucks, nrows, _ = write_pandas(conn, df_dict['Element_claims_member_demographics'], 'CCA_DEMO_RAW_TEST')\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "# ###################################\n",
    "#\n",
    "# ################################## DX SQL\n",
    "\n",
    "try:\n",
    "    sql = 'CREATE TABLE IF NOT EXISTS CCA_DX_RAW_TEST ' + sql_script_dict_table['Element_claims_member_dx']\n",
    "    execute_query(conn, sql)\n",
    "\n",
    "    success, nchucks, nrows, _ = write_pandas(conn, df_dict['Element_claims_member_dx'], 'CCA_DX_RAW_TEST')\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "# ###################################\n",
    "#\n",
    "# ################################## ENROLLMENT SQL\n",
    "\n",
    "try:\n",
    "    sql = 'CREATE TABLE IF NOT EXISTS CCA_ENROLL_RAW_TEST' + sql_script_dict_table['Element_claims_member_enrollment']\n",
    "    execute_query(conn, sql)\n",
    "\n",
    "    success, nchucks, nrows, _ = write_pandas(conn, df_dict['Element_claims_member_enrollment'], 'CCA_ENROLL_RAW_TEST')\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "# ###################################\n",
    "#\n",
    "# ################################## PCP SQL\n",
    "\n",
    "try:\n",
    "    sql = 'CREATE TABLE IF NOT EXISTS CCA_PCP_RAW_TEST' + sql_script_dict_table['Element_claims_PCP_contact']\n",
    "    execute_query(conn, sql)\n",
    "\n",
    "    success, nchucks, nrows, _ = write_pandas(conn, df_dict['Element_claims_PCP_contact'], 'CCA_PCP_RAW_TEST')\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "# # ###################################\n",
    "#\n",
    "# ################################## MDS SQL\n",
    "\n",
    "try:\n",
    "    sql = 'CREATE TABLE IF NOT EXISTS CCA_MDS_RAW_TEST' + sql_script_dict_table['Element_MDS']\n",
    "    execute_query(conn, sql)\n",
    "\n",
    "    success, nchucks, nrows, _ = write_pandas(conn, df_dict['Element_MDS'], 'CCA_MDS_RAW_TEST')\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "###################################\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7c566bff",
   "metadata": {},
   "outputs": [
    {
     "ename": "SMTPAuthenticationError",
     "evalue": "(535, b'5.7.8 Username and Password not accepted. Learn more at\\n5.7.8  https://support.google.com/mail/?p=BadCredentials v10-20020a05620a440a00b006fab416015csm2548837qkp.25 - gsmtp')",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mSMTPAuthenticationError\u001B[0m                   Traceback (most recent call last)",
      "Input \u001B[1;32mIn [24]\u001B[0m, in \u001B[0;36m<cell line: 14>\u001B[1;34m()\u001B[0m\n\u001B[0;32m     13\u001B[0m context \u001B[38;5;241m=\u001B[39m ssl\u001B[38;5;241m.\u001B[39mcreate_default_context()\n\u001B[0;32m     14\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m smtplib\u001B[38;5;241m.\u001B[39mSMTP_SSL(smtp_server, port, context\u001B[38;5;241m=\u001B[39mcontext) \u001B[38;5;28;01mas\u001B[39;00m server:\n\u001B[1;32m---> 15\u001B[0m     \u001B[43mserver\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlogin\u001B[49m\u001B[43m(\u001B[49m\u001B[43msender_email\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpassword\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     16\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m receiver_email \u001B[38;5;129;01min\u001B[39;00m receiver_email_list:\n\u001B[0;32m     17\u001B[0m         server\u001B[38;5;241m.\u001B[39msendmail(sender_email, receiver_email, message)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\NewBase\\lib\\smtplib.py:750\u001B[0m, in \u001B[0;36mSMTP.login\u001B[1;34m(self, user, password, initial_response_ok)\u001B[0m\n\u001B[0;32m    747\u001B[0m         last_exception \u001B[38;5;241m=\u001B[39m e\n\u001B[0;32m    749\u001B[0m \u001B[38;5;66;03m# We could not login successfully.  Return result of last attempt.\u001B[39;00m\n\u001B[1;32m--> 750\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m last_exception\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\NewBase\\lib\\smtplib.py:739\u001B[0m, in \u001B[0;36mSMTP.login\u001B[1;34m(self, user, password, initial_response_ok)\u001B[0m\n\u001B[0;32m    737\u001B[0m method_name \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mauth_\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;241m+\u001B[39m authmethod\u001B[38;5;241m.\u001B[39mlower()\u001B[38;5;241m.\u001B[39mreplace(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m-\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m_\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m    738\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 739\u001B[0m     (code, resp) \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mauth\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    740\u001B[0m \u001B[43m        \u001B[49m\u001B[43mauthmethod\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mgetattr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmethod_name\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    741\u001B[0m \u001B[43m        \u001B[49m\u001B[43minitial_response_ok\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minitial_response_ok\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    742\u001B[0m     \u001B[38;5;66;03m# 235 == 'Authentication successful'\u001B[39;00m\n\u001B[0;32m    743\u001B[0m     \u001B[38;5;66;03m# 503 == 'Error: already authenticated'\u001B[39;00m\n\u001B[0;32m    744\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m code \u001B[38;5;129;01min\u001B[39;00m (\u001B[38;5;241m235\u001B[39m, \u001B[38;5;241m503\u001B[39m):\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\NewBase\\lib\\smtplib.py:662\u001B[0m, in \u001B[0;36mSMTP.auth\u001B[1;34m(self, mechanism, authobject, initial_response_ok)\u001B[0m\n\u001B[0;32m    660\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m code \u001B[38;5;129;01min\u001B[39;00m (\u001B[38;5;241m235\u001B[39m, \u001B[38;5;241m503\u001B[39m):\n\u001B[0;32m    661\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m (code, resp)\n\u001B[1;32m--> 662\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m SMTPAuthenticationError(code, resp)\n",
      "\u001B[1;31mSMTPAuthenticationError\u001B[0m: (535, b'5.7.8 Username and Password not accepted. Learn more at\\n5.7.8  https://support.google.com/mail/?p=BadCredentials v10-20020a05620a440a00b006fab416015csm2548837qkp.25 - gsmtp')"
     ]
    }
   ],
   "source": [
    "my_string = '\\n'.join(claimslog)\n",
    "\n",
    "port = 465  # For SSL\n",
    "smtp_server = \"smtp.gmail.com\"\n",
    "sender_email = \"VestaPingLog@gmail.com\"  # Enter your address\n",
    "receiver_email_list = [\"jdriggers@vestahealthcare.com\", \"john@vestahealthcare.com\",\n",
    "                       'joe@vestahealthcare.com']  # Enter receiver address\n",
    "password = os.getenv('Vesta_Ping_Log_Email') #Need password for VestaPingLog@gmail.com\n",
    "message = \"Subject: Ping Logs \\n\" + '''\n",
    "             \n",
    "''' + my_string\n",
    "\n",
    "context = ssl.create_default_context()\n",
    "with smtplib.SMTP_SSL(smtp_server, port, context=context) as server:\n",
    "    server.login(sender_email, password)\n",
    "    for receiver_email in receiver_email_list:\n",
    "        server.sendmail(sender_email, receiver_email, message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('NewBase')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "4bb5f7e03c56d6e91378b915f266587dc28bbd5e1a358e8c73c01ed5dd6d43c1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
