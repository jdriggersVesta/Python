{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72278115",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Necessary dependencies\n",
    "import pandas as pd\n",
    "import snowflake.connector as sf\n",
    "import numpy as np\n",
    "import time\n",
    "import boto3\n",
    "import os\n",
    "import zipfile\n",
    "import smtplib, ssl\n",
    "import shutil\n",
    "import csv\n",
    "from snowflake.connector.pandas_tools import write_pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba74034",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Log for review\n",
    "start_time = time.time()\n",
    "claimslog = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a58ff69",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    #Create Local Directory to store files in temporarily\n",
    "    os.makedirs('C:\\\\Users\\\\Jad Driggers\\\\Documents\\\\Vesta\\\\CCAFILES')\n",
    "    os.chdir('C:\\\\Users\\\\Jad Driggers\\\\Documents\\\\Vesta\\\\CCAFILES')\n",
    "    root_directory = os.getcwd()\n",
    "    claimslog.append('Successfully created CCA File Temporary Folder at ' + time.strftime('%Y-%m-%d %H:%M:%S',\n",
    "                                                                                          time.localtime(time.time())))\n",
    "except Exception as e:\n",
    "    claimslog.append('There was an error with creating the temporary CCA File - ' + str(e))\n",
    "    print('Successfully created CCA File Temporary Folder at ' + time.strftime('%Y-%m-%d %H:%M:%S',\n",
    "                                                                               time.localtime(time.time())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1967f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    #Create Connection Object for Connecting to AWS\n",
    "    s3 = boto3.resource(\n",
    "        service_name='s3',\n",
    "        region_name='us-east-1',\n",
    "        aws_access_key_id=os.getenv('aws_access_key_id'),\n",
    "        aws_secret_access_key=os.getenv('aws_secret_access_key'))\n",
    "    print('AWS connection object created at ' + time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(time.time())))\n",
    "    claimslog.append(\n",
    "        'AWS connection object created at ' + time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(time.time())))\n",
    "except Exception as e:\n",
    "    print('There was an error with creating the AWS connection object - ' + str(e))\n",
    "    claimslog.append('There was an error with creating the AWS connection object - ' + str(e))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a96227da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the file name format for locating the proper CCA files to parse\n",
    "\n",
    "filename_format_list = ['Element claims 202301.zip', 'Element MDS 202301.zip']\n",
    "claimslog.append('Looking for CCA Files that start like ' + \" and \".join(filename_format_list) + ' at ' + time.strftime(\n",
    "    '%Y-%m-%d %H:%M:%S', time.localtime(time.time())))\n",
    "print('Looking for CCA Files that start like ' + \" and \".join(filename_format_list) + ' at ' + time.strftime(\n",
    "    '%Y-%m-%d %H:%M:%S', time.localtime(time.time())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a82ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a list to store all the keys (file names) to download\n",
    "\n",
    "key_list = []\n",
    "\n",
    "try:\n",
    "    #Searching the S3 bucket for the most current Ping Files\n",
    "    for obj in s3.Bucket('hometeam-clinical-data').objects.all():\n",
    "        for filename_format in filename_format_list:\n",
    "            if filename_format in str(obj):\n",
    "                #print(obj.key)\n",
    "                key_list.append(obj.key)\n",
    "\n",
    "except Exception as e:\n",
    "    claimslog.append('There was an error while looking for most CCA Files - ' + str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(key_list)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ccf1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    #Downloading each of the files found in the key list\n",
    "    for file in key_list:\n",
    "        s3.Bucket('hometeam-clinical-data').download_file(file, file.split('/')[2])\n",
    "        print(\n",
    "            'Files were successfully downloaded at ' + time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(time.time())))\n",
    "    claimslog.append(\n",
    "        'Files were successfully downloaded at ' + time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(time.time())))\n",
    "except Exception as e:\n",
    "    claimslog.append('There was an error while trying to download the CCA Files - ' + str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Move files into Monthly_Claims folder\n",
    "# bucket = 'hometeam-clinical-data'\n",
    "# copy_source = {\n",
    "#     'Bucket': bucket,\n",
    "#     'Key': 'raw/cca/Monthly_Claims/Element MDS 202301.zip',\n",
    "#     }\n",
    "#\n",
    "# copy_source2 = {\n",
    "#     'Bucket': bucket,\n",
    "#     'Key': 'raw/cca/Element claims 202301.zip',\n",
    "# }\n",
    "# s3.meta.client.copy(copy_source,bucket, 'raw/cca/Monthly_Claims/Element MDS 202301.zip')\n",
    "# s3.meta.client.copy(copy_source2,bucket, 'raw/cca/Monthly_Claims/Element claims 202301.zip')\n",
    "# s3_object = s3.Object('hometeam-clinical-data', 'raw/cca/Monthly_Claims/Element MDS 202301.zip')\n",
    "# s3_object2 = s3.Object('hometeam-clinical-data', 'raw/cca/Monthly_Claims/Element claims 202301.zip')\n",
    "# s3_object.delete()\n",
    "# s3_object2.delete()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca78188d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#On local computer, change directory and set directory for unzipping of files.\n",
    "os.chdir('C:\\\\Users\\\\Jad Driggers\\\\Documents\\\\Vesta\\\\CCAFILES')\n",
    "root_directory = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29382098",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Locate only Zipped Files\n",
    "files_to_unzip = []\n",
    "for filename in os.listdir(root_directory):\n",
    "    if 'zip' in filename:\n",
    "        files_to_unzip.append(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dec649e",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    #Unzip each file in the Zipped files list\n",
    "    for zipped_file in files_to_unzip:\n",
    "        with zipfile.ZipFile(root_directory + \"\\\\\" + zipped_file, 'r') as zip_ref:\n",
    "            #print(zipped_file)\n",
    "            zip_ref.extractall(root_directory)\n",
    "    shutil.unpack_archive(root_directory + \"\\\\\" + zipped_file, root_directory + \"\\\\\" + zipped_file.split('.')[0])\n",
    "    claimslog.append(\n",
    "        'Successfully Unzipped each file at ' + time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(time.time())))\n",
    "except Exception as e:\n",
    "    claimslog.append('There was an error while trying to unzip each file - ' + str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#% % timeit\n",
    "#Create dictionary to store dataframes as they are created \n",
    "df_dict = {}\n",
    "error_dict = {}\n",
    "\n",
    "#Set current directory\n",
    "cwd = os.chdir('C:\\\\Users\\\\Jad Driggers\\\\Documents\\\\Vesta\\\\CCAFILES')\n",
    "\n",
    "#Loop through all txt files in the directory\n",
    "for i, file in enumerate(os.listdir(cwd)):\n",
    "    if '.txt' in file:\n",
    "\n",
    "        #empty lists to store the data while cleaning\n",
    "        df_list = []\n",
    "        df_error_list = []\n",
    "\n",
    "        #open the txt file\n",
    "        with open(file, 'r') as csvfile:\n",
    "            reader = csv.reader(csvfile, delimiter='\\t')\n",
    "\n",
    "            #read through each line and find any rows with errors\n",
    "            for i, row in enumerate(reader):\n",
    "                if i == 0:\n",
    "                    #capture the correct number of columns for the dataframe\n",
    "                    correct_columns = len(row)\n",
    "\n",
    "                df_list.append(row)\n",
    "\n",
    "                #create list of rows with errors\n",
    "                if len(row) < correct_columns:\n",
    "                    df_error_list.append(i)\n",
    "\n",
    "            #Check to see if the list row in the data frame is an empty row, if so, drop it\n",
    "            if len(df_list[df_error_list[-1]]) == 0:\n",
    "                df_error_list.pop()\n",
    "\n",
    "            #The error exists between two rows, so looking at the second occurance of an error \n",
    "            #and deleting the first item should fix the error\n",
    "            for i, error in enumerate(df_error_list):\n",
    "                if i % 2 != 0:\n",
    "                    df_list[error].pop(0)\n",
    "\n",
    "            #Loop back through the error list and join first errors to second errors to make a complete row\n",
    "            for i, error in enumerate(df_error_list):\n",
    "                if i % 2 == 0:\n",
    "                    df_list[error] = df_list[error] + df_list[error + 1]\n",
    "\n",
    "            #Loop back through the entire data frame list to delete those rows that are smaller than the correct\n",
    "            #number of columns\n",
    "            for i, item in enumerate(df_list):\n",
    "                if len(item) < correct_columns:\n",
    "                    del df_list[i]\n",
    "\n",
    "            df = pd.DataFrame(df_list[1:])\n",
    "            df.columns = df_list[0]\n",
    "            df = df.rename(columns={df.columns[0]: df.columns[0][3:]})\n",
    "            df = df.astype(str)\n",
    "            df.columns = map(lambda x: str(x).upper(), df.columns)\n",
    "            df_dict[csvfile.name.replace(' ', '_').split(\".\")[0]] = df\n",
    "            error_dict[csvfile.name.replace(' ', '_').split(\".\")[0]] = df_error_list\n",
    "\n",
    "        csvfile.close()\n",
    "\n",
    "for key, value in df_dict.items():\n",
    "    print(key)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e675666d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Delete all contents in the temporary CCA Folder\n",
    "os.chdir('C:\\\\Users\\\\Jad Driggers\\\\Documents\\\\Vesta')\n",
    "shutil.rmtree('C:\\\\Users\\\\Jad Driggers\\\\Documents\\\\Vesta\\\\CCAFILES')\n",
    "claimslog.append('Successfully Deleted all contents in temporary CCA Folder at ' + time.strftime('%Y-%m-%d %H:%M:%S',\n",
    "                                                                                                 time.localtime(\n",
    "                                                                                                     time.time())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ec5abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict['Element_claims_member_demographics'].rename(columns={\"CCAID\": \"MEMBER_ID\",\n",
    "                                                              \"NAME\": \"MNAME\",\n",
    "                                                              \"PCL_SITENAME\": \"PCL\",\n",
    "                                                              \"PCL_SUMMARYNAME\": \"PCL_SUMMARY\",\n",
    "                                                              \"PCL_CAPSITE\": \"PCL_CAP\",\n",
    "                                                              \"DUAL\": \"DUAL_\",\n",
    "                                                              \"GC_ENGAGEMENTSTATUS\": \"GC_ENGAGEMENT_STATUS\",\n",
    "                                                              \"MDS_UNREACHABLEFLAG\": \"MDS_UNREACHABLE\"},\n",
    "                                                     errors=\"raise\",\n",
    "                                                     inplace=True)\n",
    "df_dict['Element_claims_member_contact'].rename(columns={\"CCAID\": \"MEMBER_ID\",\n",
    "                                                         \"ENR_SPAN_START\": \"ENROLL_ST\",\n",
    "                                                         \"ENR_SPAN_END\": \"ENROLL_ED\",\n",
    "                                                         \"ENROLL_STATUS\": \"ENROLL_STATUS2\",\n",
    "                                                         \"NAME\": \"FULL_NAME\",\n",
    "                                                         \"AGE_NOW\": \"AGE\",\n",
    "                                                         \"GENDER\": \"SEX\",\n",
    "                                                         \"LANGUAGE\": \"LANGUAGE_SPOKEN\",\n",
    "                                                         \"ADDRESS1\": \"ADDRESS_1\",\n",
    "                                                         \"ADDRESS2\": \"ADDRESS_2\",\n",
    "                                                         \"LATEST_PHONE\": \"PHONE_1\"},\n",
    "                                                errors=\"raise\",\n",
    "                                                inplace=True)\n",
    "df_dict['Element_claims_member_enrollment'].rename(columns={\"CCAID\": \"MEMBER_ID\",\n",
    "                                                            \"PCP_PROVK\": \"PCP_ID\",\n",
    "                                                            \"PCL_SITENAME\": \"PCL\",\n",
    "                                                            \"DUAL\": \"DUAL_\"},\n",
    "                                                   errors=\"raise\",\n",
    "                                                   inplace=True)\n",
    "df_dict['Element_claims'].rename(columns={\"CCAID\": \"MEMBER_ID\",\n",
    "                                          \"HICN\": \"MEDICARE_ID\",\n",
    "                                          \"CLAIM_NUM\": \"CLAIM_ID\",\n",
    "                                          \"TABLEROWID\": \"CLAIM_LINE\",\n",
    "                                          \"HOSPITAL_CLAIM_TYPE\": \"HOS_CLAIM_TYPE\",\n",
    "                                          \"SERVICE_CODE\": \"CODE\",\n",
    "                                          \"SERVICE_DESC\": \"CODE_DESC\",\n",
    "                                          \"DATE_TO\": \"DATE_THRU\",\n",
    "                                          \"BILLTYPE\": \"BILL_TYPE\",\n",
    "                                          \"BILLTYPE_DESCR\": \"BILL_TYPE_DESCR\",\n",
    "                                          \"DATE_PAID\": \"PAID_DTE\",\n",
    "                                          \"CLAIMCATEGORY_GL1\": \"CLAIM_GROUP\"},\n",
    "                                 errors=\"raise\",\n",
    "                                 inplace=True)\n",
    "df_dict['Element_claims_member_dx'].rename(columns={\"CCAID\": \"MEMBER_ID\",\n",
    "                                                    \"HICN\": \"MEDICARE_ID\",\n",
    "                                                    \"CLAIM_NUM\": \"CLAIM_ID\",\n",
    "                                                    \"DIAGREFNO\": \"DIAG_NUM\"},\n",
    "                                           errors=\"raise\",\n",
    "                                           inplace=True)\n",
    "df_dict['Element_MDS'].rename(columns={\"CCAID\": \"MEMBER_ID\",\n",
    "                                       \"ASSESSMENT_DATE\": \"ENC_DATE\"},\n",
    "                              errors=\"raise\",\n",
    "                              inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02503b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create two dictionaries to store the columns and the max len of values in those columns\n",
    "max_col_len = {}\n",
    "col_dict = {}\n",
    "\n",
    "#Vectorizing the length function\n",
    "measurer = np.vectorize(len)\n",
    "\n",
    "#Looping through df_dictionary to capture column names and max len of values in those columns\n",
    "max_col_len = {}\n",
    "for key, value in df_dict.items():\n",
    "    col_len = measurer(df_dict[key].astype(str)).max(axis=0)\n",
    "    max_col_len[key] = col_len\n",
    "    col_dict[key] = df_dict[key].columns.tolist()\n",
    "\n",
    "\n",
    "#Function for joining the two dictionaries with similar keys (claim files)\n",
    "def common_entries(*dcts):\n",
    "    if not dcts:\n",
    "        return\n",
    "    for i in set(dcts[0]).intersection(*dcts[1:]):\n",
    "        yield (i,) + tuple(d[i] for d in dcts)\n",
    "\n",
    "\n",
    "mylist = list(common_entries(col_dict, max_col_len))\n",
    "\n",
    "#Creating new dictionary and zipping the column names with respective max len of values in those columns\n",
    "sql_dict = {}\n",
    "for x in mylist:\n",
    "    sql_dict[x[0]] = list(zip(x[1], x[2]))\n",
    "\n",
    "#Iterating through the list values to prep for SQL to Snowflake\n",
    "sql_script_dict_table = {}\n",
    "for key, value in sql_dict.items():\n",
    "    script_string_table = ''\n",
    "    for (col, max_len) in sql_dict[key]:\n",
    "        script_string_table += str(col) + ' VARCHAR(' + str(max_len + 10) + '),'\n",
    "    sql_script_dict_table[key] = \"(\" + script_string_table[:-1] + \")\"\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8dc8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict['Element_claims_member_contact']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "#Creating of parameters for securing connection to Snowflake-credentials stored in local environment variables\n",
    "username = os.getenv('Snowflake_User')\n",
    "password = os.getenv('Snowflake_password')\n",
    "account = os.getenv('Snowflake_account')\n",
    "\n",
    "#Define parameters if neccessary\n",
    "warehouse = 'DEVELOPER_STANDARD'\n",
    "database = 'VESTA_DEVELOPMENT'\n",
    "schema = 'ANALYST_SANDBOX'\n",
    "\n",
    "#Create connection object for Snowflake connection\n",
    "conn = sf.connect(user=username, password=password, account=account, warehouse=warehouse)\n",
    "\n",
    "\n",
    "#Execution function\n",
    "def execute_query(connection, query):\n",
    "    cursor = connection.cursor()\n",
    "    cursor.execute(query)\n",
    "    cursor.close\n",
    "\n",
    "\n",
    "#Define Database to use in Snowflake\n",
    "sql = 'USE DATABASE {}'.format(database)\n",
    "execute_query(conn, sql)\n",
    "\n",
    "#Define Schema to use in Snowflake\n",
    "sql = 'USE SCHEMA {}.{}'.format(database, schema)\n",
    "execute_query(conn, sql)\n",
    "\n",
    "#Define Warehouse to use in Snowflake\n",
    "sql = 'USE WAREHOUSE {}'.format(warehouse)\n",
    "execute_query(conn, sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### SQL to drop tables prior to creating and uploading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "################################## Contact Table\n",
    "try:\n",
    "    sql = 'DROP TABLE IF EXISTS CCA_CONTACT_RAW_TEST'\n",
    "    execute_query(conn, sql)\n",
    "\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "################################## Claims Table\n",
    "try:\n",
    "    sql = 'DROP TABLE IF EXISTS CCA_CLAIMS_RAW_TEST'\n",
    "    execute_query(conn, sql)\n",
    "\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "################################## Demographic Table\n",
    "try:\n",
    "    sql = 'DROP TABLE IF EXISTS CCA_DEMO_RAW_TEST'\n",
    "    execute_query(conn, sql)\n",
    "\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "################################## DX Table\n",
    "try:\n",
    "    sql = 'DROP TABLE IF EXISTS CCA_DX_RAW_TEST'\n",
    "    execute_query(conn, sql)\n",
    "\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "################################## Enroll Table\n",
    "try:\n",
    "    sql = 'DROP TABLE IF EXISTS CCA_ENROLL_RAW_TEST'\n",
    "    execute_query(conn, sql)\n",
    "\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "################################## PCP Table\n",
    "try:\n",
    "    sql = 'DROP TABLE IF EXISTS CCA_PCP_RAW_TEST'\n",
    "    execute_query(conn, sql)\n",
    "\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "    ################################## MDS Table\n",
    "try:\n",
    "    sql = 'DROP TABLE IF EXISTS CCA_MDS_RAW_TEST'\n",
    "    execute_query(conn, sql)\n",
    "\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d315275",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "################################## MEMBER CONTACT SQL\n",
    "\n",
    "try:\n",
    "    sql = 'CREATE TABLE IF NOT EXISTS CCA_CONTACT_RAW_TEST ' + sql_script_dict_table['Element_claims_member_contact']\n",
    "    execute_query(conn, sql)\n",
    "\n",
    "    success, nchucks, nrows, _ = write_pandas(conn, df_dict['Element_claims_member_contact'], 'CCA_CONTACT_RAW_TEST')\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "###################################\n",
    "\n",
    "################################## CLAIMS SQL\n",
    "\n",
    "try:\n",
    "    sql = 'CREATE TABLE IF NOT EXISTS CCA_CLAIMS_RAW_TEST ' + sql_script_dict_table['Element_claims']\n",
    "    execute_query(conn, sql)\n",
    "\n",
    "    success, nchucks, nrows, _ = write_pandas(conn, df_dict['Element_claims'], 'CCA_CLAIMS_RAW_TEST')\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "# ###################################\n",
    "#\n",
    "# ################################## DEMO SQL\n",
    "#\n",
    "try:\n",
    "    sql = 'CREATE TABLE IF NOT EXISTS CCA_DEMO_RAW_TEST ' + sql_script_dict_table['Element_claims_member_demographics']\n",
    "    execute_query(conn, sql)\n",
    "\n",
    "    success, nchucks, nrows, _ = write_pandas(conn, df_dict['Element_claims_member_demographics'], 'CCA_DEMO_RAW_TEST')\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "# ###################################\n",
    "#\n",
    "# ################################## DX SQL\n",
    "\n",
    "try:\n",
    "    sql = 'CREATE TABLE IF NOT EXISTS CCA_DX_RAW_TEST ' + sql_script_dict_table['Element_claims_member_dx']\n",
    "    execute_query(conn, sql)\n",
    "\n",
    "    success, nchucks, nrows, _ = write_pandas(conn, df_dict['Element_claims_member_dx'], 'CCA_DX_RAW_TEST')\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "# ###################################\n",
    "#\n",
    "# ################################## ENROLLMENT SQL\n",
    "\n",
    "try:\n",
    "    sql = 'CREATE TABLE IF NOT EXISTS CCA_ENROLL_RAW_TEST' + sql_script_dict_table['Element_claims_member_enrollment']\n",
    "    execute_query(conn, sql)\n",
    "\n",
    "    success, nchucks, nrows, _ = write_pandas(conn, df_dict['Element_claims_member_enrollment'], 'CCA_ENROLL_RAW_TEST')\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "# ###################################\n",
    "#\n",
    "# ################################## PCP SQL\n",
    "\n",
    "try:\n",
    "    sql = 'CREATE TABLE IF NOT EXISTS CCA_PCP_RAW_TEST' + sql_script_dict_table['Element_claims_PCP_contact']\n",
    "    execute_query(conn, sql)\n",
    "\n",
    "    success, nchucks, nrows, _ = write_pandas(conn, df_dict['Element_claims_PCP_contact'], 'CCA_PCP_RAW_TEST')\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "# # ###################################\n",
    "#\n",
    "# ################################## MDS SQL\n",
    "\n",
    "try:\n",
    "    sql = 'CREATE TABLE IF NOT EXISTS CCA_MDS_RAW_TEST' + sql_script_dict_table['Element_MDS']\n",
    "    execute_query(conn, sql)\n",
    "\n",
    "    success, nchucks, nrows, _ = write_pandas(conn, df_dict['Element_MDS'], 'CCA_MDS_RAW_TEST')\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "###################################\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c566bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_string = '\\n'.join(claimslog)\n",
    "\n",
    "port = 465  # For SSL\n",
    "smtp_server = \"smtp.gmail.com\"\n",
    "sender_email = \"VestaPingLog@gmail.com\"  # Enter your address\n",
    "receiver_email_list = [\"jdriggers@vestahealthcare.com\", \"john@vestahealthcare.com\",\n",
    "                       'joe@vestahealthcare.com']  # Enter receiver address\n",
    "password = os.getenv('Vesta_Ping_Log_Email') #Need password for VestaPingLog@gmail.com\n",
    "message = \"Subject: Ping Logs \\n\" + '''\n",
    "             \n",
    "''' + my_string\n",
    "\n",
    "context = ssl.create_default_context()\n",
    "with smtplib.SMTP_SSL(smtp_server, port, context=context) as server:\n",
    "    server.login(sender_email, password)\n",
    "    for receiver_email in receiver_email_list:\n",
    "        server.sendmail(sender_email, receiver_email, message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('NewBase')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "4bb5f7e03c56d6e91378b915f266587dc28bbd5e1a358e8c73c01ed5dd6d43c1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
